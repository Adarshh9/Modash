{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LIj4pvopD5rf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'_id': '621ffdc036468d709f174338', 'id': 'google-bert/bert-base-uncased', 'modelId': 'google-bert/bert-base-uncased', 'author': 'google-bert', 'sha': '86b5e0934494bd15c9632b12f734a8a67f723594', 'lastModified': '2024-02-19T11:06:12.000Z', 'private': False, 'disabled': False, 'gated': False, 'pipeline_tag': 'fill-mask', 'tags': ['transformers', 'pytorch', 'tf', 'jax', 'rust', 'coreml', 'onnx', 'safetensors', 'bert', 'fill-mask', 'exbert', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1810.04805', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], 'downloads': 60696226, 'library_name': 'transformers', 'mask_token': '[MASK]', 'widgetData': [{'text': 'Paris is the [MASK] of France.'}, {'text': 'The goal of life is [MASK].'}], 'likes': 1567, 'model-index': None, 'config': {'architectures': ['BertForMaskedLM'], 'model_type': 'bert', 'tokenizer_config': {}}, 'cardData': {'language': 'en', 'tags': ['exbert'], 'license': 'apache-2.0', 'datasets': ['bookcorpus', 'wikipedia']}, 'transformersInfo': {'auto_model': 'AutoModelForMaskedLM', 'pipeline_tag': 'fill-mask', 'processor': 'AutoTokenizer'}, 'siblings': [{'rfilename': '.gitattributes'}, {'rfilename': 'LICENSE'}, {'rfilename': 'README.md'}, {'rfilename': 'config.json'}, {'rfilename': 'coreml/fill-mask/float32_model.mlpackage/Data/com.apple.CoreML/model.mlmodel'}, {'rfilename': 'coreml/fill-mask/float32_model.mlpackage/Data/com.apple.CoreML/weights/weight.bin'}, {'rfilename': 'coreml/fill-mask/float32_model.mlpackage/Manifest.json'}, {'rfilename': 'flax_model.msgpack'}, {'rfilename': 'model.onnx'}, {'rfilename': 'model.safetensors'}, {'rfilename': 'pytorch_model.bin'}, {'rfilename': 'rust_model.ot'}, {'rfilename': 'tf_model.h5'}, {'rfilename': 'tokenizer.json'}, {'rfilename': 'tokenizer_config.json'}, {'rfilename': 'vocab.txt'}], 'spaces': ['microsoft/HuggingGPT', 'Vision-CAIR/minigpt4', 'lnyan/stablediffusion-infinity', 'multimodalart/latentdiffusion', 'Salesforce/BLIP', 'shi-labs/Versatile-Diffusion', 'cvlab/zero123-live', 'xinyu1205/recognize-anything', 'AIGC-Audio/AudioGPT', 'mrfakename/MeloTTS', 'yizhangliu/Grounded-Segment-Anything', 'hilamanor/audioEditing', 'Audio-AGI/AudioSep', 'DAMO-NLP-SG/Video-LLaMA', 'gligen/demo', 'm-ric/chunk_visualizer', 'declare-lab/mustango', 'shgao/EditAnything', 'Vision-CAIR/MiniGPT-v2', 'Yuliang/ECON', 'Awiny/Image2Paragraph', 'IDEA-Research/Grounded-SAM', 'ShilongLiu/Grounding_DINO_demo', 'exbert-project/exbert', 'liuyuan-pal/SyncDreamer', 'haotiz/glip-zeroshot-demo', 'eswardivi/Podcastify', 'nateraw/lavila', 'Pinwheel/GLIP-BLIP-Object-Detection-VQA', 'sam-hq-team/sam-hq', 'Junfeng5/GLEE_demo', 'abyildirim/inst-inpaint', 'shi-labs/Matting-Anything', 'fffiloni/Video-Matting-Anything', 'magicr/BuboGPT', 'merve/Grounding_DINO_demo', 'OpenGVLab/InternGPT', 'clip-italian/clip-italian-demo', 'hongfz16/3DTopia', 'mmlab-ntu/relate-anything-model', 'byeongjun-park/HarmonyView', 'yenniejun/tokenizers-languages', 'keras-io/bert-semantic-similarity', 'MirageML/sjc', 'NAACL2022/CLIP-Caption-Reward', 'linfanluntan/Grounded-SAM', 'fffiloni/miniGPT4-Video-Zero', 'Gladiator/Text-Summarizer', 'society-ethics/model-card-regulatory-check', 'ysharma/text-to-image-to-video', 'milyiyo/reimagine-it', 'OpenGVLab/VideoChatGPT', 'avid-ml/bias-detection', 'llizhx/TinyGPT-V', 'ynhe/AskAnything', 'TencentARC/VLog', 'flax-community/koclip', 'Pusheen/LoCo', 'pseudolab/AI_Tutor_BERT', 'flax-community/clip-reply-demo', 'kaushalya/medclip-roco', 'SeViLA/SeViLA', 'PSLD/PSLD', 'AnimaLab/bias-test-gpt-pairs', 'CosmoAI/BhagwatGeeta', 'codelion/Grounding_DINO_demo', 'thewhole/GaussianDreamer_Demo', 'ALM/CALM', 'sasha/BiasDetection', 'tornadoslims/instruct-pix2pix', 'AIGC-Audio/Make_An_Audio', 'RitaParadaRamos/SmallCapDemo', 'MykolaL/evp', 'sasha/WinoBiasCheck', 'ccolas/TastyPiano', 'HaloMaster/chinesesummary', 'Make-A-Protagonist/Make-A-Protagonist-inference', 'mlpc-lab/BLIVA', 'AILab-CVC/SEED-LLaMA', 'fffiloni/audioldm-text-to-audio-generation-copy', 'emilylearning/llm_uncertainty', 'zdou0830/desco', 'taesiri/HuggingGPT-Lite', 'Volkopat/SegmentAnythingxGroundingDINO', 'attention-refocusing/Attention-refocusing', 'taka-yamakoshi/tokenizer-demo', 'mbahrami/Auto-Complete_Semantic', 'KAIST-Visual-AI-Group/salad-demo', 'EuroPython2022/clickbaitonator', 'doevent/blip', 'Dreamsome/HuggingFace-Datasets-Text-Quality-Analysis', 'badayvedat/AudioSep', 'Caoyunkang/Segment-Any-Anomaly', 'emilylearning/spurious_correlation_evaluation', 'nsethi610/ns-gradio-apps', 'iakarshu/docformer_for_document_classification', 'webshop/amazon_shop', 'Shredder/CONBERT-3', 'bradarrML/stablediffusion-infinity', 'flax-community/Multilingual-VQA'], 'createdAt': '2022-03-02T23:29:04.000Z', 'safetensors': {'parameters': {'F32': 110106428}, 'total': 110106428}}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Define the model ID (e.g., 'bert-base-uncased')\n",
        "model_id = \"bert-base-uncased\"\n",
        "\n",
        "# Define the URL for the model's information\n",
        "url = f\"https://huggingface.co/api/models/{model_id}\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    model_info = response.json()\n",
        "    print(model_info)\n",
        "else:\n",
        "    print(f\"Failed to fetch model information: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J3ghJSuTfpgx"
      },
      "outputs": [],
      "source": [
        "def get_model_data(model_id):\n",
        "  url = f\"https://huggingface.co/api/models/{model_id}\"\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    model_info = response.json()\n",
        "    return model_info\n",
        "  else:\n",
        "      print(f\"Failed to fetch model information: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_xIbp2BEf-al"
      },
      "outputs": [],
      "source": [
        "info = get_model_data(model_id='google/pegasus-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pnYorO4tgJsJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'_id': '621ffdc136468d709f17b6dd',\n",
              " 'id': 'google/pegasus-large',\n",
              " 'modelId': 'google/pegasus-large',\n",
              " 'author': 'google',\n",
              " 'sha': 'dec7796b22f29b7d1c476192313eae8ed57b6b77',\n",
              " 'lastModified': '2023-01-24T16:42:31.000Z',\n",
              " 'private': False,\n",
              " 'disabled': False,\n",
              " 'gated': False,\n",
              " 'pipeline_tag': 'summarization',\n",
              " 'tags': ['transformers',\n",
              "  'pytorch',\n",
              "  'tf',\n",
              "  'jax',\n",
              "  'pegasus',\n",
              "  'text2text-generation',\n",
              "  'summarization',\n",
              "  'en',\n",
              "  'arxiv:1912.08777',\n",
              "  'autotrain_compatible',\n",
              "  'endpoints_compatible',\n",
              "  'region:us'],\n",
              " 'downloads': 19128,\n",
              " 'library_name': 'transformers',\n",
              " 'widgetData': [{'text': 'The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.'}],\n",
              " 'likes': 91,\n",
              " 'model-index': None,\n",
              " 'config': {'architectures': ['PegasusForConditionalGeneration'],\n",
              "  'model_type': 'pegasus',\n",
              "  'tokenizer_config': {}},\n",
              " 'cardData': {'language': 'en', 'tags': ['summarization']},\n",
              " 'transformersInfo': {'auto_model': 'AutoModelForSeq2SeqLM',\n",
              "  'pipeline_tag': 'text2text-generation',\n",
              "  'processor': 'AutoTokenizer'},\n",
              " 'siblings': [{'rfilename': '.gitattributes'},\n",
              "  {'rfilename': 'README.md'},\n",
              "  {'rfilename': 'config.json'},\n",
              "  {'rfilename': 'flax_model.msgpack'},\n",
              "  {'rfilename': 'generation_config.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_aeslc.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_arxiv.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_big_patent.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_billsum.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_cnn_dailymail.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_gigaword.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_large.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_multi_news.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_newsroom.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_pubmed.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_reddit_tifu.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_wikihow.json'},\n",
              "  {'rfilename': 'generation_config_for_summarization_xsum.json'},\n",
              "  {'rfilename': 'pytorch_model.bin'},\n",
              "  {'rfilename': 'special_tokens_map.json'},\n",
              "  {'rfilename': 'spiece.model'},\n",
              "  {'rfilename': 'tf_model.h5'},\n",
              "  {'rfilename': 'tokenizer_config.json'}],\n",
              " 'spaces': ['nickmuchi/article-text-summarizer',\n",
              "  'd0r1h/youtube_summarization',\n",
              "  'awacke1/Video-Summary',\n",
              "  'sasha/CO2_inference',\n",
              "  'Rehman1603/Video-To-Text',\n",
              "  'docs-demos/pegasus_paraphrase',\n",
              "  'awacke1/VideoSummary2',\n",
              "  'khxu/pegasus-text-summarizers',\n",
              "  'imseldrith/AI-Rewriter',\n",
              "  'themanas021/Youtube-Video-Summarizer',\n",
              "  'Preetesh/VideoSummaryfromYouTubeVideo',\n",
              "  'awacke1/VideoSummaryYoutube3',\n",
              "  'jlazoff/biblical-summarizer',\n",
              "  'Myrna/VideoSummary2',\n",
              "  'sidsriv/VideoSummaryfromYoutubeVideo',\n",
              "  'santoshsindham/VideoSummary',\n",
              "  'nkatraga/7.22.VideoSummary2',\n",
              "  'williambr/VideoSummaryGenerator',\n",
              "  'MadhuV28/VideoSumamry',\n",
              "  'rsatish1110/VideoSummaryGenerator',\n",
              "  'vslasor/VLS10-VideoAudioSummarizer-GR',\n",
              "  'Taranosaurus/Classifier',\n",
              "  'chatgptbots/youtube_summarization',\n",
              "  'SamuelMiller/sum_it',\n",
              "  'nehalu/VideoSummaryfromYoutubeVideo',\n",
              "  'uparasha/YTSummary',\n",
              "  'kishorechole/VideoSummaryFromYouTubeVideo',\n",
              "  'jaydeepkum/Videosummary2',\n",
              "  'Chethan003/VideoSummary',\n",
              "  'ayush312/videosummaryfromyoutubevideo123',\n",
              "  'gpai2/VideoSummaryFromYoutubeVideo',\n",
              "  'akashagarwal/VideoSummaryFromYoutube',\n",
              "  'NotSoBad/VideoSummaryfromYoutubevideo',\n",
              "  'palak23/VideoSummaryFromYoutubeVideo',\n",
              "  'PrafulUHG/VideoSummary',\n",
              "  'rajatus231/VideoSummaryFromYoutubeVideo',\n",
              "  'SudarshanaR/VideoSummaryFromYoutubeVideo',\n",
              "  'peekaboo/VideoSummary',\n",
              "  'Vasanthp/VideoSummaryYoutube3',\n",
              "  'ocordes/VideoSummarizer',\n",
              "  'MateusA/VideoSummaryYoutube',\n",
              "  'vnemala/VideoSummaryYoutube',\n",
              "  'mm2593/videosummary',\n",
              "  'vsaripella/VideoSummaryYoutube3',\n",
              "  'MadhuV28/VideoSummary',\n",
              "  'madara-uchiha/YTVideoSummary',\n",
              "  'burhanaminvaid/VideoSummaryFromYoutubeVideo',\n",
              "  'Priyabrata017/VideoSpaceFromYoutube',\n",
              "  'krrishD/google_pegasus-large',\n",
              "  'AIZero2Hero4Health/10-VideoAudioSummary-GR',\n",
              "  'ashishgargcse/VideoAudioSummarizer-GR',\n",
              "  'tkottke/C10-VideoAutoSummery',\n",
              "  'hschlotter/VideoAudioSummarizer_GR',\n",
              "  'jamesjohnson763/VideoAudioSummarizer-GR',\n",
              "  'Robo2000/VideoAudioSummarizer-GR',\n",
              "  'apratap5/Abhay-10-VideoAudioSummarizer-GR',\n",
              "  'alecmueller/11-NLPVideoSummary-GR',\n",
              "  'niks-salodkar/NLP-Demo',\n",
              "  'Quinniboi10/article-text-summarizer',\n",
              "  'varun500/pegasus-test',\n",
              "  'CaptainM/google-pegasus-large',\n",
              "  'aloutzidis/newsum',\n",
              "  'venki21122/text-summarize',\n",
              "  'toeknee432/text-summurization',\n",
              "  'ramanakumark/VideoSummaryYoutube3',\n",
              "  'BilalSardar/yt-video-summarizer',\n",
              "  'Sambhavnoobcoder/yt-script-summariser',\n",
              "  'sushant07/Summary',\n",
              "  'CognitiveScience/Youtube-Video-Summarizer',\n",
              "  'rkf2778/product_review_summarizer_with_roberta_and_pegasus',\n",
              "  'RavdeepA/google-pegasus-large',\n",
              "  'hayanaka/Japanese_summarizer',\n",
              "  'CASLL/YouTubeSummarizerTheEconomistVersion',\n",
              "  'randish/google-pegasus-large'],\n",
              " 'createdAt': '2022-03-02T23:29:05.000Z'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bb5434gEejef"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [model_info ,info]\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emaM6iGJffLw"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLN6dMVtVBxq"
      },
      "outputs": [],
      "source": [
        "df['pipeline_tag'][0] ,df['pipeline_tag'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "753MJdivXHBV"
      },
      "outputs": [],
      "source": [
        "df['tags'][0] ,df['tags'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O84ybUYbYVyw"
      },
      "outputs": [],
      "source": [
        "model_id = 'facebook/maskformer-swin-base-coco'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0CxWR9IXqSL"
      },
      "outputs": [],
      "source": [
        "vision_info = get_model_data(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSrD1v9tYZMf"
      },
      "outputs": [],
      "source": [
        "vision_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6s3J3OjhAwP"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLr3M_hWvczc"
      },
      "outputs": [],
      "source": [
        "# for suggestion\n",
        "\n",
        "# id: The unique identifier for the model. Useful for referencing the model.\n",
        "# modelId: Another identifier, often the same as id, but can sometimes differ.\n",
        "\n",
        "# use for ranking model\n",
        "\n",
        "# downloads: The number of times the model has been downloaded. A high number indicates popularity and trust in the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jFTQvcsoJDu"
      },
      "outputs": [],
      "source": [
        "# for training\n",
        "\n",
        "# pipeline_tag: The primary task that the model is designed for (e.g., 'summarization'). Essential for understanding the model's application.\n",
        "# tags: Keywords and tags that describe the model's features, frameworks it supports (e.g., 'pytorch', 'tf'), and the type of task (e.g., 'summarization', 'text2text-generation'). These help categorize and search for models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oEHOWFcqid0"
      },
      "outputs": [],
      "source": [
        "# for displaying after suggestion\n",
        "\n",
        "# author: The author or organization that created the model. Indicates the credibility and origin of the model.\n",
        "\n",
        "# library_name: The library that the model is compatible with (e.g., 'transformers'). Important for integration into projects.\n",
        "\n",
        "# config: Contains the model's architecture information and tokenizer configuration. Key for understanding the model's structure and compatibility.\n",
        "\n",
        "# cardData: Metadata such as language and license. This includes:\n",
        "    # language: Indicates the language the model is trained on (e.g., 'en' for English).\n",
        "    # license: The licensing information, important for legal usage.\n",
        "\n",
        "# spaces: Lists of community-created spaces and applications that use this model, showcasing practical use cases and integrations.\n",
        "\n",
        "# siblings: Lists related files necessary for the model's operation, like configuration files, tokenizers, and weight files.\n",
        "\n",
        "# transformersInfo: Information about the model's compatibility with specific classes and functions in the Transformers library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T_g6HIDg5JVB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://huggingface.co/models'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "types_of_tasks = []\n",
        "types = soup.find_all('div', class_='mb-3 text-sm font-medium text-gray-500')\n",
        "for typ in types:\n",
        "    types_of_tasks.append(typ.text)\n",
        "\n",
        "tasks_of_model = []\n",
        "tasks = soup.find_all('div', class_='flex flex-wrap')\n",
        "for task in tasks:\n",
        "  for i in task:\n",
        "    tasks_of_model.append(i.text)\n",
        "\n",
        "clean_tasks = [s.strip() for s in tasks_of_model]\n",
        "clean_types = [s.strip() for s in types_of_tasks]\n",
        "\n",
        "clean_tasks = [item.lower().replace(' ', '-') for item in clean_tasks]\n",
        "\n",
        "# group_ranges = [\n",
        "#     (0, 2),    # Multimodal\n",
        "#     (3, 19),   # Computer Vision\n",
        "#     (20, 31),  # Natural Language Processing\n",
        "#     (32, 37),  # Audio\n",
        "#     (38, 40),  # Tabular\n",
        "#     (41, 42),  # Reinforcement Learning\n",
        "#     (43, 43)   # Graph Machine Learning\n",
        "# ]\n",
        "\n",
        "# clean_tasks = [clean_tasks[start:end + 1] for start, end in group_ranges]\n",
        "\n",
        "# types_with_tasks = {clean_types[i]:clean_tasks[i] for i in range(len(clean_types))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Multimodal',\n",
              " 'Computer Vision',\n",
              " 'Natural Language Processing',\n",
              " 'Audio',\n",
              " 'Tabular',\n",
              " 'Reinforcement Learning',\n",
              " 'Other']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HwgXwL1Pnwz"
      },
      "outputs": [],
      "source": [
        "len(model_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nKdxNy0Pj4w"
      },
      "outputs": [],
      "source": [
        "len(models_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uJ457t2QD69"
      },
      "outputs": [],
      "source": [
        "for i in models_data:\n",
        "  print(len(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HP2H0x5PseU"
      },
      "outputs": [],
      "source": [
        "models_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kOIEYJNTCo9B"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Multimodal': ['image-text-to-text',\n",
              "  'visual-question-answering',\n",
              "  'document-question-answering'],\n",
              " 'Computer Vision': ['depth-estimation',\n",
              "  'image-classification',\n",
              "  'object-detection',\n",
              "  'image-segmentation',\n",
              "  'text-to-image',\n",
              "  'image-to-text',\n",
              "  'image-to-image',\n",
              "  'image-to-video',\n",
              "  'unconditional-image-generation',\n",
              "  'video-classification',\n",
              "  'text-to-video',\n",
              "  'zero-shot-image-classification',\n",
              "  'mask-generation',\n",
              "  'zero-shot-object-detection',\n",
              "  'text-to-3d',\n",
              "  'image-to-3d',\n",
              "  'image-feature-extraction'],\n",
              " 'Natural Language Processing': ['text-classification',\n",
              "  'token-classification',\n",
              "  'table-question-answering',\n",
              "  'question-answering',\n",
              "  'zero-shot-classification',\n",
              "  'translation',\n",
              "  'summarization',\n",
              "  'feature-extraction',\n",
              "  'text-generation',\n",
              "  'text2text-generation',\n",
              "  'fill-mask',\n",
              "  'sentence-similarity'],\n",
              " 'Audio': ['text-to-speech',\n",
              "  'text-to-audio',\n",
              "  'automatic-speech-recognition',\n",
              "  'audio-to-audio',\n",
              "  'audio-classification',\n",
              "  'voice-activity-detection'],\n",
              " 'Tabular': ['tabular-classification',\n",
              "  'tabular-regression',\n",
              "  'time-series-forecasting'],\n",
              " 'Reinforcement Learning': ['reinforcement-learning', 'robotics'],\n",
              " 'Other': ['graph-machine-learning']}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "types_with_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('types.pickle','wb') as file:\n",
        "    pickle.dump(clean_types, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('types.pickle','rb') as file:\n",
        "    x = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Multimodal',\n",
              " 'Computer Vision',\n",
              " 'Natural Language Processing',\n",
              " 'Audio',\n",
              " 'Tabular',\n",
              " 'Reinforcement Learning',\n",
              " 'Other']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cgkySCfmLShD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['image-text-to-text',\n",
              "  'visual-question-answering',\n",
              "  'document-question-answering'],\n",
              " ['depth-estimation',\n",
              "  'image-classification',\n",
              "  'object-detection',\n",
              "  'image-segmentation',\n",
              "  'text-to-image',\n",
              "  'image-to-text',\n",
              "  'image-to-image',\n",
              "  'image-to-video',\n",
              "  'unconditional-image-generation',\n",
              "  'video-classification',\n",
              "  'text-to-video',\n",
              "  'zero-shot-image-classification',\n",
              "  'mask-generation',\n",
              "  'zero-shot-object-detection',\n",
              "  'text-to-3d',\n",
              "  'image-to-3d',\n",
              "  'image-feature-extraction'],\n",
              " ['text-classification',\n",
              "  'token-classification',\n",
              "  'table-question-answering',\n",
              "  'question-answering',\n",
              "  'zero-shot-classification',\n",
              "  'translation',\n",
              "  'summarization',\n",
              "  'feature-extraction',\n",
              "  'text-generation',\n",
              "  'text2text-generation',\n",
              "  'fill-mask',\n",
              "  'sentence-similarity'],\n",
              " ['text-to-speech',\n",
              "  'text-to-audio',\n",
              "  'automatic-speech-recognition',\n",
              "  'audio-to-audio',\n",
              "  'audio-classification',\n",
              "  'voice-activity-detection'],\n",
              " ['tabular-classification', 'tabular-regression', 'time-series-forecasting'],\n",
              " ['reinforcement-learning', 'robotics'],\n",
              " ['graph-machine-learning']]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LGv7tHTdwzTs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done for image-text-to-text !\n",
            "Done for visual-question-answering !\n",
            "Done for document-question-answering !\n",
            "Done for depth-estimation !\n",
            "Done for image-classification !\n",
            "Done for object-detection !\n",
            "Done for image-segmentation !\n",
            "Done for text-to-image !\n",
            "Done for image-to-text !\n",
            "Done for image-to-image !\n",
            "Done for image-to-video !\n",
            "Done for unconditional-image-generation !\n",
            "Done for video-classification !\n",
            "Done for text-to-video !\n",
            "Done for zero-shot-image-classification !\n",
            "Done for mask-generation !\n",
            "Done for zero-shot-object-detection !\n",
            "Done for text-to-3d !\n",
            "Done for image-to-3d !\n",
            "Done for image-feature-extraction !\n",
            "Done for text-classification !\n",
            "Done for token-classification !\n",
            "Done for table-question-answering !\n",
            "Done for question-answering !\n",
            "Done for zero-shot-classification !\n",
            "Done for translation !\n",
            "Done for summarization !\n",
            "Done for feature-extraction !\n",
            "Done for text-generation !\n",
            "Done for text2text-generation !\n",
            "Done for fill-mask !\n",
            "Done for sentence-similarity !\n",
            "Done for text-to-speech !\n",
            "Done for text-to-audio !\n",
            "Done for automatic-speech-recognition !\n",
            "Done for audio-to-audio !\n",
            "Done for audio-classification !\n",
            "Done for voice-activity-detection !\n",
            "Done for tabular-classification !\n",
            "Done for tabular-regression !\n",
            "Done for time-series-forecasting !\n",
            "Done for reinforcement-learning !\n",
            "Done for robotics !\n",
            "Done for graph-machine-learning !\n",
            "Done for vikhyatk/moondream2\n",
            "Done for HuggingFaceM4/idefics2-8b\n",
            "Done for Salesforce/xgen-mm-phi3-mini-instruct-r-v1\n",
            "Done for llava-hf/llava-v1.6-mistral-7b-hf\n",
            "Done for HuggingFaceM4/idefics2-8b-chatty\n",
            "Done for 01-ai/Yi-VL-34B\n",
            "Done for deepseek-ai/deepseek-vl-7b-chat\n",
            "Done for liuhaotian/llava-v1.5-7b\n",
            "Done for Salesforce/xgen-mm-phi3-mini-base-r-v1\n",
            "Done for liuhaotian/llava-v1.6-34b\n",
            "Done for liuhaotian/llava-v1.6-vicuna-7b\n",
            "Done for microsoft/llava-med-v1.5-mistral-7b\n",
            "Done for Xenova/moondream2\n",
            "Done for liuhaotian/llava-v1.5-13b\n",
            "Done for liuhaotian/llava-v1.6-mistral-7b\n",
            "Done for bczhou/TinyLLaVA-1.5B\n",
            "Done for xtuner/llava-llama-3-8b-v1_1-transformers\n",
            "Done for gokaygokay/paligemma-rich-captions\n",
            "Done for Lin-Chen/ShareGPT4V-7B\n",
            "Done for 01-ai/Yi-VL-6B\n",
            "Done for cjpais/llava-1.6-mistral-7b-gguf\n",
            "Done for microsoft/udop-large\n",
            "Done for microsoft/udop-large-512-300k\n",
            "Done for HuggingFaceM4/idefics2-8b-base\n",
            "Done for xtuner/llava-llama-3-8b-v1_1\n",
            "Done for lamm-mit/Cephalo-Phi-3-vision-128k-4b-alpha\n",
            "Done for hiyouga/PaliGemma-3B-Chat-v0.1\n",
            "Done for lamm-mit/Cephalo-Idefics-2-vision-8b-beta\n",
            "Done for ucsahin/paligemma-3b-mix-448-ft-TableDetection\n",
            "Done for liuhaotian/llava-v1.5-7b-lora\n",
            "Done for taesiri/llava-videogame-qa-lora-wip\n",
            "Done for liuhaotian/llava-v1.6-vicuna-13b\n",
            "Done for cjpais/llava-v1.6-34B-gguf\n",
            "Done for cmp-nct/llava-1.6-gguf\n",
            "Done for Trelis/llava-v1.6-mistral-7b-PATCHED\n",
            "Done for deepseek-ai/deepseek-vl-1.3b-chat\n",
            "Done for StarCycle/llava-siglip-internlm2-1_8b-v1\n",
            "Done for llava-hf/llava-v1.6-vicuna-7b-hf\n",
            "Done for llava-hf/llava-v1.6-vicuna-13b-hf\n",
            "Done for xtuner/llava-phi-3-mini\n",
            "Done for cjpais/moondream2-llamafile\n",
            "Done for impactframes/ifai_moondream_prompt\n",
            "Done for HuggingFaceM4/idefics2-8b-chatty-AWQ\n",
            "Done for Xenova/nanoLLaVA\n",
            "Done for tinyllava/TinyLLaVA-Phi-2-SigLIP-3.1B\n",
            "Done for mlx-community/paligemma-3b-mix-224-8bit\n",
            "Done for mlx-community/paligemma-3b-mix-448-8bit\n",
            "Done for leo009/paligemma-3b-mix-224\n",
            "Done for RichardLuo/Shotluck-Holmes-1.5\n",
            "Done for Lin-Chen/open-llava-next-vicuna-7b\n",
            "Done for abhi-8/Age-gender-predictor\n",
            "Done for Lin-Chen/open-llava-next-llama3-8b\n",
            "Done for rulins/blip2-t5-llava\n",
            "Done for s3nh/llava-llama-2-13b-chat-lightning-preview-GGML\n",
            "Done for s3nh/Chinese-LLaVA-Baichuan-GGML\n",
            "Done for Lorim/The_WonderMix\n",
            "Done for liuhaotian/llava-v1.5-13b-lora\n",
            "Done for kuyesu22/ll-avatar\n",
            "Done for Frorozcol/LLaVa-instruction-trasaleted\n",
            "Done for Nagase-Kotono/LLaVA_X_KoLlama2-7B-pretrain-0.2v\n",
            "Done for leonardPKU/llava1.5_data\n",
            "Done for MaoXun/llava-lora-7-20-10-5-vicuna-7b-v1.3\n",
            "Done for PsiPi/liuhaotian_llava-v1.5-13b-GGUF\n",
            "Done for ybelkada/test-llava-13b\n",
            "Done for PsiPi/NousResearch_Nous-Hermes-2-Vision-GGUF\n",
            "Done for y10ab1/ggml_llava-v1.5-7b\n",
            "Done for llava-hf/vip-llava-7b-hf\n",
            "Done for xtuner/llava-internlm-7b\n",
            "Done for sshh12/Mistral-7B-LoRA-VisionCLIPPool-LLAVA\n",
            "Done for sshh12/Mistral-7B-LoRA-Multi-VisionCLIPPool-LLAVA\n",
            "Done for xtuner/llava-v1.5-7b-xtuner\n",
            "Done for xtuner/llava-v1.5-13b-xtuner\n",
            "Done for alpindale/llava-1.5-7b\n",
            "Done for power0341/llava-v1_5-mlp2x-336px-qwen1_8b\n",
            "Done for q-future/co-instruct\n",
            "Done for NouRed/Med-LLaVa-QLoRA\n",
            "Done for xtuner/llava-internlm2-7b\n",
            "Done for xtuner/llava-internlm2-20b\n",
            "Done for OEvortex/HelpingAI-Vision\n",
            "Done for StarCycle/llava-dinov2-internlm2-7b-v1\n",
            "Done for paulasquin/ml-mgie\n",
            "Done for antiven0m/llava-v1.5-13b-dpo-gguf\n",
            "Done for MunirAbobaker/Llava\n",
            "Done for granddad/llava-v1.5-7b-gguf\n",
            "Done for singhutkarsh/LLaVA\n",
            "Done for granddad/llava-v1.5-13b-gguf\n",
            "Done for cjpais/llava-v1.6-vicuna-7b-gguf\n",
            "Done for cjpais/llava-v1.6-vicuna-13b-gguf\n",
            "Done for SurfaceData/llava-v1.6-mistral-7b-sglang\n",
            "Done for SurfaceData/llava-v1.6-vicuna-7b-sglang\n",
            "Done for StarCycle/llava-clip-internlm2-1_8b-pretrain-v1\n",
            "Done for StarCycle/llava-clip-internlm2-1_8b-v1\n",
            "Done for yuezih/llava-v1.5-7b-selective-150k\n",
            "Done for yuezih/llava-v1.5-7b-selective-23k\n",
            "Done for ColorfulAI/LSTP-Chat\n",
            "Done for bczhou/TinyLLaVA-2.0B\n",
            "Done for microsoft/udop-large-512\n",
            "Done for DanielClough/Candle_llava-v1.6-mistral-7b\n",
            "Done for megaaziib/Llava-Maid-7B-DPO-GGUF\n",
            "Done for nopperl/clip-ye-pop-llava_caption\n",
            "Done for StarCycle/llava-siglip-internlm2-1_8b-pretrain-v1\n",
            "Done for StarCycle/llava-siglip-internlm2-1_8b-v2\n",
            "Done for StarCycle/llava-siglip-internlm2-1_8b-pretrain-v2\n",
            "Done for Mrwhitmeyer/Quill\n",
            "Done for llava-hf/llava-v1.6-34b-hf\n",
            "Done for Straive/llava-v1.6-34b-hf\n",
            "Done for LeroyDyer/Mixtral_AI_Vision_128k_7b\n",
            "Done for LeroyDyer/Mixtral_AI_Vision_V1_128_7b\n",
            "Done for LeroyDyer/Mixtral_AI_Vision-Instruct_X_7b\n",
            "Done for gokaygokay/moondream-prompt\n",
            "Done for LeroyDyer/Mixtral_AI_CyberVision-Q4_K_M-GGUF\n",
            "Done for Tensoic/Cerule-v0.1\n",
            "Done for codys12/llava-v1.6-mistral-7b-PATCHED\n",
            "Done for LeroyDyer/Mixtral_AI_Cyber_Q_Vision\n",
            "Done for LeroyDyer/Mixtral_AI_MiniTronVision\n",
            "Done for HuggingFaceM4/idefics2-8b-AWQ\n",
            "Done for HuggingFaceM4/idefics2-8b-base-AWQ\n",
            "Done for Syed-Hasan-8503/Idefics2-8B-SFT\n",
            "Done for solidrust/Mixtral_AI_MiniTronVision-AWQ\n",
            "Done for xtuner/llava-llama-3-8b\n",
            "Done for Bessa/llava-llama-3-8b-v1_1-Q4_K_M-GGUF\n",
            "Done for Bessa/llava-llama-3-8b-v1_1-Q5_K_M-GGUF\n",
            "Done for RaincloudAi/llava-llama-3-8b-v1_1-Q4_K_M-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q6_K-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q8_0-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q5_K_M-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q5_K_S-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q5_0-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q4_K_M-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q4_K_S-GGUF\n",
            "Done for djward888/llava-llama-3-8b-v1_1-Q4_0-GGUF\n",
            "Done for openbmb/MiniCPM-Llama3-V-2_5\n",
            "Done for OpenGVLab/InternVL-Chat-V1-5\n",
            "Done for openbmb/MiniCPM-Llama3-V-2_5-int4\n",
            "Done for openbmb/MiniCPM-V-2\n",
            "Done for OpenGVLab/Mini-InternVL-Chat-2B-V1-5\n",
            "Done for CausalLM/Vision-8B-MiniCPM-2_5-Uncensored-and-Detailed\n",
            "Done for qresearch/llama-3-vision-alpha-hf\n",
            "Done for openbmb/MiniCPM-V\n",
            "Done for Salesforce/blip-vqa-base\n",
            "Done for internlm/internlm-xcomposer2-vl-7b\n",
            "Done for OpenGVLab/InternVL-Chat-V1-2-Plus\n",
            "Done for internlm/internlm-xcomposer2-4khd-7b\n",
            "Done for qihoo360/360VL-8B\n",
            "Done for qihoo360/360VL-70B\n",
            "Done for Lin-Chen/sharegpt4video-8b\n",
            "Done for dandelin/vilt-b32-finetuned-vqa\n",
            "Done for Salesforce/blip-vqa-capfilt-large\n",
            "Done for openbmb/OmniLMM-12B\n",
            "Done for OpenGVLab/InternVL-Chat-V1-5-Int8\n",
            "Done for jihadzakki/blip1-medvqa\n",
            "Done for google/deplot\n",
            "Done for ByteDance/shot2story\n",
            "Done for OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-13B\n",
            "Done for OpenGVLab/InternVL-Chat-V1-1\n",
            "Done for OpenGVLab/InternVL-Chat-V1-2\n",
            "Done for weikaih/internvl-v1-5-multigpus\n",
            "Done for failspy/InternVL-Chat-V1-5-quantable\n",
            "Done for azwierzc/vilt-b32-finetuned-vqa-pl\n",
            "Done for Bingsu/temp_vilt_vqa\n",
            "Done for microsoft/git-base-vqav2\n",
            "Done for microsoft/git-base-textvqa\n",
            "Done for tufa15nik/vilt-finetuned-vqasi\n",
            "Done for microsoft/git-large-vqav2\n",
            "Done for microsoft/git-large-textvqa\n",
            "Done for ivelin/donut-refexp-combined-v1\n",
            "Done for sheldonxxxx/OFA_model_weights\n",
            "Done for NhatDFO/sf_blip2\n",
            "Done for ethzanalytics/blip2-flan-t5-xl-sharded\n",
            "Done for google/pix2struct-widget-captioning-large\n",
            "Done for google/pix2struct-ai2d-base\n",
            "Done for icyheat23/blip-fine-tuned-2ep\n",
            "Done for google/pix2struct-chartqa-base\n",
            "Done for google/pix2struct-docvqa-large\n",
            "Done for google/pix2struct-docvqa-base\n",
            "Done for google/pix2struct-widget-captioning-base\n",
            "Done for google/pix2struct-ocrvqa-large\n",
            "Done for google/pix2struct-ocrvqa-base\n",
            "Done for google/pix2struct-ai2d-large\n",
            "Done for google/pix2struct-infographics-vqa-large\n",
            "Done for google/pix2struct-infographics-vqa-base\n",
            "Done for google/pix2struct-screen2words-base\n",
            "Done for google/pix2struct-screen2words-large\n",
            "Done for hf-tiny-model-private/tiny-random-Blip2ForConditionalGeneration\n",
            "Done for hf-tiny-model-private/tiny-random-ViltForQuestionAnswering\n",
            "Done for ayushk4/smol-gpt4\n",
            "Done for google/matcha-chart2text-pew\n",
            "Done for google/matcha-chart2text-statista\n",
            "Done for google/matcha-plotqa-v1\n",
            "Done for google/matcha-plotqa-v2\n",
            "Done for google/matcha-chartqa\n",
            "Done for google/matcha-base\n",
            "Done for main-horse/blip2-pony-test\n",
            "Done for ybelkada/blip2-opt-6.7b-fp16-sharded\n",
            "Done for ybelkada/blip2-opt-2.7b-fp16-sharded\n",
            "Done for JosephusCheung/GuanacoVQA\n",
            "Done for JosephusCheung/GuanacoVQAOnConsumerHardware\n",
            "Done for DAMO-NLP-SG/Video-LLaMA-Series\n",
            "Done for y10ab1/blip-image-captioning-base-football-finetuned\n",
            "Done for nflechas/VQArt\n",
            "Done for nouman-10/vqa_test\n",
            "Done for jasper0314-huang/blip2-opt-2.7b\n",
            "Done for IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1\n",
            "Done for Hellraiser24/vilt-textvqa\n",
            "Done for MBZUAI/Video-ChatGPT-7B\n",
            "Done for vdo/Video-LLaMA-Series\n",
            "Done for Jeney/vilt-b32-finetuned-vqa\n",
            "Done for pleisto/yuren-baichuan-7b\n",
            "Done for csarron/vilt-vqa2-ft\n",
            "Done for csarron/vilt-vqa2-p0.1-r0.3-t0.2-258\n",
            "Done for MohammadAlameenArtan/BLIP_Model_VizWiz\n",
            "Done for Mediocreatmybest/blip2-flan-t5-xxl_8bit\n",
            "Done for Minqin/carets_vqa_finetuned\n",
            "Done for nielsr/blip2-flan-t5-xl\n",
            "Done for mlpc-lab/BLIVA_Vicuna\n",
            "Done for mlpc-lab/BLIVA_FlanT5\n",
            "Done for unni12345/MedBlip2\n",
            "Done for BleachNick/MIC-vit-T5-xl\n",
            "Done for MariaK/vilt_finetuned_100\n",
            "Done for MariaK/vilt_finetuned_200\n",
            "Done for Braulio0316/Bea10\n",
            "Done for Joe99/visionlanguageTransformer\n",
            "Done for JEILDLWLRMA/LHS-git-vqa-fine-tuned\n",
            "Done for MohishKhadse55/majorProject\n",
            "Done for tt1225/vilt-finetuned-vqacp\n",
            "Done for aqachun/vilt_finetuned_200\n",
            "Done for VinayReddyPulyala/graphcorevqa\n",
            "Done for vamsidulam/vqa_graphcore2\n",
            "Done for vamsidulam/graphcorevqa_03\n",
            "Done for next-social/blip2-opt-2.7b-bf16\n",
            "Done for aqachun/Vilt_fine_tune_2000\n",
            "Done for forye/vilt_finetuned_200\n",
            "Done for marcelo-dalmeida/vilt_finetuned_200\n",
            "Done for jiy03150/vilt_finetuned_200\n",
            "Done for Kevin0217/vilt_finetuned_200\n",
            "Done for IDEA-CCNL/Ziya-Visual-14B-Chat\n",
            "Done for jalbrechts/vilt-finetuned-fashion-vqa\n",
            "Done for dineshcr7/med-VQA\n",
            "Done for dineshcr7/med-VQA-1\n",
            "Done for 0xAmey/tinyllava-1.1b-v0.1\n",
            "Done for schubertcarvalho/vilt_finetuned_200\n",
            "Done for yoon6173/vqa_finetuned_ok-vqa\n",
            "Done for yoon6173/git-base-vqa2_finetuning_ok-vqa_epoch-30_batch-8\n",
            "Done for yoon6173/git-base-vqa2_finetuning_clevr_epoch-30_batch-8\n",
            "Done for yoon6173/git-base-vqa2_finetuning_clevr_epoch-20_batch-8\n",
            "Done for dineshcr7/Type_MediVQA\n",
            "Done for io-roboto/vilt_finetuned_200\n",
            "Done for dineshcr7/MediVQA\n",
            "Done for io-roboto/vilt_finetuned_10000\n",
            "Done for io-roboto/vilt_finetuned_100000\n",
            "Done for micanal/vilt_finetuned_100000\n",
            "Done for yuliano/saleCoPilot\n",
            "Done for jaimik69/blip_finetuned\n",
            "Done for Atul8827/vilt_finetuned_200\n",
            "Done for dineshcr7/BLIP-LORA-TRY\n",
            "Done for dineshcr7/Final-BLIP-LORA\n",
            "Done for nanom/pix2struct-vizwizvqa-base\n",
            "Done for DylanJHJ/blip-base-129M\n",
            "Done for ChirathD/Blip-2-test-1\n",
            "Done for ChirathD/Blip-2-test-2\n",
            "Done for ChirathD/Blip-2-test-3\n",
            "Done for rkushwah16/vilt_finetuned_200\n",
            "Done for xtuner/llava-internlm-7b-pretrain\n",
            "Done for xtuner/llava-v1.5-7b-xtuner-pretrain\n",
            "Done for aisuko/ft-vilt-b32-mlm\n",
            "Done for nuua/ko-deplot\n",
            "Done for xtuner/llava-v1.5-13b-xtuner-pretrain\n",
            "Done for OpenGVLab/InternVL-Chat-ViT-6B-Vicuna-7B\n",
            "Done for unum-cloud/uform-gen-chat\n",
            "Done for SeanForHim/KoBEiT3\n",
            "Done for wesley7137/BlipFinetune-ScienceQA\n",
            "Done for NouRed/Med-BLIP-2-QLoRA\n",
            "Done for marwanimroz18/blip-trainer\n",
            "Done for xtuner/llava-internlm2-7b-pretrain\n",
            "Done for xtuner/llava-internlm2-20b-pretrain\n",
            "Done for TeeA/MATCHA-ViChart\n",
            "Done for TeeA/DONUT-ViChart\n",
            "Done for TeeA/MATCHA-ChartQA-v1\n",
            "Done for RaviNaik/Llava-Phi2\n",
            "Done for GunaKoppula/Llava-Phi2\n",
            "Done for impira/layoutlm-document-qa\n",
            "Done for impira/layoutlm-invoices\n",
            "Done for jinhybr/OCR-DocVQA-Donut\n",
            "Done for naver-clova-ix/donut-base-finetuned-docvqa\n",
            "Done for Or4cl3-1/multimodal-fusion-optimized\n",
            "Done for frizwankhan/entity-linking-model-final\n",
            "Done for tiennvcs/layoutlmv2-base-uncased-finetuned-docvqa\n",
            "Done for tiennvcs/layoutlmv2-base-uncased-finetuned-infovqa\n",
            "Done for tiennvcs/layoutlmv2-base-uncased-finetuned-vi-infovqa\n",
            "Done for tiennvcs/layoutlmv2-large-uncased-finetuned-infovqa\n",
            "Done for tiennvcs/layoutlmv2-large-uncased-finetuned-vi-infovqa\n",
            "Done for mishig/temp-model\n",
            "Done for xhyi/layoutlmv3_docvqa_t11c5000\n",
            "Done for pardeepSF/layoutlm-vqa\n",
            "Done for faisalraza/layoutlm-invoices\n",
            "Done for davanstrien/testwebhook\n",
            "Done for MariaK/layoutlmv2-base-uncased_finetuned_docvqa_v2\n",
            "Done for rubentito/layoutlmv3-base-mpdocvqa\n",
            "Done for cloudqi/CQI_Visual_Question_Awnser_PT_v0\n",
            "Done for hf-tiny-model-private/tiny-random-LayoutLMForQuestionAnswering\n",
            "Done for hf-tiny-model-private/tiny-random-LayoutLMv3ForQuestionAnswering\n",
            "Done for hugginglaoda/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Sayantan1993/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for ytiriyar/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for eachadea/ggml-vicuna-13b-1.1\n",
            "Done for dperales/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for stevevu/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for liuliu96/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for PrplHrt/LayoutLMv2_hub\n",
            "Done for PrplHrt/LayoutLMv2_hub_500\n",
            "Done for sofa566/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for sarveediwan/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Itpace/lmlayout-enesfr-invoices\n",
            "Done for HEN10/layoutlmv2_Kb_qa04\n",
            "Done for padalavinaybhushan/VinayParser\n",
            "Done for fxmarty/tiny-doc-qa-vision-encoder-decoder\n",
            "Done for magorshunov/layoutlm-invoices\n",
            "Done for magorshunov/layoutlm-document-qa\n",
            "Done for fimu-docproc-research/CIVQA_layoutXLM_model\n",
            "Done for aavash/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for madiltalay/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for JacobHenry/Pleasantnoise\n",
            "Done for elfard/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for PledgeVentures/COSMO\n",
            "Done for yeojinkim05/impira-layoutlm-invoices\n",
            "Done for yeojinkim05/layoutlm-docqa\n",
            "Done for Shwetang270899/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for arao02/Llama\n",
            "Done for prajwalJumde/LayoutLM_test_docvqa\n",
            "Done for prajwalJumde/my-awesome-model\n",
            "Done for am-infoweb/layout-test_model\n",
            "Done for am-infoweb/layoutlmv2-finetuned_docvqa\n",
            "Done for Xenova/donut-base-finetuned-docvqa\n",
            "Done for am-infoweb/layoutlmv3-finetuned_docvqa\n",
            "Done for enricmoreu/invoice\n",
            "Done for TusharGoel/LayoutLM-Finetuned-DocVQA\n",
            "Done for vfu/trained_model\n",
            "Done for vfu/ccc_doc_vqa_test\n",
            "Done for Dhineshk/TestDocumentQuestionAnswering\n",
            "Done for AyushPremjith/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for TusharGoel/LayoutLMv2-finetuned-docvqa\n",
            "Done for loroxiv/docvqa-test\n",
            "Done for jiy03150/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Dhineshk/TekclanDocumentKeyInfo\n",
            "Done for pinkthepink/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for TusharGoel/LiLT-Document-QA\n",
            "Done for AprilLim/layoutlmv2-base-uncased-finetuned-test\n",
            "Done for beneor/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Mikhail1313/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for paru4ik/content\n",
            "Done for sutejawe1/v1\n",
            "Done for Dhineshk/DocumentQuestionAnsweringV2\n",
            "Done for paru4ik/model\n",
            "Done for jonathanjordan21/donut_fine_tuning_food_composition_id\n",
            "Done for StKirill/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for AlexSaz/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for zibajoon/20231101_layoutlm2_1.2k_3ep_Doc_A\n",
            "Done for StKirill/layoutlmv2-base-uncased_finetuned_docvqa_v2\n",
            "Done for zibajoon/20231102_layoutlm2_1.2k_3ep_Doc_B\n",
            "Done for sDenisov3/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for zibajoon/20231108_layoutlm2_5k_3ep_Doc_NA_B\n",
            "Done for greatakela/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for sDenisov3/model_ver_9\n",
            "Done for pivthegreat/DocVQA\n",
            "Done for pivovalera2012/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for lizalmazova/HW3\n",
            "Done for vik-pups/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for VesleAnne/VesleAnne\n",
            "Done for Nefertury/test_test_42\n",
            "Done for AlinaKozyreva/HW3_1\n",
            "Done for AlinaKozyreva/AlinaKozyreva\n",
            "Done for AlinaKozyreva/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for pooh/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for maximvb/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for iliabel/HW3\n",
            "Done for iliabel/iliabel_HW3\n",
            "Done for damir-hi/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Dhineshk/TekDocumentQuestionAnswering_V3\n",
            "Done for yourComplete/HW3\n",
            "Done for zibajoon/20231108_layoutlm2_5k_3ep_Doc_NA\n",
            "Done for zibajoon/20231109_layoutlm2_5k_20ep_Doc_NA\n",
            "Done for CarlBrendt/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for vlipovoy/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Nobilis/pokemon-lora\n",
            "Done for zibajoon/20231113_DocVQA_laytlm_1ep_full50k_Doc_NA\n",
            "Done for zibajoon/20231114_DocVQA_laytlm_2ep_full50k_Doc_NA\n",
            "Done for vvkropochev/hw3_1\n",
            "Done for Volodiy/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Nobilis/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for yinhang945/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for PrimWong/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for PrimWong/layoutlm_qa\n",
            "Done for SantiagoPG/DOC_QA\n",
            "Done for yuanzheng625/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for PrimWong/layout_lmqa2\n",
            "Done for PrimWong/layout_qa_hparam_tuning\n",
            "Done for Anise1006/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Sharka/CIVQA_LayoutXLM\n",
            "Done for Sharka/CIVQA_LayoutLMv2\n",
            "Done for Sharka/CIVQA_LayoutLMv3\n",
            "Done for Sharka/CIVQA_LayoutXLM_EasyOCR\n",
            "Done for Sharka/CIVQA_LayoutLMv2_EasyOCR\n",
            "Done for Sharka/CIVQA_LayoutLMv3_EasyOCR\n",
            "Done for Sharka/CIVQA_Impira_QA_EasyOCR\n",
            "Done for Sharka/CIVQA_Impira_I_EasyOCR\n",
            "Done for Sharka/CIVQA_Impira_QA\n",
            "Done for Sharka/CIVQA_Impira_I\n",
            "Done for Tejagoud/sampe_docqa_layoutlmv3-base\n",
            "Done for aslessor/layoutlm-invoices\n",
            "Done for Tejagoud/sampel2_docqa_layoutlmv3-base\n",
            "Done for RamzesIII/llmv2-docvqa-finetuned\n",
            "Done for shurik-p/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Estasss/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for shurik-p/llmv2-docvqa-finetuned\n",
            "Done for Sharka/CIVQA_DVQA_LayoutXLM\n",
            "Done for Sharka/CIVQA_DVQA_LayoutLMv3\n",
            "Done for cehkop/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Barth371/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Sharka/CIVQA_DVQA_LayoutLMv2\n",
            "Done for Sharka/CIVQA_DVQA_Impira_QA\n",
            "Done for tatva-root/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Autumn3011/7februaryNW\n",
            "Done for Mariya21/layoutlmv2-base-uncased_finetuned_docvqa\n",
            "Done for Smoket/llmv2_base_finetuned_docvqa\n",
            "Done for warshakhan/LayoutLMv2-docvqa\n",
            "Done for Tejagoud/bardydatasample_model\n",
            "Done for kanansharmaa/layoutlm_document_qa\n",
            "Done for prs-eth/marigold-v1-0\n",
            "Done for Intel/dpt-large\n",
            "Done for LiheYoung/depth-anything-small-hf\n",
            "Done for LiheYoung/depth-anything-large-hf\n",
            "Done for prs-eth/marigold-lcm-v1-0\n",
            "Done for unity/sentis-MiDaS\n",
            "Done for ChristianOrr/madnet_keras\n",
            "Done for vinvino02/glpn-kitti\n",
            "Done for vinvino02/glpn-nyu\n",
            "Done for nielsr/dpt-large-redesign\n",
            "Done for Intel/dpt-hybrid-midas\n",
            "Done for SamKenX-Hub-Community/SamKenXAI-engine-compiting\n",
            "Done for hf-tiny-model-private/tiny-random-DPTForDepthEstimation\n",
            "Done for hf-tiny-model-private/tiny-random-GLPNForDepthEstimation\n",
            "Done for ibaiGorordo/lap-depth-kitti\n",
            "Done for ibaiGorordo/lap-depth-kitti-grad\n",
            "Done for ibaiGorordo/lap-depth-nyu\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230530-193901\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230530-195017\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230530-195824\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230530-200638\n",
            "Done for Onegafer/glpn-nyu-finetuned\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230530-204740\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230531-145730\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230603-090019\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230603-090701\n",
            "Done for caicai0205/8888800\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230603-091354\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230603-093449\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230603-100738\n",
            "Done for Onegafer/glpn-nyu-finetuned-diode-230603-102021\n",
            "Done for tplove2010/test001\n",
            "Done for justinsoberano/rock-depth-ai\n",
            "Done for justinsoberano/depth-ai\n",
            "Done for Cr4yfish/zipnerf\n",
            "Done for jzhangbs/dpt-hybrid-omnidata-normal\n",
            "Done for nielsr/dpt-dinov2-small-nyu\n",
            "Done for a6047425318/room-3d-scene-estimation\n",
            "Done for facebook/dpt-dinov2-small-nyu\n",
            "Done for facebook/dpt-dinov2-small-kitti\n",
            "Done for facebook/dpt-dinov2-base-kitti\n",
            "Done for facebook/dpt-dinov2-base-nyu\n",
            "Done for facebook/dpt-dinov2-large-nyu\n",
            "Done for facebook/dpt-dinov2-large-kitti\n",
            "Done for facebook/dpt-dinov2-giant-nyu\n",
            "Done for facebook/dpt-dinov2-giant-kitti\n",
            "Done for Xenova/glpn-kitti\n",
            "Done for Xenova/glpn-nyu\n",
            "Done for Xenova/dpt-hybrid-midas\n",
            "Done for Xenova/dpt-large\n",
            "Done for Intel/dpt-beit-large-512\n",
            "Done for Intel/dpt-beit-large-384\n",
            "Done for Intel/dpt-beit-base-384\n",
            "Done for Intel/dpt-swinv2-base-384\n",
            "Done for Intel/dpt-swinv2-tiny-256\n",
            "Done for Intel/dpt-swinv2-large-384\n",
            "Done for julienkay/sentis-MiDaS\n",
            "Done for LiheYoung/depth-anything-base-hf\n",
            "Done for LiheYoung/depth_anything_vits14\n",
            "Done for LiheYoung/depth_anything_vitb14\n",
            "Done for LiheYoung/depth_anything_vitl14\n",
            "Done for Xenova/depth-anything-small-hf\n",
            "Done for Xenova/depth-anything-base-hf\n",
            "Done for Xenova/depth-anything-large-hf\n",
            "Done for a414166402/DepthSmall\n",
            "Done for halimb/depth-anything-small-hf\n",
            "Done for halimb/depth-anything-large-hf\n",
            "Done for qualcomm/TrOCR\n",
            "Done for julienkay/Marigold\n",
            "Done for cyuer/new_test_model\n",
            "Done for Saqlaintaswar1/safespace\n",
            "Done for zachL1/Metric3D\n",
            "Done for EddieT/DepthAnything_v0.3.1\n",
            "Done for nagayama0706/natural_science_model\n",
            "Done for nagayama0706/security_model\n",
            "Done for Intel/zoedepth-nyu\n",
            "Done for Intel/zoedepth-kitti\n",
            "Done for Intel/zoedepth-nyu-kitti\n",
            "Done for Hopper1394/RoadRoBillionaire\n",
            "Done for Falconsai/nsfw_image_detection\n",
            "Done for google/vit-base-patch16-224\n",
            "Done for microsoft/resnet-50\n",
            "Done for porntech/sex-position\n",
            "Done for dima806/face_obstruction_image_detection\n",
            "Done for facebook/deit-small-patch16-224\n",
            "Done for cafeai/cafe_aesthetic\n",
            "Done for dima806/bird_species_image_detection\n",
            "Done for dima806/facial_age_image_detection\n",
            "Done for dima806/smoker_image_classification\n",
            "Done for shadowlilac/aesthetic-shadow-v2\n",
            "Done for dima806/skin_types_image_detection\n",
            "Done for qualcomm/MediaPipe-Pose-Estimation\n",
            "Done for vm24/net_dfm_myimg\n",
            "Done for microsoft/beit-base-patch16-224-pt22k-ft22k\n",
            "Done for nateraw/food\n",
            "Done for nateraw/vit-base-beans\n",
            "Done for nvidia/mit-b5\n",
            "Done for microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\n",
            "Done for umm-maybe/AI-image-detector\n",
            "Done for trpakov/vit-face-expression\n",
            "Done for timm/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k\n",
            "Done for timm/efficientnet_b3.ra2_in1k\n",
            "Done for timm/mobilenetv3_large_100.ra_in1k\n",
            "Done for timm/vit_base_patch16_224.augreg2_in21k_ft_in1k\n",
            "Done for EdBianchi/vit-fire-detection\n",
            "Done for torchgeo/resnet50_sentinel2_rgb_moco\n",
            "Done for keremberke/yolov8m-painting-classification\n",
            "Done for Kaludi/food-category-classification-v2.0\n",
            "Done for facebook/convnextv2-atto-1k-224\n",
            "Done for facebook/convnextv2-tiny-1k-224\n",
            "Done for edadaltocg/resnet18_cifar10\n",
            "Done for timm/resnet18.a1_in1k\n",
            "Done for cledoux42/Ethnicity_Test_v003\n",
            "Done for cledoux42/Age_Classify_v001\n",
            "Done for ThanHitt/FishTreeRock_Classifier_v1\n",
            "Done for Xenova/quickdraw-mobilevit-small\n",
            "Done for dima806/brain_tumor_detection\n",
            "Done for dima806/rice_type_detection\n",
            "Done for dima806/fruits_type_detection\n",
            "Done for dima806/pets_facial_expression_detection\n",
            "Done for dima806/butterfly_moth_species_detection\n",
            "Done for dima806/dogs_cats_image_detection\n",
            "Done for dima806/fruit_vegetable_image_detection\n",
            "Done for dima806/sea_animals_image_detection\n",
            "Done for dima806/gemstones_image_detection\n",
            "Done for dima806/galaxy_type_image_detection\n",
            "Done for dima806/footwear_image_detection\n",
            "Done for dima806/dogs_70_breeds_image_detection\n",
            "Done for dima806/diamond_types_image_detection\n",
            "Done for dima806/67_cat_breeds_image_detection\n",
            "Done for facebook/dinov2-base-imagenet1k-1-layer\n",
            "Done for dima806/food_type_image_detection_new\n",
            "Done for dima806/car_brand_image_detection\n",
            "Done for dima806/fast_food_image_detection\n",
            "Done for dima806/portuguese_meals_image_detection\n",
            "Done for dima806/coffee_bean_roast_image_detection\n",
            "Done for dima806/flowers_16_types_image_detection\n",
            "Done for dima806/marvel_heroes_image_detection\n",
            "Done for dima806/horse_breeds_image_detection\n",
            "Done for dima806/tesla_car_model_image_detection\n",
            "Done for dima806/pokemon_types_image_detection\n",
            "Done for dima806/lemon_quality_image_detection\n",
            "Done for dima806/top_15_anime_characters_image_detection\n",
            "Done for dima806/ball_types_image_detection\n",
            "Done for dima806/shoe_types_image_detection\n",
            "Done for dima806/buscuit_wrappers_image_detection\n",
            "Done for dima806/beard_face_image_detection\n",
            "Done for dima806/food_beverages_japan_image_detection\n",
            "Done for dima806/tyre_quality_image_detection\n",
            "Done for dima806/full_flat_tyre_image_detection\n",
            "Done for dima806/headgear_image_detection\n",
            "Done for dima806/wild_cats_image_detection\n",
            "Done for dima806/deepfake_vs_real_image_detection\n",
            "Done for dima806/faces_age_detection\n",
            "Done for dima806/farm_insects_image_detection\n",
            "Done for dima806/jellyfish_types_image_detection\n",
            "Done for dima806/215_mushroom_types_image_detection\n",
            "Done for dima806/pneumonia_chest_xray_image_detection\n",
            "Done for dima806/30_plant_types_image_detection\n",
            "Done for dima806/14_flower_types_image_detection\n",
            "Done for dima806/75_butterfly_types_image_detection\n",
            "Done for dima806/10_ship_types_image_detection\n",
            "Done for dima806/weather_types_image_detection\n",
            "Done for dima806/100_butterfly_types_image_detection\n",
            "Done for dima806/wildfire_types_image_detection\n",
            "Done for dima806/fruit_100_types_image_detection\n",
            "Done for dima806/vehicle_10_types_image_detection\n",
            "Done for dima806/celebs_face_image_detection\n",
            "Done for dima806/mammals_45_types_image_classification\n",
            "Done for dima806/card_type_image_detection\n",
            "Done for dima806/animal_151_types_image_detection\n",
            "Done for beingamit99/car_damage_detection\n",
            "Done for metadome/face_shape_classification\n",
            "Done for imatag/stable-signature-bzh-detector-resnet18\n",
            "Done for ares1123/photo_age_detection\n",
            "Done for lokeshk/Face-Recognition-NM\n",
            "Done for timm/nextvit_base.bd_ssld_6m_in1k_384\n",
            "Done for dcarpintero/fastai-interstellar-class\n",
            "Done for prithivMLmods/Deep-Fake-Detector-Model\n",
            "Done for MahmoudWSegni/swin-tiny-patch4-window7-224-finetuned-face-emotion-v12_right\n",
            "Done for NYUAD-ComNets/AI-generated_images_detector\n",
            "Done for dima806/traffic_sign_detection\n",
            "Done for ilyesdjerfaf/vit-base-patch16-224-in21k-quickdraw\n",
            "Done for MITLL/LADI-v2-classifier-small\n",
            "Done for ilsilfverskiold/traffic-levels-image-classification\n",
            "Done for glazzova/body_type\n",
            "Done for Robys01/facial_age_estimator\n",
            "Done for vuongnhathien/SwinV2-30VNFood\n",
            "Done for vuongnhathien/SwinV2-Base-30VN-Food\n",
            "Done for ahmedesmail16/Train-Test-Augmentation-NO-UPNormal-swinv2-base\n",
            "Done for vuongnhathien/Vit-Base-30VN\n",
            "Done for vuongnhathien/Resnet152-30VN\n",
            "Done for timm/vit_medium_patch16_reg4_gap_256.sbb_in12k\n",
            "Done for timm/vit_medium_patch16_reg4_gap_256.sbb_in12k_ft_in1k\n",
            "Done for vuongnhathien/ConvnextV2-tiny\n",
            "Done for vuongnhathien/deit-base\n",
            "Done for vuongnhathien/vit-base-change-arg\n",
            "Done for vuongnhathien/vit-base-5e-4\n",
            "Done for vuongnhathien/vit-base-add-2-decay\n",
            "Done for vuongnhathien/vit-base-org-plot\n",
            "Done for vuongnhathien/vit-base-25ep\n",
            "Done for vuongnhathien/convnext-nano\n",
            "Done for vuongnhathien/vit-base-batch-32\n",
            "Done for vuongnhathien/convnext-nano-15ep\n",
            "Done for vuongnhathien/convnext-nano-20ep\n",
            "Done for vuongnhathien/convnext-nano-5ep-batch-32\n",
            "Done for vuongnhathien/vit-base-seed-3e-4\n",
            "Done for vuongnhathien/vit-base-seed-1e-4\n",
            "Done for vuongnhathien/vit-base-1e-4-15ep\n",
            "Done for vuongnhathien/convnext-nano-1e-4\n",
            "Done for vuongnhathien/vit-base-1e-4-20ep\n",
            "Done for Augusto777/vit-base-patch16-224-U8-10b\n",
            "Done for Augusto777/vit-base-patch16-224-U8-40b\n",
            "Done for emaballarin/CARSO-CNN\n",
            "Done for vuongnhathien/convnext-base\n",
            "Done for Ab0/foo-model\n",
            "Done for Aftabhussain/Tomato_Leaf_Classifier\n",
            "Done for AkshatSurolia/BEiT-FaceMask-Finetuned\n",
            "Done for AkshatSurolia/ConvNeXt-FaceMask-Finetuned\n",
            "Done for AkshatSurolia/DeiT-FaceMask-Finetuned\n",
            "Done for AkshatSurolia/ViT-FaceMask-Finetuned\n",
            "Done for Amrrs/indian-foods\n",
            "Done for Amrrs/south-indian-foods\n",
            "Done for Francesco/resnet101-224-1k\n",
            "Done for Francesco/resnet101\n",
            "Done for Francesco/resnet152-224-1k\n",
            "Done for Francesco/resnet152\n",
            "Done for Francesco/resnet18-224-1k\n",
            "Done for kadirnar/Yolov10\n",
            "Done for facebook/detr-resnet-50\n",
            "Done for onnx-community/yolov10s\n",
            "Done for kittendev/YOLOv8m-smoke-detection\n",
            "Done for microsoft/table-transformer-detection\n",
            "Done for foduucom/stockmarket-future-prediction\n",
            "Done for keremberke/yolov8m-table-extraction\n",
            "Done for turhancan97/yolov5-obb-trash-detection\n",
            "Done for microsoft/table-transformer-structure-recognition-v1.1-all\n",
            "Done for Ultralytics/YOLOv8\n",
            "Done for onnx-community/yolov10n\n",
            "Done for onnx-community/yolov10x\n",
            "Done for facebook/detr-resnet-101\n",
            "Done for microsoft/table-transformer-structure-recognition\n",
            "Done for keremberke/yolov5m-license-plate\n",
            "Done for aditmohan96/detr-finetuned-face\n",
            "Done for turhancan97/yolov5-detect-trash-classification\n",
            "Done for pitangent-ds/YOLOv8-human-detection-thermal\n",
            "Done for arnabdhar/YOLOv8-Face-Detection\n",
            "Done for jags/yolov8_model_segmentation-set\n",
            "Done for qfisch/yolov8n-watermark-detection\n",
            "Done for unity/sentis-hand-landmark\n",
            "Done for Oblix/yolov8x-doclaynet_ONNX\n",
            "Done for onnx-community/YOLOv10\n",
            "Done for onnx-community/yolov10b\n",
            "Done for onnx-community/yolov10m\n",
            "Done for onnx-community/yolov10l\n",
            "Done for Riser/YOLOP\n",
            "Done for SamMorgan/yolo_v4_tflite\n",
            "Done for akhaliq/YOLOP\n",
            "Done for aychang/fasterrcnn-resnet50-cpu\n",
            "Done for davanstrien/detr_beyond_words\n",
            "Done for facebook/detr-resnet-101-dc5\n",
            "Done for facebook/detr-resnet-50-dc5\n",
            "Done for merve/model-card-example\n",
            "Done for mindee/fasterrcnn_mobilenet_v3_large_fpn\n",
            "Done for nateraw/hot-dog\n",
            "Done for SenseTime/deformable-detr-single-scale-dc5\n",
            "Done for SenseTime/deformable-detr-single-scale\n",
            "Done for SenseTime/deformable-detr-with-box-refine-two-stage\n",
            "Done for SenseTime/deformable-detr-with-box-refine\n",
            "Done for SenseTime/deformable-detr\n",
            "Done for nielsr/detr-resnet-50-new\n",
            "Done for zuppif/maskformer-swin-small-ade\n",
            "Done for TahaDouaji/detr-doc-table-detection\n",
            "Done for drab/distribution-equipment-belgium\n",
            "Done for hustvl/yolos-tiny\n",
            "Done for hustvl/yolos-base\n",
            "Done for hustvl/yolos-small\n",
            "Done for hustvl/yolos-small-dwr\n",
            "Done for hustvl/yolos-small-300\n",
            "Done for gary109/STAS_yolos-small\n",
            "Done for gary109/STAS_yolos-base\n",
            "Done for gary109/STAS_detr-resnet-50\n",
            "Done for Jackett/detr_test\n",
            "Done for keras-io/Object-Detection-RetinaNet\n",
            "Done for danieladejumo/darknet-coco-object_detection\n",
            "Done for johko/wideresnet28-2-mnist\n",
            "Done for nickmuchi/yolos-small-finetuned-masks\n",
            "Done for nickmuchi/yolos-base-finetuned-masks\n",
            "Done for mhyatt000/YOLOv5\n",
            "Done for nickmuchi/yolos-small-rego-plates-detection\n",
            "Done for nateraw/yolov6n\n",
            "Done for nateraw/yolov6s\n",
            "Done for nateraw/yolov6t\n",
            "Done for NimaBoscarino/unicorn_track_tiny_rt_mask\n",
            "Done for adit94/question_roi\n",
            "Done for biglam/detr-resnet-50_fine_tuned_nls_chapbooks\n",
            "Done for NimaBoscarino/unicorn_track_large_mask\n",
            "Done for NimaBoscarino/unicorn_track_tiny_mask\n",
            "Done for NimaBoscarino/unicorn_track_r50_mask\n",
            "Done for NimaBoscarino/unicorn_track_large_mot_challenge_mask\n",
            "Done for nickmuchi/yolos-small-finetuned-license-plate-detection\n",
            "Done for nickmuchi/detr-resnet50-finetuned-license-plate-detection\n",
            "Done for nickmuchi/detr-resnet50-license-plate-detection\n",
            "Done for adit94/dit_test\n",
            "Done for nielsr/detr-table-detection\n",
            "Done for nielsr/detr-table-structure-recognition\n",
            "Done for microsoft/conditional-detr-resnet-50\n",
            "Done for SalML/DETR-table-detection\n",
            "Done for zack01/detr_pubtable\n",
            "Done for SalML/DETR-table-structure-recognition\n",
            "Done for napatswift/paliament-vote-table-detection\n",
            "Done for napatswift/paliament-vote-table-column-detection\n",
            "Done for zchflyer/test1\n",
            "Done for nielsr/table-transformer-detection\n",
            "Done for zoheb/yolos-small-balloon\n",
            "Done for hussamturjman/epic-kitchen-55-detr-resnet-50\n",
            "Done for hussamturjman/epic-detr-latest\n",
            "Done for nickmuchi/yolos-small-plant-disease-detection\n",
            "Done for Narsil/layoutlm-funsd\n",
            "Done for valentinafeve/yolos-fashionpedia\n",
            "Done for Rahul-2022/detr-base-sroie\n",
            "Done for fcakyon/mmdet-yolox-tiny\n",
            "Done for davanstrien/detr-resnet-50_fine_tuned_trade_dir\n",
            "Done for Sembiance/detr-resnet-101-fixed\n",
            "Done for fcakyon/yolov5n-v7.0\n",
            "Done for fcakyon/yolov5s-v7.0\n",
            "Done for Narsil/layoutlmv3-finetuned-funsd\n",
            "Done for Narsil/layoutlmv2-finetuned-funsd\n",
            "Done for nielsr/deta-swin-large\n",
            "Done for kadirnar/yolov7-v0.1\n",
            "Done for kadirnar/yolov7-tiny-v0.1\n",
            "Done for kadirnar/yolov6n-v3.0\n",
            "Done for kadirnar/yolov6s-v3.0\n",
            "Done for kadirnar/yolov6m-v3.0\n",
            "Done for nielsr/deta-resnet-50\n",
            "Done for jozhang97/deta-resnet-50\n",
            "Done for kadirnar/yolox_s-v0.1.1\n",
            "Done for kadirnar/yolox_tiny-v0.1.1\n",
            "Done for kadirnar/yolox_nano-v0.1.1\n",
            "Done for kadirnar/yolox_m-v0.1.1\n",
            "Done for kadirnar/yolox_l-v0.1.1\n",
            "Done for kadirnar/yolox_x-v0.1.1\n",
            "Done for liaujianjie/detr-resnet-50\n",
            "Done for keremberke/yolov5n-valorant\n",
            "Done for keremberke/yolov5s-valorant\n",
            "Done for keremberke/yolov5m-valorant\n",
            "Done for keremberke/yolov5n-football\n",
            "Done for keremberke/yolov5s-football\n",
            "Done for keremberke/yolov5m-football\n",
            "Done for keremberke/yolov5n-csgo\n",
            "Done for keremberke/yolov5s-csgo\n",
            "Done for keremberke/yolov5m-csgo\n",
            "Done for keremberke/yolov5n-construction-safety\n",
            "Done for keremberke/yolov5s-construction-safety\n",
            "Done for keremberke/yolov5m-construction-safety\n",
            "Done for keremberke/yolov5n-clash-of-clans\n",
            "Done for keremberke/yolov5s-clash-of-clans\n",
            "Done for keremberke/yolov5m-clash-of-clans\n",
            "Done for keremberke/yolov5n-nfl\n",
            "Done for keremberke/yolov5s-nfl\n",
            "Done for keremberke/yolov5m-nfl\n",
            "Done for keremberke/yolov5n-blood-cell\n",
            "Done for keremberke/yolov5s-blood-cell\n",
            "Done for keremberke/yolov5m-blood-cell\n",
            "Done for keremberke/yolov5n-license-plate\n",
            "Done for keremberke/yolov5s-license-plate\n",
            "Done for keremberke/yolov5n-forklift\n",
            "Done for keremberke/yolov5s-forklift\n",
            "Done for keremberke/yolov5m-forklift\n",
            "Done for keremberke/yolov5n-smoke\n",
            "Done for keremberke/yolov5s-smoke\n",
            "Done for keremberke/yolov5m-smoke\n",
            "Done for keremberke/yolov5n-aerial-sheep\n",
            "Done for keremberke/yolov5s-aerial-sheep\n",
            "Done for keremberke/yolov5m-aerial-sheep\n",
            "Done for keremberke/yolov5n-garbage\n",
            "Done for keremberke/yolov5s-garbage\n",
            "Done for briaai/RMBG-1.4\n",
            "Done for mattmdjaga/segformer_b2_clothes\n",
            "Done for nvidia/segformer-b0-finetuned-ade-512-512\n",
            "Done for qualcomm/FastSam-X\n",
            "Done for qualcomm/FFNet-40S\n",
            "Done for facebook/maskformer-swin-base-coco\n",
            "Done for facebook/maskformer-swin-large-ade\n",
            "Done for CIDAS/clipseg-rd64-refined\n",
            "Done for facebook/mask2former-swin-large-coco-instance\n",
            "Done for facebook/mask2former-swin-large-ade-panoptic\n",
            "Done for matei-dorian/segformer-b5-finetuned-human-parsing\n",
            "Done for Riksarkivet/rtmdet_lines\n",
            "Done for qualcomm/Segment-Anything-Model\n",
            "Done for sayeed99/segformer-b2-fashion\n",
            "Done for wide-video/rmbg-v1.0.0\n",
            "Done for OwlMaster/FixRM\n",
            "Done for Narsil/pet-segmentation\n",
            "Done for facebook/detr-resnet-101-panoptic\n",
            "Done for facebook/detr-resnet-50-dc5-panoptic\n",
            "Done for facebook/detr-resnet-50-panoptic\n",
            "Done for facebook/maskformer-swin-base-ade\n",
            "Done for facebook/maskformer-swin-large-coco\n",
            "Done for facebook/maskformer-swin-small-ade\n",
            "Done for facebook/maskformer-swin-small-coco\n",
            "Done for facebook/maskformer-swin-tiny-ade\n",
            "Done for facebook/maskformer-swin-tiny-coco\n",
            "Done for keras-io/deeplabv3p-resnet50\n",
            "Done for keras-io/monocular-depth-estimation\n",
            "Done for keras-io/semantic-segmentation\n",
            "Done for microsoft/beit-base-finetuned-ade-640-640\n",
            "Done for microsoft/beit-large-finetuned-ade-640-640\n",
            "Done for Intel/dpt-large-ade\n",
            "Done for nvidia/segformer-b0-finetuned-cityscapes-1024-1024\n",
            "Done for nvidia/segformer-b0-finetuned-cityscapes-512-1024\n",
            "Done for nvidia/segformer-b0-finetuned-cityscapes-640-1280\n",
            "Done for nvidia/segformer-b0-finetuned-cityscapes-768-768\n",
            "Done for nvidia/segformer-b1-finetuned-ade-512-512\n",
            "Done for nvidia/segformer-b1-finetuned-cityscapes-1024-1024\n",
            "Done for nvidia/segformer-b2-finetuned-ade-512-512\n",
            "Done for nvidia/segformer-b2-finetuned-cityscapes-1024-1024\n",
            "Done for nvidia/segformer-b3-finetuned-ade-512-512\n",
            "Done for nvidia/segformer-b3-finetuned-cityscapes-1024-1024\n",
            "Done for nvidia/segformer-b4-finetuned-ade-512-512\n",
            "Done for nvidia/segformer-b4-finetuned-cityscapes-1024-1024\n",
            "Done for nvidia/segformer-b5-finetuned-ade-640-640\n",
            "Done for nvidia/segformer-b5-finetuned-cityscapes-1024-1024\n",
            "Done for tobiasc/segformer-b0-finetuned-segments-sidewalk\n",
            "Done for tobiasc/segformer-b3-finetuned-segments-sidewalk\n",
            "Done for nielsr/segformer-b0-finetuned-segments-sidewalk\n",
            "Done for SerdarHelli/Segmentation-of-Teeth-in-Panoramic-X-ray-Image-Using-U-Net\n",
            "Done for nickmuchi/segformer-b4-finetuned-segments-sidewalk\n",
            "Done for nielsr/segformer-finetuned-sidewalk\n",
            "Done for nielsr/segformer-test-sidewalk-v2\n",
            "Done for nielsr/sidewalk-semantic-demo\n",
            "Done for nielsr/segformer-test-v5\n",
            "Done for nielsr/segformer-test-v6\n",
            "Done for nielsr/segformer-test-v7\n",
            "Done for hufanyoung/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for nielsr/segformer-trainer-test\n",
            "Done for nielsr/segformer-trainer-test-bis\n",
            "Done for nielsr/segformer-finetuned-sidewalk-10k-steps\n",
            "Done for matjesg/cFOS_in_HC\n",
            "Done for Matthijs/deeplabv3-mobilevit-small\n",
            "Done for reannayang/segformer-b0-pavement\n",
            "Done for jakka/segformer-b0-finetuned-segments-sidewalk-4\n",
            "Done for apple/deeplabv3-mobilevit-small\n",
            "Done for apple/deeplabv3-mobilevit-x-small\n",
            "Done for apple/deeplabv3-mobilevit-xx-small\n",
            "Done for merve/deeplab-v3\n",
            "Done for keja/deeplab-v3\n",
            "Done for matjesg/deepflash2_demo\n",
            "Done for malra/segformer-b0-finetuned-segments-sidewalk-4\n",
            "Done for malra/segformer-b5-segments-warehouse1\n",
            "Done for jakka/segformer-b0-finetuned-warehouse-part-1-V2\n",
            "Done for lmazzon70/deeplab-v3\n",
            "Done for q2-jlbar/segformer-b0-finetuned-brooks-or-dunn\n",
            "Done for chainyo/segformer-sidewalk\n",
            "Done for chainyo/segformer-b1-sidewalk\n",
            "Done for Matthijs/deeplabv3_mobilenet_v2_1.0_513\n",
            "Done for userGagan/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for jonathandinu/face-parsing\n",
            "Done for imadd/segformer-b0-finetuned-segments-water-2\n",
            "Done for sayakpaul/mit-b0-finetuned-sidewalk-semantic\n",
            "Done for koushikn/segformer-finetuned-Maize-10k-steps-sem\n",
            "Done for plant/segformer-b5-finetuned-segments-instryde-foot-test\n",
            "Done for kiheh85202/yolo\n",
            "Done for nishita/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for NimaBoscarino/IS-Net_DIS\n",
            "Done for NimaBoscarino/IS-Net_DIS-general-use\n",
            "Done for shaheen1998/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for kasumi222/segformer-b0-finetuned-busigt2\n",
            "Done for lapix/segformer-b3-finetuned-ccagt-400-300\n",
            "Done for zoheb/mit-b5-finetuned-sidewalk-semantic\n",
            "Done for matnun/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for Teklia/doc-ufcn-generic-page\n",
            "Done for CIDAS/clipseg-rd64\n",
            "Done for CIDAS/clipseg-rd16\n",
            "Done for skaliy/spine-segmentation\n",
            "Done for irfan-noordin/segformer-b0-finetuned-segments-sidewalk-oct-22\n",
            "Done for Teklia/doc-ufcn-norhand-v1-line\n",
            "Done for google/deeplabv3_mobilenet_v2_1.0_513\n",
            "Done for shi-labs/oneformer_ade20k_swin_large\n",
            "Done for shi-labs/oneformer_cityscapes_swin_large\n",
            "Done for shi-labs/oneformer_coco_swin_large\n",
            "Done for shi-labs/oneformer_ade20k_dinat_large\n",
            "Done for shi-labs/oneformer_coco_dinat_large\n",
            "Done for shi-labs/oneformer_cityscapes_dinat_large\n",
            "Done for shi-labs/oneformer_ade20k_swin_tiny\n",
            "Done for facebook/mask2former-swin-base-coco-instance\n",
            "Done for voitl/unet_plus_plus\n",
            "Done for turcuciprian/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for Abhilashvj/clipseg-rd64-refined-copy\n",
            "Done for optimum/segformer-b0-finetuned-ade-512-512\n",
            "Done for facebook/mask2former-swin-tiny-coco-instance\n",
            "Done for facebook/mask2former-swin-small-coco-instance\n",
            "Done for mnosouhi96/segformer-b0-finetuned-segments-sidewalk-2\n",
            "Done for facebook/mask2former-swin-base-coco-panoptic\n",
            "Done for facebook/mask2former-swin-large-coco-panoptic\n",
            "Done for facebook/mask2former-swin-small-coco-panoptic\n",
            "Done for facebook/mask2former-swin-tiny-coco-panoptic\n",
            "Done for facebook/mask2former-swin-tiny-cityscapes-panoptic\n",
            "Done for facebook/mask2former-swin-large-cityscapes-panoptic\n",
            "Done for facebook/mask2former-swin-small-cityscapes-panoptic\n",
            "Done for facebook/mask2former-swin-large-cityscapes-semantic\n",
            "Done for facebook/mask2former-swin-large-mapillary-vistas-semantic\n",
            "Done for facebook/mask2former-swin-large-mapillary-vistas-panoptic\n",
            "Done for facebook/mask2former-swin-small-cityscapes-instance\n",
            "Done for facebook/mask2former-swin-tiny-cityscapes-instance\n",
            "Done for facebook/mask2former-swin-base-ade-semantic\n",
            "Done for facebook/mask2former-swin-base-IN21k-ade-semantic\n",
            "Done for facebook/mask2former-swin-large-ade-semantic\n",
            "Done for facebook/mask2former-swin-small-ade-semantic\n",
            "Done for facebook/mask2former-swin-tiny-ade-semantic\n",
            "Done for facebook/mask2former-swin-base-IN21k-cityscapes-instance\n",
            "Done for facebook/mask2former-swin-large-cityscapes-instance\n",
            "Done for facebook/mask2former-swin-base-IN21k-cityscapes-panoptic\n",
            "Done for facebook/mask2former-swin-small-cityscapes-semantic\n",
            "Done for facebook/mask2former-swin-tiny-cityscapes-semantic\n",
            "Done for Xpitfire/segformer-finetuned-segments-cmp-facade\n",
            "Done for Sevenlee/kkk\n",
            "Done for cosmobaby/ka\n",
            "Done for openmmlab/upernet-convnext-tiny\n",
            "Done for openmmlab/upernet-convnext-small\n",
            "Done for openmmlab/upernet-convnext-base\n",
            "Done for openmmlab/upernet-convnext-large\n",
            "Done for openmmlab/upernet-convnext-xlarge\n",
            "Done for openmmlab/upernet-swin-tiny\n",
            "Done for openmmlab/upernet-swin-small\n",
            "Done for openmmlab/upernet-swin-base\n",
            "Done for TheMistoAI/MistoLine\n",
            "Done for stabilityai/stable-diffusion-xl-base-1.0\n",
            "Done for sd-community/sdxl-flash\n",
            "Done for ByteDance/Hyper-SD\n",
            "Done for runwayml/stable-diffusion-v1-5\n",
            "Done for fluently/Fluently-XL-v4\n",
            "Done for ByteDance/SDXL-Lightning\n",
            "Done for stabilityai/sdxl-turbo\n",
            "Done for tianweiy/DMD2\n",
            "Done for cagliostrolab/animagine-xl-3.1\n",
            "Done for sd-community/sdxl-flash-mini\n",
            "Done for CompVis/stable-diffusion-v1-4\n",
            "Done for InstantX/InstantID\n",
            "Done for ostris/sdxl-sd1-vae-lora\n",
            "Done for h94/IP-Adapter-FaceID\n",
            "Done for Alpha-VLLM/Lumina-Next-T2I\n",
            "Done for UnfilteredAI/NSFW-gen-v2\n",
            "Done for RunDiffusion/Juggernaut-X-v10\n",
            "Done for KBlueLeaf/Kohaku-XL-Epsilon-rev2\n",
            "Done for h94/IP-Adapter\n",
            "Done for stabilityai/stable-cascade\n",
            "Done for common-canvas/CommonCanvas-XL-C\n",
            "Done for cutycat2000x/InterDiffusion-3.8\n",
            "Done for SG161222/RealVisXL_V4.0\n",
            "Done for playgroundai/playground-v2.5-1024px-aesthetic\n",
            "Done for ehristoforu/dalle-3-xl-v2\n",
            "Done for stabilityai/stable-diffusion-2-1\n",
            "Done for Kvikontent/midjourney-v6\n",
            "Done for UnfilteredAI/NSFW-gen-v2.1\n",
            "Done for Yntec/AnythingV7\n",
            "Done for hakurei/waifu-diffusion\n",
            "Done for Lykon/DreamShaper\n",
            "Done for stabilityai/control-lora\n",
            "Done for latent-consistency/lcm-lora-sdv1-5\n",
            "Done for RunDiffusion/Juggernaut-XL-v9\n",
            "Done for UnfilteredAI/NSFW-GEN-ANIME\n",
            "Done for stabilityai/stable-diffusion-2-1-base\n",
            "Done for thibaud/controlnet-openpose-sdxl-1.0\n",
            "Done for SargeZT/controlnet-sd-xl-1.0-softedge-dexined\n",
            "Done for cagliostrolab/animagine-xl-3.0\n",
            "Done for SG161222/Realistic_Vision_V6.0_B1_noVAE\n",
            "Done for dataautogpt3/OpenDalleV1.1\n",
            "Done for UnfilteredAI/NSFW-GEN-ANIME-v2\n",
            "Done for RunDiffusion/Juggernaut-X-Hyper\n",
            "Done for runwayml/stable-diffusion-inpainting\n",
            "Done for stabilityai/stable-diffusion-2\n",
            "Done for dreamlike-art/dreamlike-photoreal-2.0\n",
            "Done for JosefJilek/loliDiffusion\n",
            "Done for gsdf/Counterfeit-V3.0\n",
            "Done for diffusers/controlnet-canny-sdxl-1.0\n",
            "Done for nerijs/pixel-art-xl\n",
            "Done for artificialguybr/StickersRedmond\n",
            "Done for stabilityai/sd-turbo\n",
            "Done for Dremmar/nsfw-xl\n",
            "Done for deadman44/SDXL_Photoreal_Merged_Models\n",
            "Done for dataautogpt3/ProteusV0.2\n",
            "Done for RunDiffusion/Juggernaut-XL-Lightning\n",
            "Done for KBlueLeaf/Kohaku-XL-Delta\n",
            "Done for h1t/TCD-SD15-LoRA\n",
            "Done for PixArt-alpha/pixart_sigma_sdxlvae_T5_diffusers\n",
            "Done for JackAILab/ConsistentID\n",
            "Done for Alpha-VLLM/Lumina-T2I\n",
            "Done for GTsuya/boobsgames_pony\n",
            "Done for eienmojiki/Starry-XL-v5.2\n",
            "Done for digiplay/7pa-VAE\n",
            "Done for prithivMLmods/Pinwheel-DallE-3-Lora-Xl-v2\n",
            "Done for Niggendar/duchaitenPonyXLNo_ponyNoScoreV30\n",
            "Done for votepurchase/NSFW-GEN-ANIME-v2\n",
            "Done for tk93/V-Express\n",
            "Done for cutycat2000x/InterDiffusion-4.0\n",
            "Done for hakurei/waifu-diffusion-v1-3\n",
            "Done for AstraliteHeart/pony-diffusion\n",
            "Done for hakurei/waifu-diffusion-v1-4\n",
            "Done for prompthero/openjourney\n",
            "Done for WarriorMama777/OrangeMixs\n",
            "Done for prompthero/openjourney-lora\n",
            "Done for emilianJR/chilloutmix_NiPrunedFp32Fix\n",
            "Done for digiplay/BeautifulArt_v1\n",
            "Done for diffusers/stable-diffusion-xl-1.0-inpainting-0.1\n",
            "Done for ehristoforu/dalle-3-xl\n",
            "Done for openskyml/midjourney-v4-xl\n",
            "Done for DoctorDiffusion/doctor-diffusion-s-claymation-style-lora\n",
            "Done for PixArt-alpha/PixArt-LCM-XL-2-1024-MS\n",
            "Done for ntc-ai/SDXL-LoRA-slider.micro-details-fine-details-detailed\n",
            "Done for TencentARC/PhotoMaker\n",
            "Done for hhks/PonyXL_Styles_Backup\n",
            "Done for Bakanayatsu/ponyDiffusion-V6-XL-Turbo-DPO\n",
            "Done for dataautogpt3/ProteusV0.4-Lightning\n",
            "Done for nerijs/pixelcascade128-v0.1\n",
            "Done for h1t/TCD-SDXL-LoRA\n",
            "Done for jiaxiangc/res-adapter\n",
            "Done for bdsqlsz/SDXL-Consists-Model-Lora-Collection\n",
            "Done for IDKiro/sdxs-512-dreamshaper\n",
            "Done for digiplay/Jellymix_XL_v1\n",
            "Done for KBlueLeaf/Kohaku-XL-Epsilon\n",
            "Done for sWizad/pokemon-trainer-sprite-pixelart\n",
            "Done for alimama-creative/EcomXL_controlnet_inpaint\n",
            "Done for Niggendar/hamefmixsdxlBased_hamefmixsdxlDPO\n",
            "Done for VikramSingh178/Products10k-SDXL-Lora\n",
            "Done for RedRocket/Fluffyrock-Unbound\n",
            "Done for Niggendar/SDXLAnimePony_beta\n",
            "Done for Niggendar/malaAnimeMixNSFW_v20\n",
            "Done for Niggendar/radiata_2\n",
            "Done for Niggendar/chrismixpnyNSFW_v10\n",
            "Done for Niggendar/hadrianDelicexl_v10\n",
            "Done for Niggendar/prefectPonyXL_v10\n",
            "Done for Niggendar/waiANINSFWPONYXL_v40\n",
            "Done for Niggendar/dhxlDeadHorseProject_dhxlResourceV10\n",
            "Done for Niggendar/hotdogPonyMixXL_v10\n",
            "Done for Niggendar/duchaitenPonyXLNo_ponyNoScoreV10\n",
            "Done for Niggendar/duchaitenPonyXLNo_v40Beta\n",
            "Done for Niggendar/duchaitenPonyXLNo_v35\n",
            "Done for Niggendar/ponymatureSDXL_ponyeclipse10\n",
            "Done for Niggendar/obsidianpdxl_V03\n",
            "Done for Niggendar/stardropXL_v10\n",
            "Done for Niggendar/pulenkompotPonyxl_praskovaxl\n",
            "Done for Niggendar/agendaMixPDXL_v10\n",
            "Done for Niggendar/astralponymixxl_v10\n",
            "Done for Niggendar/kizukiXLPonyAnime_v10\n",
            "Done for Niggendar/mythos_v10\n",
            "Done for Yntec/LEOSAMsFilmGirlUltra\n",
            "Done for John6666/anime-bulldozer-v2-sdxl\n",
            "Done for Xibanya/City\n",
            "Done for dalle-mini/dalle-mega\n",
            "Done for CompVis/stable-diffusion-v1-3\n",
            "Done for Severian-Void/Starsector-Portraits\n",
            "Done for stabilityai/sd-vae-ft-mse-original\n",
            "Done for waifu-research-department/long-prompt-weighting-pipeline\n",
            "Done for nitrosocke/mo-di-diffusion\n",
            "Done for IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1\n",
            "Done for Onodofthenorth/SD_PixelArt_SpriteSheet_Generator\n",
            "Done for 0xJustin/Dungeons-and-Diffusion\n",
            "Done for Bingsu/my-korean-stable-diffusion-v1-5\n",
            "Done for NoCrypt/cafe-instagram-unofficial\n",
            "Done for stabilityai/stable-diffusion-2-base\n",
            "Done for nitrosocke/Future-Diffusion\n",
            "Done for Envvi/Inkpunk-Diffusion\n",
            "Done for prompthero/openjourney-v4\n",
            "Done for EK12317/Ekmix-Diffusion\n",
            "Done for Kagerage/wriggly-s-extra-gum-artstyle-ponydiffusion\n",
            "Done for dream-textures/texture-diffusion\n",
            "Done for lunarfish/furrydiffusion\n",
            "Done for gsdf/Counterfeit-V2.0\n",
            "Done for circulus/sd-anireal-3d-v2\n",
            "Done for Ojimi/anime-kawai-diffusion\n",
            "Done for Mitsua/mitsua-diffusion-one\n",
            "Done for xtuner/llava-llama-3-8b-v1_1-gguf\n",
            "Done for unum-cloud/uform-gen2-dpo\n",
            "Done for Salesforce/blip-image-captioning-large\n",
            "Done for microsoft/trocr-large-printed\n",
            "Done for nlpconnect/vit-gpt2-image-captioning\n",
            "Done for Salesforce/blip-image-captioning-base\n",
            "Done for xtuner/llava-phi-3-mini-hf\n",
            "Done for xtuner/llava-phi-3-mini-gguf\n",
            "Done for microsoft/trocr-base-handwritten\n",
            "Done for microsoft/trocr-large-handwritten\n",
            "Done for ddobokki/ko-trocr\n",
            "Done for facebook/nougat-small\n",
            "Done for microsoft/kosmos-2-patch14-224\n",
            "Done for Norm/nougat-latex-base\n",
            "Done for Xenova/nougat-base\n",
            "Done for MohamedRashad/arabic-small-nougat\n",
            "Done for kkatiz/THAI-BLIP-2\n",
            "Done for microsoft/trocr-large-stage1\n",
            "Done for microsoft/trocr-small-handwritten\n",
            "Done for TeamFnord/manga-ocr\n",
            "Done for microsoft/trocr-base-str\n",
            "Done for microsoft/trocr-large-str\n",
            "Done for Zayn/AICVTG_What_if_a_machine_could_create_captions_automatically\n",
            "Done for jinhybr/OCR-Donut-CORD\n",
            "Done for ViLMedic/captioning_baseline\n",
            "Done for microsoft/git-base\n",
            "Done for microsoft/git-base-textcaps\n",
            "Done for microsoft/git-large-coco\n",
            "Done for microsoft/git-large-r-coco\n",
            "Done for Salesforce/blip2-opt-2.7b\n",
            "Done for Salesforce/blip2-opt-2.7b-coco\n",
            "Done for to-be/donut-base-finetuned-invoices\n",
            "Done for Flova/omr_transformer\n",
            "Done for MAGAer13/mplug-owl-llama-7b\n",
            "Done for Riksarkivet/HTR_pipeline_models\n",
            "Done for Salesforce/instructblip-vicuna-7b\n",
            "Done for snzhang/FilmTitle-Beit-GPT2\n",
            "Done for bidiptas/PG-InstructBLIP\n",
            "Done for facebook/nougat-base\n",
            "Done for ayymen/crnn_mobilenet_v3_large_gen_hw\n",
            "Done for hezarai/crnn-fa-64x256-license-plate-recognition\n",
            "Done for selvakumarcts/sk_invoice_receipts\n",
            "Done for llava-hf/llava-1.5-7b-hf\n",
            "Done for llava-hf/vip-llava-13b-hf\n",
            "Done for moranyanuka/blip-image-captioning-large-mocha\n",
            "Done for OleehyO/TexTeller\n",
            "Done for breezedeus/pix2text-mfr\n",
            "Done for GnanaPrasath/ocr_tamil\n",
            "Done for unum-cloud/uform-gen2-qwen-500m\n",
            "Done for prithivMLmods/Beetz-Image-Captioning-Blip\n",
            "Done for Revrse/icon-captioning-model\n",
            "Done for aayushgs/Salesforce-blip-image-captioning-large-custom-handler\n",
            "Done for Mouwiya/BLIP_image_captioning\n",
            "Done for waleko/TikZ-llava-1.5-7b\n",
            "Done for HuanjinYao/DenseConnector-v1.5-8B\n",
            "Done for gagan3012/ViTGPT2_vizwiz\n",
            "Done for keras-io/image-captioning\n",
            "Done for keras-io/ocr-for-captcha\n",
            "Done for kha-white/manga-ocr-base\n",
            "Done for microsoft/trocr-base-printed\n",
            "Done for microsoft/trocr-base-stage1\n",
            "Done for microsoft/trocr-small-printed\n",
            "Done for microsoft/trocr-small-stage1\n",
            "Done for sachin/vit2distilgpt2\n",
            "Done for ydshieh/vit-gpt2-coco-en\n",
            "Done for bipin/image-caption-generator\n",
            "Done for Felix92/doctr-dummy-torch-crnn-vgg16-bn\n",
            "Done for Felix92/doctr-dummy-torch-crnn-mobilenet-v3-small\n",
            "Done for Felix92/doctr-dummy-tf-crnn-vgg16-bn\n",
            "Done for Felix92/doctr-dummy-tf-crnn-mobilenet-v3-large\n",
            "Done for gagan3012/ArOCR\n",
            "Done for Felix92/doctr-tf-crnn-vgg16-bn-french\n",
            "Done for Felix92/doctr-torch-crnn-mobilenet-v3-large-french\n",
            "Done for naver-clova-ix/donut-base-finetuned-cord-v2\n",
            "Done for naver-clova-ix/donut-base\n",
            "Done for naver-clova-ix/donut-proto\n",
            "Done for naver-clova-ix/donut-base-finetuned-rvlcdip\n",
            "Done for naver-clova-ix/donut-base-finetuned-cord-v1-2560\n",
            "Done for naver-clova-ix/donut-base-finetuned-cord-v1\n",
            "Done for naver-clova-ix/donut-base-finetuned-zhtrainticket\n",
            "Done for florentgbelidji/blip_captioning\n",
            "Done for yuewu/toc_titler\n",
            "Done for philschmid/trocr-base-printed\n",
            "Done for dhansmair/flamingo-tiny\n",
            "Done for dhansmair/flamingo-mini\n",
            "Done for baudm/parseq-small-patch16-224\n",
            "Done for baudm/parseq-small\n",
            "Done for baudm/parseq-tiny\n",
            "Done for baudm/vitstr-small\n",
            "Done for baudm/vitstr-small-patch16-224\n",
            "Done for baudm/abinet-lv\n",
            "Done for baudm/trba\n",
            "Done for baudm/crnn\n",
            "Done for Yova/SmallCap7M\n",
            "Done for lokibots/vit-patch16-1280-gpt2-large-image-summary\n",
            "Done for philschmid/donut-base-finetuned-cord-v2\n",
            "Done for studiolike/caps\n",
            "Done for KETI-AIR/veld-base\n",
            "Done for ViLMedic/rrg_baseline\n",
            "Done for espnet/iam_handwriting_ocr\n",
            "Done for napatswift/test-ocr\n",
            "Done for daekeun-ml/ko-trocr-base-nsmc-news-chatbot\n",
            "Done for alibaba-damo/mgp-str-base\n",
            "Done for microsoft/git-base-coco\n",
            "Done for Teklia/pylaia-norhand-v1\n",
            "Done for johko/capdec_015\n",
            "Done for michelecafagna26/vinvl-base-finetuned-hl-scenes-image-captioning\n",
            "Done for michelecafagna26/vinvl-base-image-captioning\n",
            "Done for microsoft/git-large\n",
            "Done for microsoft/git-large-textcaps\n",
            "Done for microsoft/git-base-msrvtt-qa\n",
            "Done for microsoft/git-large-msrvtt-qa\n",
            "Done for dumperize/movie-picture-captioning\n",
            "Done for johko/capdec_0\n",
            "Done for johko/capdec_001\n",
            "Done for johko/capdec_005\n",
            "Done for johko/capdec_025\n",
            "Done for johko/capdec_05\n",
            "Done for DunnBC22/trocr-base-printed_captcha_ocr\n",
            "Done for callmezombie/ZombieSDMixes\n",
            "Done for DunnBC22/trocr-base-printed_license_plates_ocr\n",
            "Done for katanaml/donut-demo\n",
            "Done for tuman/vit-rugpt2-image-captioning\n",
            "Done for Metformin/dummy_img_captioning\n",
            "Done for Teklia/pylaia-norhand-v1-postprocessed\n",
            "Done for microsoft/git-large-r\n",
            "Done for microsoft/git-large-r-textcaps\n",
            "Done for tifa-benchmark/promptcap-coco-vqa\n",
            "Done for SpringAI/AiGenImg2TxtV1\n",
            "Done for artificialguybr/textcaps-teste2\n",
            "Done for shikunl/prismer\n",
            "Done for nathansutton/generate-cxr\n",
            "Done for laion/mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k\n",
            "Done for Abdou/vit-swin-base-224-gpt2-image-captioning\n",
            "Done for Salesforce/blip2-flan-t5-xl\n",
            "Done for Salesforce/blip2-opt-6.7b\n",
            "Done for Salesforce/blip2-opt-6.7b-coco\n",
            "Done for Salesforce/blip2-flan-t5-xl-coco\n",
            "Done for sayakpaul/git-base-pokemon\n",
            "Done for Salesforce/blip2-flan-t5-xxl\n",
            "Done for svjack/vit-gpt-diffusion-zh\n",
            "Done for leeyunjai/img2txt\n",
            "Done for IDEA-CCNL/Taiyi-BLIP-750M-Chinese\n",
            "Done for jaimin/image_caption\n",
            "Done for google/pix2struct-textcaps-base\n",
            "Done for Tomatolovve/DemoTest\n",
            "Done for Shamima/Blip-finetuned-sd-1k\n",
            "Done for google/pix2struct-textcaps-large\n",
            "Done for google/pix2struct-base\n",
            "Done for yisol/IDM-VTON\n",
            "Done for stabilityai/stable-diffusion-xl-refiner-1.0\n",
            "Done for timbrooks/instruct-pix2pix\n",
            "Done for stabilityai/stable-diffusion-2-inpainting\n",
            "Done for TencentARC/t2i-adapter-lineart-sdxl-1.0\n",
            "Done for lllyasviel/control_v11p_sd15_openpose\n",
            "Done for qualcomm/Real-ESRGAN-x4plus\n",
            "Done for AIRI-Institute/HairFastGAN\n",
            "Done for huggan/sim2real_cyclegan\n",
            "Done for lambdalabs/sd-image-variations-diffusers\n",
            "Done for lllyasviel/control_v11e_sd15_ip2p\n",
            "Done for ViscoseBean/control_v1p_sd15_brightness\n",
            "Done for rsortino/ColorizeNet\n",
            "Done for TencentARC/t2i-adapter-canny-sdxl-1.0\n",
            "Done for TencentARC/t2i-adapter-depth-zoe-sdxl-1.0\n",
            "Done for Xenova/4x_APISR_GRL_GAN_generator-onnx\n",
            "Done for keras-io/low-light-image-enhancement\n",
            "Done for caidas/swin2SR-classical-sr-x2-64\n",
            "Done for lllyasviel/sd-controlnet-seg\n",
            "Done for lllyasviel/control_v11p_sd15_lineart\n",
            "Done for BertChristiaens/controlnet-seg-room\n",
            "Done for MakiPan/controlnet-encoded-hands-130k\n",
            "Done for radames/instruct-pix2pix-img2img\n",
            "Done for DionTimmer/controlnet_qrcode-control_v1p_sd15\n",
            "Done for openai/shap-e-img2img\n",
            "Done for TencentARC/t2i-adapter-depth-midas-sdxl-1.0\n",
            "Done for TencentARC/t2i-adapter-openpose-sdxl-1.0\n",
            "Done for destitech/controlnet-inpaint-dreamer-sdxl\n",
            "Done for JCTN/RMBG-1.4\n",
            "Done for qualcomm/AOT-GAN\n",
            "Done for OzzyGT/RealVisXL_V4.0_inpainting\n",
            "Done for camenduru/IDM-VTON-F16\n",
            "Done for isp-uv-es/superIX\n",
            "Done for keras-io/conditional-gan\n",
            "Done for keras-io/lowlight-enhance-mirnet\n",
            "Done for keras-io/super-resolution\n",
            "Done for akiyamasho/AnimeBackgroundGAN-Shinkai\n",
            "Done for akiyamasho/AnimeBackgroundGAN-Hosoda\n",
            "Done for akiyamasho/AnimeBackgroundGAN-Miyazaki\n",
            "Done for akiyamasho/AnimeBackgroundGAN-Kon\n",
            "Done for gwang-kim/DiffusionCLIP-CelebA_HQ\n",
            "Done for gwang-kim/DiffusionCLIP-LSUN_Bedroom\n",
            "Done for huggingnft/cryptopunks__2__bored-apes-yacht-club\n",
            "Done for huggingnft/boredapeyachtclub__2__mutant-ape-yacht-club\n",
            "Done for huggingnft/mini-mutants__2__boredapeyachtclub\n",
            "Done for NDugar/horse_to_zebra_cycle_GAN\n",
            "Done for SBB/sbb_binarization\n",
            "Done for Jorgvt/CycleGAN_GTA_REAL\n",
            "Done for keras-io/bit\n",
            "Done for keras-io/EDSR\n",
            "Done for hugginglearners/fastai-style-transfer\n",
            "Done for lambdalabs/stable-diffusion-image-conditioned\n",
            "Done for kunheekim/style-aware-discriminator\n",
            "Done for weitf/muscleAmine\n",
            "Done for google/maxim-s3-denoising-sidd\n",
            "Done for google/maxim-s3-deblurring-gopro\n",
            "Done for google/maxim-s3-deblurring-reds\n",
            "Done for google/maxim-s3-deblurring-realblur-r\n",
            "Done for google/maxim-s3-deblurring-realblur-j\n",
            "Done for google/maxim-s2-deraining-rain13k\n",
            "Done for google/maxim-s2-deraining-raindrop\n",
            "Done for google/maxim-s2-dehazing-sots-indoor\n",
            "Done for google/maxim-s2-dehazing-sots-outdoor\n",
            "Done for google/maxim-s2-enhancement-lol\n",
            "Done for google/maxim-s2-enhancement-fivek\n",
            "Done for davidfant/sd-ecom-brightswimwear\n",
            "Done for cmudrc/microstructure-colorization\n",
            "Done for carsonkatri/stable-diffusion-2-depth-diffusers\n",
            "Done for matttrent/sd-image-variations-diffusers\n",
            "Done for thanhhau097/swin2SR-realworld-sr-x4-64-bsrgan-psnr\n",
            "Done for philschmid/stable-diffusion-2-inpainting-endpoint\n",
            "Done for caidas/swin2SR-classical-sr-x4-64\n",
            "Done for caidas/swin2SR-compressed-sr-x4-48\n",
            "Done for caidas/swin2SR-lightweight-x2-64\n",
            "Done for caidas/swin2SR-realworld-sr-x4-64-bsrgan-psnr\n",
            "Done for Pie31415/rome\n",
            "Done for NoxiusEngine/Vivid\n",
            "Done for sivar/legostyle1-5\n",
            "Done for parlance/dreamlike-diffusion-1.0-inpainting\n",
            "Done for rullaf/RealESRGAN_MtG\n",
            "Done for redfoo/stable-diffusion-2-inpainting-endpoint-foo\n",
            "Done for whybeyoung/test\n",
            "Done for smikhai1/sd21_db_pixar3d-test\n",
            "Done for transpchan/Live3D-v2-windowsbundle\n",
            "Done for niren/test1\n",
            "Done for lllyasviel/sd-controlnet-canny\n",
            "Done for lllyasviel/sd-controlnet-depth\n",
            "Done for lllyasviel/sd-controlnet-hed\n",
            "Done for lllyasviel/sd-controlnet-mlsd\n",
            "Done for lllyasviel/sd-controlnet-normal\n",
            "Done for lllyasviel/sd-controlnet-openpose\n",
            "Done for lllyasviel/sd-controlnet-scribble\n",
            "Done for Sanster/anything-4.0-inpainting\n",
            "Done for Sanster/Realistic_Vision_V1.4-inpainting\n",
            "Done for PKUWilliamYang/StyleGANEX\n",
            "Done for sayakpaul/whitebox-cartoonizer\n",
            "Done for instruction-tuning-sd/cartoonizer\n",
            "Done for instruction-tuning-sd/low-level-img-proc\n",
            "Done for instruction-tuning-sd/scratch-cartoonizer\n",
            "Done for instruction-tuning-sd/scratch-low-level-img-proc\n",
            "Done for skella83/test\n",
            "Done for CrucibleAI/ControlNetMediaPipeFace\n",
            "Done for steren/deepwater\n",
            "Done for ayaderaghul/photo2monet\n",
            "Done for GreeneryScenery/SheepsControlV1\n",
            "Done for GreeneryScenery/SheepsControlV2\n",
            "Done for GreeneryScenery/SheepsControlV3\n",
            "Done for GreeneryScenery/SheepsControlV4\n",
            "Done for LYFCJJ/anythingv45-cjj-diffusers\n",
            "Done for ckpt/realistic_vision_inpainting\n",
            "Done for ckpt/f222-inpainting\n",
            "Done for ckpt/dreamlike-diffusion-1.0-inpainting\n",
            "Done for ckpt/SS_0.15_x_protogen-inpainting\n",
            "Done for ckpt/AniMerge-inpainting\n",
            "Done for ckpt/PhotoMerge-inpainting\n",
            "Done for GreeneryScenery/SheepsControlV5\n",
            "Done for lllyasviel/control_v11p_sd15_seg\n",
            "Done for lllyasviel/control_v11p_sd15_normalbae\n",
            "Done for lllyasviel/control_v11p_sd15_mlsd\n",
            "Done for lllyasviel/control_v11p_sd15_canny\n",
            "Done for lllyasviel/control_v11p_sd15_softedge\n",
            "Done for lllyasviel/control_v11p_sd15s2_lineart_anime\n",
            "Done for lllyasviel/control_v11e_sd15_shuffle\n",
            "Done for lllyasviel/control_v11p_sd15_inpaint\n",
            "Done for lllyasviel/control_v11p_sd15_scribble\n",
            "Done for lllyasviel/control_v11f1p_sd15_depth\n",
            "Done for latentcat/control_v1p_sd15_brightness\n",
            "Done for GreeneryScenery/SheepsControlV7\n",
            "Done for GreeneryScenery/SheepsControlV8\n",
            "Done for GreeneryScenery/SheepsControlV9\n",
            "Done for osanseviero/tiny-controlnet\n",
            "Done for GreeneryScenery/SheepsControlV9.5\n",
            "Done for JFoz/dog-cat-pose\n",
            "Done for Timmek/anime_world\n",
            "Done for Okka676767/Test_model\n",
            "Done for wyrde/upscales\n",
            "Done for ghoskno/Color-Canny-Controlnet-model\n",
            "Done for Vincent-luo/controlnet-hands\n",
            "Done for Nahrawy/controlnet-VIDIT-FAID\n",
            "Done for SAMControlNet/sd-controlnet-sam-seg\n",
            "Done for tsungtao/controlnet-mlsd-202305011046\n",
            "Done for mfidabel/controlnet-segment-anything\n",
            "Done for huqiming513/Bread\n",
            "Done for kovaIenko/sd-controlnet-canny-local\n",
            "Done for ControlNet-1-1-preview/control_v11f1e_sd15_tile\n",
            "Done for lllyasviel/control_v11f1e_sd15_tile\n",
            "Done for Lobbb08/Nick\n",
            "Done for stabilityai/stable-video-diffusion-img2vid\n",
            "Done for stabilityai/stable-video-diffusion-img2vid-xt\n",
            "Done for wangfuyun/AnimateLCM-I2V\n",
            "Done for wangfuyun/AnimateLCM-SVD-xt\n",
            "Done for vdo/stable-video-diffusion-img2vid-xt-1-1\n",
            "Done for Vchitect/SEINE\n",
            "Done for thingthatis/stable-video-diffusion-img2vid-xt\n",
            "Done for Latinos/TH3BULL\n",
            "Done for joshhhyyy/ai\n",
            "Done for model-hub/stable-video-diffusion-img2vid-xt\n",
            "Done for model-hub/stable-video-diffusion-img2vid\n",
            "Done for zyand/animate-anything-v1.02\n",
            "Done for Namitoo/verify_01\n",
            "Done for Juno360219/aaa\n",
            "Done for stabilityai/stable-video-diffusion-img2vid-xt-1-1-tensorrt\n",
            "Done for DbloZero/Ggggggggg\n",
            "Done for Yeraz22/SpeakerPhoto\n",
            "Done for dr-cipher/motionacam\n",
            "Done for multimodalart/sdxl_perturbed_attention_guidance\n",
            "Done for lucky-lance/TerDiT\n",
            "Done for google/ddpm-cifar10-32\n",
            "Done for 1aurent/ddpm-mnist\n",
            "Done for qualcomm/Stable-Diffusion\n",
            "Done for hyoungwoncho/sd_perturbed_attention_guidance\n",
            "Done for huggan/crypto-gan\n",
            "Done for huggan/fastgan-few-shot-fauvism-still-life\n",
            "Done for huggan/fastgan-few-shot-painting\n",
            "Done for huggan/fastgan-few-shot-shells\n",
            "Done for huggan/fastgan-few-shot-aurora\n",
            "Done for huggingnft/cyberkongz\n",
            "Done for huggingnft/mini-mutants\n",
            "Done for huggingnft/nftrex\n",
            "Done for huggingnft/dooggies\n",
            "Done for huggingnft/cryptopunks\n",
            "Done for huggan/projected_gan_color_field\n",
            "Done for huggan/projected_gan_popart\n",
            "Done for huggan/projected_gan_abstract_expressionism\n",
            "Done for huggingnft/trippytoadznft\n",
            "Done for huggingnft/etherbears\n",
            "Done for ceyda/butterfly_cropped_uniq1K_512\n",
            "Done for huggingnft/hapeprime\n",
            "Done for huggingnft/cryptoskulls\n",
            "Done for huggan/ArtGAN\n",
            "Done for huggingnft/alpacadabraz\n",
            "Done for huggan/projected_gan_Hana_Hanak\n",
            "Done for huggan/projected_gan_color_field_hana\n",
            "Done for huggan/projected_gan_abstract_expressionism_hana\n",
            "Done for huggan/fastgan-few-shot-anime-face\n",
            "Done for huggan/fastgan-few-shot-moongate\n",
            "Done for huggingnft/cryptoadz-by-gremplin\n",
            "Done for chainyo/DocuGAN\n",
            "Done for huggan/fastgan-few-shot-universe\n",
            "Done for huggan/fastgan-few-shot-grumpy-cat\n",
            "Done for huggingnft/theshiboshis\n",
            "Done for huggingnft/boredapeyachtclub\n",
            "Done for huggingnft/azuki\n",
            "Done for huggan/projected_gan_cubism\n",
            "Done for huggan/projected_gan_pop_art_hana\n",
            "Done for huggan/pggan-celebahq-1024\n",
            "Done for huggan/stylegan_animeface512\n",
            "Done for huggan/stylegan_car512\n",
            "Done for huggan/stylegan_cat256\n",
            "Done for huggan/NeonGAN\n",
            "Done for huggingnft/hedgies\n",
            "Done for keras-io/VGG19\n",
            "Done for keras-io/wgan-molecular-graphs\n",
            "Done for huggingnft/frames\n",
            "Done for keras-io/denoising-diffusion-implicit-models\n",
            "Done for CompVis/ldm-celebahq-256\n",
            "Done for google/ddpm-ema-bedroom-256\n",
            "Done for google/ncsnpp-ffhq-1024\n",
            "Done for google/ncsnpp-bedroom-256\n",
            "Done for google/ncsnpp-celebahq-256\n",
            "Done for google/ncsnpp-church-256\n",
            "Done for google/ncsnpp-ffhq-256\n",
            "Done for google/ddpm-cat-256\n",
            "Done for google/ddpm-celebahq-256\n",
            "Done for google/ddpm-ema-celebahq-256\n",
            "Done for google/ddpm-church-256\n",
            "Done for google/ddpm-bedroom-256\n",
            "Done for google/ddpm-ema-church-256\n",
            "Done for google/ddpm-ema-cat-256\n",
            "Done for skytnt/fbanime-gan\n",
            "Done for uripper/GIANNIS\n",
            "Done for cmudrc/2d-lattice-decoder\n",
            "Done for lewtun/sd-class-butterflies-32-test1\n",
            "Done for jfjensen/sd-class-butterflies-32\n",
            "Done for jfjensen/sd-class-butterflies-64\n",
            "Done for arrandi/sd-class-butterflies-32\n",
            "Done for AdelZakirov/sd-class-butterflies-42\n",
            "Done for lewtun/sd-class-butterflies-64\n",
            "Done for LuisQ/LuisQ_sd-class-butterflies-32\n",
            "Done for KidTheCat/sd-class-butterflies-32\n",
            "Done for LuisQ/LuisQ_sd-class-butterflies-64\n",
            "Done for antgrutta/sd-class-butterflies-32\n",
            "Done for mostafahaggag/sd-class-butterflies-32\n",
            "Done for FrancoisDongier/sd-class-butterflies-32\n",
            "Done for Akriel/sd-class-butterflies-32\n",
            "Done for SwePalm/sd-class-butterflies-32\n",
            "Done for CyantifiCQ/noisy_butterflied_diffusion\n",
            "Done for rmartinshort/sd-class-butterflies-64\n",
            "Done for SwePalm/sd-class-butterflies-64\n",
            "Done for michaelmayo704/sd-class-butterflies-32\n",
            "Done for michaelmayo704/sd-class-butterflies-64\n",
            "Done for ignacioiglesias/sd-class-butterflies-32\n",
            "Done for ali97/sd-class-butterflies-32\n",
            "Done for dogeplusplus/sd-class-butterflies-32\n",
            "Done for drool/sd-class-butterflies-32\n",
            "Done for Pramodith/sd-class-butterflies-32\n",
            "Done for jqtrde/sd-class-butterflies-32\n",
            "Done for drool/sd-class-butterflies-64\n",
            "Done for joweyel/sd-class-butterflies-32\n",
            "Done for matan-diamond/sd-class-butterflies-32\n",
            "Done for matan-diamond/sd-class-butterflies-64\n",
            "Done for ryvalenza/sd-class-butterflies-32\n",
            "Done for jl8771/sd-class-butterflies-32\n",
            "Done for cjp/sd-class-butterflies-32\n",
            "Done for nagais/sd-class-butterflies-32\n",
            "Done for JulianBons/sd-class-butterflies-32\n",
            "Done for shivammehta25/sd-class-butterflies-32\n",
            "Done for kaizerkam/sd-class-comics-64\n",
            "Done for thliang01/sd-class-butterflies-32\n",
            "Done for thliang01/sd-class-butterflies-64\n",
            "Done for lily-phoo-95/sd-class-butterflies-32\n",
            "Done for lily-phoo-95/sd-class-butterflies-64\n",
            "Done for sudipta002/sd-class-butterflies-32\n",
            "Done for epsil/sd-class-butterflies-32\n",
            "Done for epsil/sd-class-butterflies-64\n",
            "Done for aleksandrinvictor/sd-class-butterflies-32\n",
            "Done for joweyel/sd-class-butterflies-64\n",
            "Done for ikanher/sd-class-butterflies-32\n",
            "Done for Tetraquarky/sd-class-butterflies-32\n",
            "Done for jl8771/sd-class-butterflies-64\n",
            "Done for AlexChe/sd-class-butterflies-32\n",
            "Done for AlexChe/sd-class-butterflies-64\n",
            "Done for davidaponte/sd-class-butterflies-32\n",
            "Done for ben765/sd-class-butterflies-32\n",
            "Done for Glen/sd-class-butterflies-32-gf\n",
            "Done for ykhwang/sd-class-butterflies-32\n",
            "Done for ykhwang/sd-class-butterflies-64\n",
            "Done for sonicviz/sd-class-butterflies-32\n",
            "Done for Vincent-luo/sd-class-butterflies-32\n",
            "Done for sonicviz/sd-class-butterflies-64\n",
            "Done for lukasHoel/sd-class-butterflies-32\n",
            "Done for Vincent-luo/sd-class-butterflies-64\n",
            "Done for kzipa/sd-class-butterflies-32\n",
            "Done for kzipa/sd-class-butterflies-64\n",
            "Done for aareblau/diffusers-tutorial-butterflies-32\n",
            "Done for aareblau/diffusers-tutorial-butterflies-64\n",
            "Done for yorko/sd-class-butterflies-32\n",
            "Done for juancopi81/sd-class-butterflies-32\n",
            "Done for juancopi81/sd-class-butterflies-64\n",
            "Done for Tetraquarky/sd-class-butterflies-64\n",
            "Done for alexrofail/sd-class-butterflies-32\n",
            "Done for Didier/sd-class-butterflies-32\n",
            "Done for vitaliye/sd-class-butterflies-32\n",
            "Done for Didier/sd-class-butterflies-64\n",
            "Done for alkiskoudounas/sd-butterflies-32px\n",
            "Done for alkiskoudounas/sd-butterflies-64px\n",
            "Done for hizak/sd-class-butterflies-32\n",
            "Done for yanezh/sd-class-butterflies-32\n",
            "Done for hizak/sd-class-butterflies-64\n",
            "Done for alkiskoudounas/sd-butterflies-128px\n",
            "Done for bowwwave/sd-class-butterflies-32\n",
            "Done for exiomius/sd-class-butterflies-32\n",
            "Done for VlakoResker/sd-class-butterflies-32\n",
            "Done for bowwwave/sd-class-butterflies-64\n",
            "Done for exiomius/sd-class-butterflies-64\n",
            "Done for giannisan/timesformer-base-finetuned-k400-finetuned-ucf101-subset\n",
            "Done for microsoft/xclip-base-patch16-zero-shot\n",
            "Done for facebook/timesformer-base-finetuned-k400\n",
            "Done for google/vivit-b-16x2-kinetics400\n",
            "Done for mohamedsaeed823/videomae-base-finetuned-kinetics-finetuned-arsl-subset\n",
            "Done for Sense-X/uniformer_video\n",
            "Done for keras-io/video-classification-cnn-rnn\n",
            "Done for MCG-NJU/videomae-base-short\n",
            "Done for MCG-NJU/videomae-base-finetuned-kinetics\n",
            "Done for MCG-NJU/videomae-base-short-finetuned-kinetics\n",
            "Done for MCG-NJU/videomae-large\n",
            "Done for MCG-NJU/videomae-large-finetuned-kinetics\n",
            "Done for MCG-NJU/videomae-base-short-ssv2\n",
            "Done for MCG-NJU/videomae-base-short-finetuned-ssv2\n",
            "Done for MCG-NJU/videomae-base-ssv2\n",
            "Done for MCG-NJU/videomae-base-finetuned-ssv2\n",
            "Done for MCG-NJU/videomae-base\n",
            "Done for microsoft/xclip-base-patch32\n",
            "Done for microsoft/xclip-base-patch32-16-frames\n",
            "Done for microsoft/xclip-base-patch16\n",
            "Done for microsoft/xclip-base-patch16-16-frames\n",
            "Done for microsoft/xclip-large-patch14\n",
            "Done for microsoft/xclip-large-patch14-16-frames\n",
            "Done for microsoft/xclip-base-patch16-hmdb-2-shot\n",
            "Done for microsoft/xclip-base-patch16-hmdb-4-shot\n",
            "Done for microsoft/xclip-base-patch16-hmdb-8-shot\n",
            "Done for microsoft/xclip-base-patch16-hmdb-16-shot\n",
            "Done for microsoft/xclip-base-patch16-ucf-2-shot\n",
            "Done for microsoft/xclip-base-patch16-ucf-4-shot\n",
            "Done for microsoft/xclip-base-patch16-ucf-8-shot\n",
            "Done for microsoft/xclip-base-patch16-ucf-16-shot\n",
            "Done for microsoft/xclip-base-patch16-kinetics-600\n",
            "Done for microsoft/xclip-base-patch16-kinetics-600-16-frames\n",
            "Done for microsoft/xclip-large-patch14-kinetics-600\n",
            "Done for facebook/timesformer-base-finetuned-ssv2\n",
            "Done for facebook/timesformer-base-finetuned-k600\n",
            "Done for facebook/timesformer-hr-finetuned-k400\n",
            "Done for facebook/timesformer-hr-finetuned-ssv2\n",
            "Done for facebook/timesformer-hr-finetuned-k600\n",
            "Done for sayakpaul/videomae-base-finetuned-kinetics-finetuned-ucf101-subset\n",
            "Done for sayakpaul/videomae-base-finetuned-ucf101-subset\n",
            "Done for nateraw/videomae-base-finetuned-ucf101-subset\n",
            "Done for nateraw/videomae-base-finetuned-ucf101\n",
            "Done for miladfa7/videomae-base-finetuned-ucf101-subset\n",
            "Done for google/vivit-b-16x2\n",
            "Done for younggi/videomae-base-finetuned-ucf101-subset\n",
            "Done for MatiasTamayo/videomae-base-finetuned-ucf101-subset\n",
            "Done for zahrav/videomae-base-finetuned-ucf101-subset\n",
            "Done for fcakyon/timesformer-hr-finetuned-k400\n",
            "Done for fcakyon/timesformer-hr-finetuned-k600\n",
            "Done for fcakyon/timesformer-hr-finetuned-ssv2\n",
            "Done for fcakyon/timesformer-large-finetuned-ssv2\n",
            "Done for fcakyon/timesformer-base-finetuned-k400\n",
            "Done for fcakyon/timesformer-base-finetuned-k600\n",
            "Done for fcakyon/timesformer-base-finetuned-ssv2\n",
            "Done for fcakyon/timesformer-large-finetuned-k400\n",
            "Done for fcakyon/timesformer-large-finetuned-k600\n",
            "Done for NiiCole/videomae-base-finetuned-ucf101-subset\n",
            "Done for L1mbo/videomae-base-finetuned-kinetics-finetuned-ucf101-subset-finetuned-ucf101-subset\n",
            "Done for lmazzon70/videomae-base-short-finetuned-rwf2000\n",
            "Done for ManuD/videomae-base-finetuned-ucf101-subset\n",
            "Done for ManuD/videomae-base-finetuned-dfl_clips\n",
            "Done for lmazzon70/videomae-base-ssv2-finetuned-rwf2000\n",
            "Done for lmazzon70/videomae-base-ssv2-finetuned-rwf2000-epochs6\n",
            "Done for lmazzon70/videomae-base-short-finetuned-ssv2-finetuned-rwf2000-epochs8\n",
            "Done for lmazzon70/videomae-base-short-finetuned-ssv2-finetuned-rwf2000-epochs8-sample8\n",
            "Done for lmazzon70/videomae-base-short-finetuned-ssv2-finetuned-rwf2000-epochs8-batch8\n",
            "Done for lmazzon70/videomae-base-short-finetuned-ssv2-finetuned-rwf2000-epochs8-batch8-fp16\n",
            "Done for burcusu/videomae-base-finetuned-ucf101-subset\n",
            "Done for lmazzon70/videomae-base-short-finetuned-kinetics-finetuned-rwf2000-epochs8-batch8-k\n",
            "Done for laurahanu/videomae-base-finetuned-ucf101-subset\n",
            "Done for anitavero/videomae-base-finetuned-ucf101-subset\n",
            "Done for lmazzon70/videomae-base-finetuned-kinetics-finetuned-rwf2000-epochs8-batch8-kb\n",
            "Done for duyngocadn/videomae-base-finetuned-ucf101-subset\n",
            "Done for Yuanz/videomae-base-finetuned-ucf101-subset\n",
            "Done for zhenligod/videomae-base-finetuned-ucf101-subset\n",
            "Done for LouisDT/videomae-base-finetuned-ucf1012bovi-subset\n",
            "Done for muneeb1812/videomae-base-fake-video-classification\n",
            "Done for LouisDT/videomae-base-finetuned\n",
            "Done for sheraz179/videomae-base-finetuned\n",
            "Done for scallioncake/videomae-base-finetuned-ucf101-subset\n",
            "Done for NerfLongshot/videomae-base-finetuned-sign-subset\n",
            "Done for kkkkii11/videomae-base-finetuned-ucf101-subset\n",
            "Done for vijaym/videomae-base-finetuned-ucf101-subset\n",
            "Done for steveice/videomae-base-finetuned-ucf101-subset\n",
            "Done for bayesianist/videomae-base-finetuned-ucf101-subset\n",
            "Done for koya1/videomae-base-finetuned-ucf101-subset\n",
            "Done for tianquaw/videomae-base-finetuned-ucf101-subset\n",
            "Done for scallioncake/videomae-base-finetuned-thrombosis-subset\n",
            "Done for bayesianist/timesformer-base-finetuned-k400-finetuned-ucf101-subset\n",
            "Done for vcapurro/videomae-base-finetuned-ucf101-subset\n",
            "Done for steveice/videomae-base-finetuned-engine-subset\n",
            "Done for steveice/videomae-base-finetuned-engine-subset-20230310\n",
            "Done for venkateshtata/videomae-base-finetuned-ucf101-subset\n",
            "Done for steveice/videomae-base-finetuned-engine-subset-20230313\n",
            "Done for dangle124/videomae-base-finetuned-RealLifeViolenceSituations-subset\n",
            "Done for yerx/videomae-base-finetuned-basketball-subset-v2\n",
            "Done for clyde890202/videomae-base-finetuned-ucf101-subset\n",
            "Done for AseemD/videomae-base-finetuned-ucf101\n",
            "Done for 222zhaolinniloahszss/hhdaaa\n",
            "Done for momina000/videomae-base-short-ssv2-finetuned-ucf101-subset\n",
            "Done for ronybot/videomae-base-finetuned-weightlifting-subset\n",
            "Done for hf-tiny-model-private/tiny-random-TimesformerForVideoClassification\n",
            "Done for hf-tiny-model-private/tiny-random-VideoMAEForVideoClassification\n",
            "Done for HamzaYous/videomae-base-finetuned-ucf101-subset\n",
            "Done for lmazzon70/videomae-base-finetuned-kinetics-finetuned-rwf2000mp4-epochs8-batch8-kb\n",
            "Done for Mvp-24/videomae-base-finetuned-ucf101-subset\n",
            "Done for Mvp-24/assist_vc\n",
            "Done for lmazzon70/videomae-large-finetuned-kinetics-finetuned-rwf2000-epochs8-batch8-kl-torch2\n",
            "Done for yerx/videomae-base-finetuned-basketball-subset-v3-25epoch\n",
            "Done for MCG-NJU/videomae-huge-finetuned-kinetics\n",
            "Done for MCG-NJU/videomae-small-finetuned-kinetics\n",
            "Done for MCG-NJU/videomae-small-finetuned-ssv2\n",
            "Done for steveice/videomae-base-finetuned-kinetics-finetuned-engine-subset-R2-20230417_K400_2\n",
            "Done for steveice/videomae-base-finetuned-kinetics-finetuned-engine-subset-R2-K400-20230418\n",
            "Done for steveice/videomae-large-finetuned-kinetics-finetuned-engine-subset-R2-K400-20230418_3\n",
            "Done for invictusying/videomae-base-finetuned-ucf101-subset\n",
            "Done for noji/videomae-base-finetuned-ucf101-subset\n",
            "Done for Ymanz/videomae-base-finetuned-ucf101-subset\n",
            "Done for yerx/videomae-base-finetuned-basketball-subset-20epochs\n",
            "Done for fertrevino/videomae-base-finetuned-ucf101-subset\n",
            "Done for mbshaikh/videomae-base-finetuned-ucf101-subset\n",
            "Done for seank0602/videomae-base-finetuned-ucf101-subset\n",
            "Done for hocheewai/videomae-base-finetuned-ucf101-subset\n",
            "Done for ruoyu001/videomae-base-finetuned-ucf101-subset\n",
            "Done for skywarrd/videomae-base-finetuned-ucf101-subset\n",
            "Done for rickysk/videomae-base-finetuned-ucf101-subset\n",
            "Done for yuuhan/videomae-base-finetuned-ucf101-subset\n",
            "Done for yuuhan/videomae-base-lora-ucf101-subset\n",
            "Done for shania-f/timesformer-base-finetuned-k400-finetuned-ucf101-subset\n",
            "Done for Rohit001/face_celeb\n",
            "Done for minoosh/videomae-base-finetuned-IEMOCAP_videos\n",
            "Done for minoosh/videomae-base-finetuned-IEMOCAP_videos-finetuned-IEMOCAP_videos_20\n",
            "Done for qjin/videomae-base-finetuned-kinetics-finetuned-human-training\n",
            "Done for rickysk/videomae-base-ipm_first_videos\n",
            "Done for minoosh/videomae-base-finetuned-IEMOCAP_videos-finetuned-IEMOCAP_videos_20-finetuned-IEMOCAP_videos_30\n",
            "Done for minoosh/videomae-base-finetuned-IEMOCAP_videos-finetuned-IEMOCAP_videos_1010\n",
            "Done for skywarrd/videomae-base-finetuned-michilla-subset\n",
            "Done for IsraelSonseca/videomae-base-finetuned-ucf101-subset\n",
            "Done for thegigasurgeon/videomae-large-finetuned-kinetics-mopping\n",
            "Done for Julia0408/videomae-base-finetuned-ucf101-subset\n",
            "Done for IsraelSonseca/videomae-base-finetuned-ucf101_sport-subset\n",
            "Done for rahulbarua/videomae-base-finetuned-ucf_crime\n",
            "Done for shazab/videomae-base-finetuned-ucf_crime\n",
            "Done for meermoazzam41/videomae-base-finetuned-ucf101-subset\n",
            "Done for thegigasurgeon/mopping_224_16frames_resampling1\n",
            "Done for Q-Wind/videomae-base-finetuned-ucf101-subset\n",
            "Done for thegigasurgeon/mopping_224_32_frames_resampling_1_huge\n",
            "Done for thegigasurgeon/mopping_224_32_frames_resampling_4_huge\n",
            "Done for meermoazzam41/videomae-base-finetuned-human-activity-classification\n",
            "Done for ByteDance/AnimateDiff-Lightning\n",
            "Done for ali-vilab/text-to-video-ms-1.7b\n",
            "Done for wangfuyun/AnimateLCM\n",
            "Done for TMElyralab/MuseV\n",
            "Done for ID-Animator/ID-Animator\n",
            "Done for cerspense/zeroscope_v2_576w\n",
            "Done for ali-vilab/i2vgen-xl\n",
            "Done for ali-vilab/modelscope-damo-text-to-video-synthesis\n",
            "Done for PAIR/text2video-zero-controlnet-canny-anime\n",
            "Done for vdo/animov-0.1.1\n",
            "Done for CiaraRowles/TemporalDiff\n",
            "Done for hotshotco/Hotshot-XL\n",
            "Done for DREX-Institute/2.5D_ANIME_NSFW\n",
            "Done for DREX-Institute/2.5D_ANIME_NSFW-2\n",
            "Done for Tune-A-Video-library/mo-di-bear-guitar\n",
            "Done for Tune-A-Video-library/redshift-man-skiing\n",
            "Done for chavinlo/TempoFunk\n",
            "Done for ali-vilab/text-to-video-ms-1.7b-legacy\n",
            "Done for PAIR/text2video-zero-controlnet-canny-gta5\n",
            "Done for PAIR/text2video-zero-controlnet-canny-arcane\n",
            "Done for PAIR/text2video-zero-controlnet-canny-avatar\n",
            "Done for camenduru/text2-video-zero\n",
            "Done for provin/test\n",
            "Done for Searchium-ai/clip4clip-webvid150k\n",
            "Done for strangeman3107/animov-0.1.1\n",
            "Done for ImRma/Brucelee\n",
            "Done for Hooman66/Unicorn\n",
            "Done for TempoFunk/makeavid-sd-jax\n",
            "Done for Saeidfabd/Trade\n",
            "Done for duncan93/video\n",
            "Done for strangeman3107/animov-512x\n",
            "Done for puffy310/TempoModelCard\n",
            "Done for vdo/animov-512x\n",
            "Done for vdo/text-to-video-ms-1.7b\n",
            "Done for ddrfan/floweR\n",
            "Done for Vibek/Op\n",
            "Done for Mesnyankin/Kkk\n",
            "Done for camenduru/potat1\n",
            "Done for DREX-Institute/potat1.pth\n",
            "Done for Tune-A-Video-library/df-cpt-mo-di-bear-guitar\n",
            "Done for thinkamconnect/ThinkSites\n",
            "Done for Tyffuss86/Polsk\n",
            "Done for Ilovemykid/sim\n",
            "Done for 420bind/neon\n",
            "Done for kyujinpy/Tune-A-VideKO-v1-5\n",
            "Done for kyujinpy/Tune-A-VideKO-anything\n",
            "Done for kyujinpy/Tune-A-VideKO-disney\n",
            "Done for WillemVH/E\n",
            "Done for AthensInfoTech/sum_2023_gr\n",
            "Done for Ashyyy167/Kaeya\n",
            "Done for Nekochu/zeroscope_v2_576w_potat1\n",
            "Done for Rtrggf/Type-A\n",
            "Done for vdo/Hotshot-XL\n",
            "Done for showlab/show-1-interpolation\n",
            "Done for showlab/show-1-base\n",
            "Done for showlab/show-1-sr1\n",
            "Done for showlab/show-1-sr2\n",
            "Done for showlab/show-1-base-0.0\n",
            "Done for sayakpaul/show-1-base\n",
            "Done for Husayn1/Hadi\n",
            "Done for guoyww/animatediff-motion-adapter-v1-4\n",
            "Done for guoyww/animatediff-motion-adapter-v1-5\n",
            "Done for guoyww/animatediff-motion-adapter-v1-5-2\n",
            "Done for AVIIAX/vid\n",
            "Done for guoyww/animatediff-motion-lora-rolling-anticlockwise\n",
            "Done for guoyww/animatediff-motion-lora-tilt-down\n",
            "Done for guoyww/animatediff-motion-lora-pan-right\n",
            "Done for guoyww/animatediff-motion-lora-zoom-out\n",
            "Done for guoyww/animatediff-motion-lora-rolling-clockwise\n",
            "Done for guoyww/animatediff-motion-lora-tilt-up\n",
            "Done for guoyww/animatediff-motion-lora-pan-left\n",
            "Done for guoyww/animatediff-motion-lora-zoom-in\n",
            "Done for Vchitect/LaVie\n",
            "Done for Manu7870/Pic\n",
            "Done for victor/text-to-video-test\n",
            "Done for Revanthraja/Text_to_Vision\n",
            "Done for Lightricks/LongAnimateDiff\n",
            "Done for dilson222/vodeie\n",
            "Done for DIAMONIK7777/AnimateDiff\n",
            "Done for MileAway/hkjk\n",
            "Done for bflooreonline/yesyoucan\n",
            "Done for Alfred000/Alfd.ai\n",
            "Done for DREX-Institute/SHINE_SHUTTLE-V1\n",
            "Done for Enpersson/Test1\n",
            "Done for Edwardwangbo/film\n",
            "Done for Warvito/animatediff-motion-adapter-v1-5-3\n",
            "Done for Yuren/FLATTEN\n",
            "Done for Warvito/animatediff-motion-adapter-sdxl-v1-0-beta\n",
            "Done for JCTN/AnimateDiff-Lightning\n",
            "Done for pengxiang/trackdiffusion_ytvis\n",
            "Done for longlian/text-to-video-lvd-ms\n",
            "Done for pengxiang/TrackDiffusion_ModelScope\n",
            "Done for pengxiang/TrackDiffusion_SVD_Stage1\n",
            "Done for pengxiang/TrackDiffusion_SVD_Stage2\n",
            "Done for nagayama0706/video_generation_model\n",
            "Done for lendarioJF/O_majestoso_e_aterrorizante_JF\n",
            "Done for Kalaphant/KalaVids\n",
            "Done for longlian/text-to-video-lvd-zs\n",
            "Done for openai/clip-vit-large-patch14\n",
            "Done for google/siglip-so400m-patch14-384\n",
            "Done for openai/clip-vit-base-patch32\n",
            "Done for microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\n",
            "Done for HuggingFaceM4/siglip-so400m-14-980-flash-attn2-navit\n",
            "Done for openai/clip-vit-large-patch14-336\n",
            "Done for laion/CLIP-ViT-H-14-laion2B-s32B-b79K\n",
            "Done for timm/ViT-L-16-SigLIP-384\n",
            "Done for xinyu1205/recognize-anything-plus-model\n",
            "Done for OFA-Sys/chinese-clip-vit-base-patch16\n",
            "Done for laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\n",
            "Done for geolocal/StreetCLIP\n",
            "Done for patrickjohncyh/fashion-clip\n",
            "Done for facebook/metaclip-b32-400m\n",
            "Done for facebook/metaclip-h14-fullcc2.5b\n",
            "Done for timm/ViT-B-16-SigLIP\n",
            "Done for timm/ViT-SO400M-14-SigLIP\n",
            "Done for timm/ViT-SO400M-14-SigLIP-384\n",
            "Done for LanguageBind/LanguageBind_Video_FT\n",
            "Done for q-future/one-align\n",
            "Done for google/siglip-base-patch16-256-multilingual\n",
            "Done for Citaman/VeCLIP\n",
            "Done for SaulLu/clip-vit-base-patch32\n",
            "Done for arampacha/clip-rsicd-v5\n",
            "Done for flax-community/clip-rsicd-v2\n",
            "Done for flax-community/clip-rsicd-v3\n",
            "Done for flax-community/clip-rsicd-v4\n",
            "Done for flax-community/clip-rsicd\n",
            "Done for hdo03/clip-finetune\n",
            "Done for nostalgebraist/clip-tumblr-vae\n",
            "Done for openai/clip-vit-base-patch16\n",
            "Done for vesteinn/clip-nabirds\n",
            "Done for vicgalle/clip-vit-base-patch16-photo-critique\n",
            "Done for arampacha/clip-test\n",
            "Done for sujitpal/clip-imageclef\n",
            "Done for thannarot/hug-clip-bid\n",
            "Done for Ngit/clip-rsicd\n",
            "Done for vincentclaes/emoji-predictor\n",
            "Done for rvignav/clip-vit-base-patch32-demo\n",
            "Done for omarques/clip-vit-base-patch32-demo\n",
            "Done for pizapalooza/clip-vit-base-patch32-demo\n",
            "Done for vinayakvsv/clip-vit-base-patch32-demo\n",
            "Done for nhatpth/clip-vit-base-patche32-demo\n",
            "Done for TheLitttleThings/ArchDaily\n",
            "Done for TheLitttleThings/clip-archdaily-5k\n",
            "Done for philschmid/clip-zero-shot-image-classification\n",
            "Done for xiaoliy2/clip-vit-base-patch32-demo\n",
            "Done for sachin/tiny_clip\n",
            "Done for drn/clip-vit-base-pathc32-demo\n",
            "Done for lewtun/tiny-clip-test\n",
            "Done for NimaBoscarino/clip-vit-large-patch14-336\n",
            "Done for laion/CLIP-ViT-B-32-laion2B-s34B-b79K\n",
            "Done for laion/CLIP-ViT-L-14-laion2B-s32B-b82K\n",
            "Done for Bingsu/clip-vit-base-patch32-ko\n",
            "Done for rkolaghassi/clip-vit-base-patch32-demo1\n",
            "Done for Bingsu/clip-vit-large-patch14-ko\n",
            "Done for gagan3012/clip\n",
            "Done for OFA-Sys/chinese-clip-vit-large-patch14\n",
            "Done for OFA-Sys/chinese-clip-vit-large-patch14-336px\n",
            "Done for OFA-Sys/chinese-clip-vit-huge-patch14\n",
            "Done for amir7d0/CLIP-fa\n",
            "Done for mattmdjaga/clip-vit-base-patch32_handler\n",
            "Done for fehime/arma-model\n",
            "Done for fehime/clip-model\n",
            "Done for lyua1225/clip-huge-zh-75k-steps-bs4096\n",
            "Done for Bingsu/cold_light_pass\n",
            "Done for laion/CLIP-ViT-B-16-laion2B-s34B-b88K\n",
            "Done for laion/CLIP-convnext_base_w-laion2B-s13B-b82K\n",
            "Done for laion/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K\n",
            "Done for laion/CLIP-convnext_base_w_320-laion_aesthetic-s13B-b82K\n",
            "Done for laion/CLIP-convnext_base_w-laion2B-s13B-b82K-augreg\n",
            "Done for laion/CLIP-convnext_base_w_320-laion_aesthetic-s13B-b82K-augreg\n",
            "Done for ismot/14t5\n",
            "Done for laion/CLIP-convnext_large_d.laion2B-s26B-b102K-augreg\n",
            "Done for sergioprada/clip-vit-base-patch322\n",
            "Done for laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup\n",
            "Done for laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft\n",
            "Done for Rocketknight1/tiny-random-clip-tf\n",
            "Done for kakaobrain/align-base\n",
            "Done for laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-soup\n",
            "Done for laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind\n",
            "Done for laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg\n",
            "Done for Shubhamai/tiny-random-clip-zero-shot-image-classification\n",
            "Done for vinid/plip\n",
            "Done for laion/CLIP-ViT-g-14-laion2B-s34B-b88K\n",
            "Done for Idan0405/ClipMD\n",
            "Done for BAAI/AltCLIP-m18\n",
            "Done for hf-tiny-model-private/tiny-random-AlignModel\n",
            "Done for hf-tiny-model-private/tiny-random-AltCLIPModel\n",
            "Done for hf-tiny-model-private/tiny-random-BlipModel\n",
            "Done for hf-tiny-model-private/tiny-random-ChineseCLIPModel\n",
            "Done for hf-tiny-model-private/tiny-random-CLIPModel\n",
            "Done for hf-tiny-model-private/tiny-random-CLIPSegModel\n",
            "Done for baseplate/clip-vit-large-patch14\n",
            "Done for timm/vit_large_patch14_clip_336.openai\n",
            "Done for timm/eva02_base_patch16_clip_224.merged2b_s8b_b131k\n",
            "Done for timm/eva02_large_patch14_clip_224.merged2b_s4b_b131k\n",
            "Done for timm/eva02_large_patch14_clip_336.merged2b_s6b_b61k\n",
            "Done for timm/eva_giant_patch14_clip_224.laion400m_s11b_b41k\n",
            "Done for timm/eva_giant_patch14_plus_clip_224.merged2b_s11b_b114k\n",
            "Done for timm/eva02_enormous_patch14_clip_224.laion2b_s4b_b115k\n",
            "Done for timm/eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k\n",
            "Done for Splend1dchan/ViT-H-14-laion2B-s32B-b79K\n",
            "Done for yuvalkirstain/PickScore_v1\n",
            "Done for Superlore/clip-vit-large-patch14\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.S-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.S.basic-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.S.text-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.S.image-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.S.laion-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.S.clip-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-DataComp.S-s13M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.M-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.M.basic-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.M.text-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.M.image-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.M.laion-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-CommonPool.M.clip-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-32-DataComp.M-s128M-b4K\n",
            "Done for laion/CLIP-ViT-B-16-CommonPool.L-s1B-b8K\n",
            "Done for laion/CLIP-ViT-B-16-CommonPool.L.basic-s1B-b8K\n",
            "Done for laion/CLIP-ViT-B-16-CommonPool.L.text-s1B-b8K\n",
            "Done for laion/CLIP-ViT-B-16-CommonPool.L.image-s1B-b8K\n",
            "Done for laion/CLIP-ViT-B-16-CommonPool.L.laion-s1B-b8K\n",
            "Done for laion/CLIP-ViT-B-16-CommonPool.L.clip-s1B-b8K\n",
            "Done for laion/CLIP-ViT-B-16-DataComp.L-s1B-b8K\n",
            "Done for laion/CLIP-ViT-L-14-CommonPool.XL-s13B-b90K\n",
            "Done for laion/CLIP-ViT-L-14-CommonPool.XL.laion-s13B-b90K\n",
            "Done for laion/CLIP-ViT-L-14-CommonPool.XL.clip-s13B-b90K\n",
            "Done for laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K\n",
            "Done for helenai/CLIP-ViT-B-16-plus-240\n",
            "Done for pickapic-anonymous/PickScore_v1\n",
            "Done for gokuls/custom_clip\n",
            "Done for TencentARC/QA-CLIP-ViT-B-16\n",
            "Done for TencentARC/QA-CLIP-ViT-L-14\n",
            "Done for kavorite/e6clip\n",
            "Done for gadgetsam/CLIP-ViT-L-14-DataComp.XL-s13B-b90K\n",
            "Done for Aixile/CLIP-ViT-L-14-DataComp.XL-s13B-b90K\n",
            "Done for laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K\n",
            "Done for justram/CLIP-ViT-B-32-laion2B-e16\n",
            "Done for OysterQAQ/DanbooruCLIP\n",
            "Done for Xenova/clip-vit-base-patch16\n",
            "Done for Xenova/clip-vit-base-patch32\n",
            "Done for mooncakex/img2\n",
            "Done for TJKlein/CLIP-ViT\n",
            "Done for ashm/mini-test\n",
            "Done for mudra1710/clip-embeddings\n",
            "Done for flaviagiammarino/pubmed-clip-vit-base-patch32\n",
            "Done for Junchong-Huang/CLIP\n",
            "Done for wisdomik/QuiltNet-B-32\n",
            "Done for facebook/sam-vit-huge\n",
            "Done for facebook/sam-vit-base\n",
            "Done for facebook/sam-vit-large\n",
            "Done for mit-han-lab/efficientvit-sam\n",
            "Done for HanzhiZhang/lowResSegModel\n",
            "Done for fxmarty/sam-vit-tiny-random\n",
            "Done for wanglab/medsam-vit-base\n",
            "Done for cmhong68/medSAM_skin\n",
            "Done for Xenova/sam-vit-base\n",
            "Done for masapasa/breast-cancer-segmentation\n",
            "Done for masapasa/medsam-vit-base-cancer\n",
            "Done for h2thez3/sam_busi\n",
            "Done for Xenova/sam-vit-large\n",
            "Done for Xenova/sam-vit-huge\n",
            "Done for ahishamm/skinsam\n",
            "Done for merve/sam-finetuned\n",
            "Done for flaviagiammarino/medsam-vit-base\n",
            "Done for ahishamm/skinsam_large\n",
            "Done for ZoeVN/sam_full_finetune_breastcancer\n",
            "Done for ahishamm/skinsam_focalloss_base\n",
            "Done for ahishamm/skinsam_focalloss_base_combined\n",
            "Done for ahishamm/skinsam_focalloss_large\n",
            "Done for giladvdn/test-sam-handler\n",
            "Done for aradootle/sam-vit-base\n",
            "Done for yjmsvma/car_sam\n",
            "Done for Mit1208/sam-fine-tune-doclaynet\n",
            "Done for andrewprayle/SAM_gut_MRI_v0.01_20231123\n",
            "Done for adhisetiawan/sam-pothole-segmentation\n",
            "Done for merve/EfficientSAM\n",
            "Done for xinghaochen/tinysam\n",
            "Done for xinghaochen/Q-TinySAM\n",
            "Done for nielsr/slimsam-50-uniform\n",
            "Done for nielsr/slimsam-77-uniform\n",
            "Done for Zigeng/SlimSAM-uniform-50\n",
            "Done for Zigeng/SlimSAM-uniform-77\n",
            "Done for Xenova/medsam-vit-base\n",
            "Done for Xenova/slimsam-50-uniform\n",
            "Done for Xenova/slimsam-77-uniform\n",
            "Done for kosmalex/mamosam-vit-large\n",
            "Done for nielsr/mobilesam\n",
            "Done for halimb/sam-vit-base\n",
            "Done for ahishamm/fine_tuned_efficient_sam\n",
            "Done for ahishamm/fine_tuned_sam_feb_17\n",
            "Done for ksyint/sam0222\n",
            "Done for crom87/segmentation_test1\n",
            "Done for janakipanneerselvam/SAM_Sunlit\n",
            "Done for crom87/segmentation_test2\n",
            "Done for dragonSwing/nanosam\n",
            "Done for YuvanKumar/sam-finetuned\n",
            "Done for diliash/sam-2024-04-06-23-37-39\n",
            "Done for diliash/sam-2024-04-07-01-52-30\n",
            "Done for diliash/sam-2024-04-07-02-54-21\n",
            "Done for diliash/sam-2024-04-07-03-25-02\n",
            "Done for diliash/sam-2024-04-07-03-45-36\n",
            "Done for diliash/sam-2024-04-07-04-06-08\n",
            "Done for diliash/sam-2024-04-07-04-26-36\n",
            "Done for diliash/sam-2024-04-07-04-47-05\n",
            "Done for diliash/sam-2024-04-07-05-49-01\n",
            "Done for diliash/sam-2024-04-07-06-10-00\n",
            "Done for diliash/sam-2024-04-07-06-30-51\n",
            "Done for diliash/sam-2024-04-07-07-01-30\n",
            "Done for diliash/sam-2024-04-07-10-24-45\n",
            "Done for diliash/sam-2024-04-07-10-45-14\n",
            "Done for diliash/sam-2024-04-07-11-05-41\n",
            "Done for diliash/sam-2024-04-07-11-45-47\n",
            "Done for diliash/sam-2024-04-07-12-26-10\n",
            "Done for diliash/sam-2024-04-07-13-06-08\n",
            "Done for diliash/sam-2024-04-07-13-19-27\n",
            "Done for diliash/sam-2024-04-07-13-59-40\n",
            "Done for diliash/sam-2024-04-07-14-39-34\n",
            "Done for diliash/sam-2024-04-07-15-00-38\n",
            "Done for diliash/sam-2024-04-07-15-40-19\n",
            "Done for diliash/sam-2024-04-07-16-20-04\n",
            "Done for diliash/sam-2024-04-07-16-40-22\n",
            "Done for diliash/sam-2024-04-07-17-20-52\n",
            "Done for diliash/sam-2024-04-07-17-40-54\n",
            "Done for diliash/sam-2024-04-07-17-55-03\n",
            "Done for diliash/sam-2024-04-07-18-15-11\n",
            "Done for diliash/sam-2024-04-07-18-28-34\n",
            "Done for diliash/sam-2024-04-07-19-09-10\n",
            "Done for diliash/sam-2024-04-07-19-23-24\n",
            "Done for diliash/sam-2024-04-07-19-36-43\n",
            "Done for diliash/sam-2024-04-07-19-49-56\n",
            "Done for diliash/sam-2024-04-07-21-32-54\n",
            "Done for diliash/sam-2024-04-07-22-13-47\n",
            "Done for diliash/sam-2024-04-07-22-34-09\n",
            "Done for diliash/sam-2024-04-07-22-54-42\n",
            "Done for diliash/sam-2024-04-07-23-15-14\n",
            "Done for diliash/sam-2024-04-07-23-36-28\n",
            "Done for diliash/sam-2024-04-07-23-50-11\n",
            "Done for diliash/sam-2024-04-08-00-30-41\n",
            "Done for diliash/sam-2024-04-08-00-51-18\n",
            "Done for diliash/sam-2024-04-08-01-05-04\n",
            "Done for diliash/sam-2024-04-08-01-25-31\n",
            "Done for diliash/sam-2024-04-08-02-05-41\n",
            "Done for diliash/sam-2024-04-08-02-45-55\n",
            "Done for diliash/sam-2024-04-08-03-26-19\n",
            "Done for diliash/sam-2024-04-08-04-06-34\n",
            "Done for diliash/sam-2024-04-08-04-46-54\n",
            "Done for diliash/sam-2024-04-08-05-27-09\n",
            "Done for diliash/sam-2024-04-08-06-34-33\n",
            "Done for diliash/sam-2024-04-08-09-03-51\n",
            "Done for diliash/sam-2024-04-08-10-30-40\n",
            "Done for diliash/sam-2024-04-08-11-52-04\n",
            "Done for martintmv/InsectSAM\n",
            "Done for batuhandumani/zerosam\n",
            "Done for kitooo/sidewalk-seg-base\n",
            "Done for hmdliu/sidewalks-seg\n",
            "Done for ansal/sidewalk-segment\n",
            "Done for uisikdag/finetunedsam\n",
            "Done for doggywastaken/bmri-prep_cnn_seg\n",
            "Done for IDEA-Research/grounding-dino-base\n",
            "Done for google/owlv2-base-patch16\n",
            "Done for IDEA-Research/grounding-dino-tiny\n",
            "Done for google/owlv2-base-patch16-ensemble\n",
            "Done for google/owlvit-base-patch32\n",
            "Done for google/owlvit-base-patch16\n",
            "Done for google/owlvit-large-patch14\n",
            "Done for hf-tiny-model-private/tiny-random-OwlViTForObjectDetection\n",
            "Done for juhi7ag/idea-model\n",
            "Done for google/owlv2-base-patch16-finetuned\n",
            "Done for google/owlv2-large-patch14\n",
            "Done for google/owlv2-large-patch14-ensemble\n",
            "Done for google/owlv2-large-patch14-finetuned\n",
            "Done for Xenova/owlvit-base-patch32\n",
            "Done for Xenova/owlvit-base-patch16\n",
            "Done for Xenova/owlvit-large-patch14\n",
            "Done for fxmarty/owlvit-tiny-non-contiguous-weight\n",
            "Done for Xenova/owlv2-base-patch16-ensemble\n",
            "Done for Xenova/owlv2-base-patch16\n",
            "Done for Xenova/owlv2-base-patch16-finetuned\n",
            "Done for Thomasboosinger/owlvit-base-patch32\n",
            "Done for Thomasboosinger/owlv2-base-patch16-ensemble\n",
            "Done for Thomasboosinger/owlv2-large-patch14-ensemble\n",
            "Done for Thomasboosinger/owlv2-large-patch14-finetuned\n",
            "Done for Thomasboosinger/owlv2-large-patch14\n",
            "Done for solomonpm/my-owlvit-8bit\n",
            "Done for Gunulhona/owlvit-base-patch32-qint8\n",
            "Done for rathi2023/owlvit-base-patch32_FT_cppe5\n",
            "Done for rathi2023/owlvit-base-patch32\n",
            "Done for dokutoshi/owlvit-base-patch32_FT_cppe5\n",
            "Done for nateg10/custom_model\n",
            "Done for stabilityai/stable-zero123\n",
            "Done for openai/shap-e\n",
            "Done for ashawkey/LGM\n",
            "Done for Intel/ldm3d\n",
            "Done for Intel/ldm3d-4c\n",
            "Done for One-2-3-45/code\n",
            "Done for Intel/ldm3d-pano\n",
            "Done for Intel/ldm3d-sr\n",
            "Done for Maikou/Michelangelo\n",
            "Done for ironjr/LucidDreamer\n",
            "Done for model-hub/stable-zero123\n",
            "Done for dylanebert/3dlfm\n",
            "Done for dylanebert/NeRFiller\n",
            "Done for dylanebert/RichDreamer\n",
            "Done for hongfz16/3DTopia\n",
            "Done for seungminh/zero123-pro_v1.0\n",
            "Done for JCTN/LGM\n",
            "Done for unity/sentis-alphafold-v1\n",
            "Done for jonquimbly/shap-e\n",
            "Done for hzxie/city-dreamer\n",
            "Done for AlSr/HugFace01\n",
            "Done for dylanebert/mvdream\n",
            "Done for stabilityai/TripoSR\n",
            "Done for TencentARC/InstantMesh\n",
            "Done for VAST-AI/TriplaneGaussian\n",
            "Done for dylanebert/LGM\n",
            "Done for naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt\n",
            "Done for Peng-Wang/ImageDream\n",
            "Done for FrozenBurning/SceneDreamer\n",
            "Done for Rompo/Rompov\n",
            "Done for zxhezexin/openlrm-small-obj-1.0\n",
            "Done for zxhezexin/openlrm-large-obj-1.0\n",
            "Done for zxhezexin/openlrm-base-obj-1.0\n",
            "Done for dylanebert/En3D-human-animation\n",
            "Done for dylanebert/EasyVolcap\n",
            "Done for dylanebert/SyncDreamer\n",
            "Done for dylanebert/4K4D\n",
            "Done for dylanebert/pixelSplat\n",
            "Done for Luizinftr/TESTE\n",
            "Done for dylanebert/3DFauna\n",
            "Done for dylanebert/HarmonyView\n",
            "Done for dylanebert/ROMP\n",
            "Done for zxhezexin/openlrm-obj-small-1.1\n",
            "Done for zxhezexin/openlrm-obj-base-1.1\n",
            "Done for zxhezexin/openlrm-obj-large-1.1\n",
            "Done for zxhezexin/openlrm-mix-large-1.1\n",
            "Done for zxhezexin/openlrm-mix-base-1.1\n",
            "Done for zxhezexin/openlrm-mix-small-1.1\n",
            "Done for Zhengyi/CRM\n",
            "Done for dylanebert/DSINE\n",
            "Done for julienkay/TripoSR\n",
            "Done for dylanebert/StyleGaussian\n",
            "Done for pkunliu/Isotropic3D\n",
            "Done for dylanebert/mvsplat\n",
            "Done for dylanebert/multi-view-diffusion\n",
            "Done for gvecchio/MatForger\n",
            "Done for Bianribian/Gian\n",
            "Done for not-lain/Michelangelo\n",
            "Done for szymanowiczs/splatter-image-v1\n",
            "Done for naver/DUSt3R_ViTLarge_BaseDecoder_512_linear\n",
            "Done for naver/DUSt3R_ViTLarge_BaseDecoder_224_linear\n",
            "Done for dylanebert/imagedream\n",
            "Done for paulengstler/invisible-stitch\n",
            "Done for hjebuoebduede/BRICK\n",
            "Done for m27m27/courseMVSDifuusion\n",
            "Done for TANGsy/triplane_value\n",
            "Done for KenanKhan/my-multi-view-diffusion\n",
            "Done for mromerocastro/3d2xr\n",
            "Done for chadlinden/stablediffusion1\n",
            "Done for google/vit-base-patch16-224-in21k\n",
            "Done for TTPlanet/TTPLanet_SDXL_Controlnet_Tile_Realistic\n",
            "Done for OpenGVLab/InternVL-14B-224px\n",
            "Done for OpenGVLab/InternViT-6B-448px-V1-5\n",
            "Done for OpenGVLab/InternViT-300M-448px\n",
            "Done for dayyass/trocr-base-handwritten-vit-encoder\n",
            "Done for facebook/dinov2-base\n",
            "Done for adhisetiawan/test-vit\n",
            "Done for adhisetiawan/vit-resisc45\n",
            "Done for facebook/dino-vitb16\n",
            "Done for facebook/dino-vitb8\n",
            "Done for facebook/dino-vits16\n",
            "Done for facebook/dino-vits8\n",
            "Done for google/vit-base-patch32-224-in21k\n",
            "Done for google/vit-huge-patch14-224-in21k\n",
            "Done for google/vit-large-patch16-224-in21k\n",
            "Done for google/vit-large-patch32-224-in21k\n",
            "Done for nateraw/tiny-vit-random\n",
            "Done for nielsr/dino_deits8\n",
            "Done for nielsr/dino_vitb16\n",
            "Done for nielsr/dino_vitb8\n",
            "Done for facebook/regnet-y-320-seer\n",
            "Done for facebook/regnet-y-640-seer\n",
            "Done for facebook/regnet-y-1280-seer\n",
            "Done for Francesco/regnet-y-10b-seer\n",
            "Done for facebook/regnet-y-10b-seer\n",
            "Done for vumichien/imagegpt-small\n",
            "Done for arxyzan/data2vec-beit-base\n",
            "Done for joaogante/test_img\n",
            "Done for solve/vit-zigzag-attribute-768dim-patch16-224\n",
            "Done for facebook/vit-msn-small\n",
            "Done for facebook/vit-msn-base\n",
            "Done for facebook/vit-msn-large\n",
            "Done for facebook/vit-msn-base-4\n",
            "Done for facebook/vit-msn-large-7\n",
            "Done for sumba/deit_base_other_classes\n",
            "Done for ydshieh/tiny-random-ViTModel\n",
            "Done for timm/vit_base_patch16_clip_224.openai\n",
            "Done for delima87/Defect_vs_NoDefect_SewerInspection\n",
            "Done for Ramos-Ramos/dino-resnet-50\n",
            "Done for Ramos-Ramos/vicreg-resnet-50\n",
            "Done for gagan3012/swin_arocr_tiny\n",
            "Done for vuiseng9/tiny-random-SwinModel\n",
            "Done for timm/vit_base_patch8_224.dino\n",
            "Done for timm/vit_base_patch16_224.dino\n",
            "Done for timm/vit_huge_patch14_224.orig_in21k\n",
            "Done for timm/vit_large_patch32_224.orig_in21k\n",
            "Done for timm/vit_small_patch8_224.dino\n",
            "Done for timm/vit_small_patch16_224.dino\n",
            "Done for timm/vit_base_r50_s16_224.orig_in21k\n",
            "Done for timm/convnextv2_atto.fcmae\n",
            "Done for timm/convnextv2_base.fcmae\n",
            "Done for timm/convnextv2_femto.fcmae\n",
            "Done for timm/convnextv2_huge.fcmae\n",
            "Done for timm/convnextv2_large.fcmae\n",
            "Done for timm/convnextv2_nano.fcmae\n",
            "Done for timm/convnextv2_pico.fcmae\n",
            "Done for timm/convnextv2_tiny.fcmae\n",
            "Done for Rocketknight1/tiny-random-deit-tf\n",
            "Done for nlebovitz/hw8\n",
            "Done for jcmeyer/week8hw_model1\n",
            "Done for yujiepan/tiny-random-SwinModel\n",
            "Done for yujiepan/tiny-random-swin-patch4-window7-224\n",
            "Done for mkvarghese/detr-finetuned-tesla\n",
            "Done for timm/focalnet_huge_fl4.ms_in22k\n",
            "Done for timm/regnety_320.seer\n",
            "Done for timm/regnety_640.seer\n",
            "Done for timm/regnety_1280.seer\n",
            "Done for hf-tiny-model-private/tiny-random-BeitModel\n",
            "Done for hf-tiny-model-private/tiny-random-BitModel\n",
            "Done for hf-tiny-model-private/tiny-random-ConditionalDetrModel\n",
            "Done for hf-tiny-model-private/tiny-random-ConvNextModel\n",
            "Done for hf-tiny-model-private/tiny-random-ConvNextV2Model\n",
            "Done for hf-tiny-model-private/tiny-random-Data2VecVisionModel\n",
            "Done for hf-tiny-model-private/tiny-random-DeformableDetrModel\n",
            "Done for hf-tiny-model-private/tiny-random-DeiTModel\n",
            "Done for hf-tiny-model-private/tiny-random-DetaModel\n",
            "Done for hf-tiny-model-private/tiny-random-DetrModel\n",
            "Done for hf-tiny-model-private/tiny-random-DinatModel\n",
            "Done for hf-tiny-model-private/tiny-random-DPTModel\n",
            "Done for hf-tiny-model-private/tiny-random-EfficientFormerModel\n",
            "Done for hf-tiny-model-private/tiny-random-EfficientNetModel\n",
            "Done for hf-tiny-model-private/tiny-random-GLPNModel\n",
            "Done for hf-tiny-model-private/tiny-random-ImageGPTModel\n",
            "Done for hf-tiny-model-private/tiny-random-LevitModel\n",
            "Done for hf-tiny-model-private/tiny-random-MobileNetV1Model\n",
            "Done for hf-tiny-model-private/tiny-random-MobileNetV2Model\n",
            "Done for hf-tiny-model-private/tiny-random-MobileViTModel\n",
            "Done for hf-tiny-model-private/tiny-random-NatModel\n",
            "Done for hf-tiny-model-private/tiny-random-PoolFormerModel\n",
            "Done for hf-tiny-model-private/tiny-random-RegNetModel\n",
            "Done for hf-tiny-model-private/tiny-random-ResNetModel\n",
            "Done for hf-tiny-model-private/tiny-random-SegformerModel\n",
            "Done for hf-tiny-model-private/tiny-random-SwinModel\n",
            "Done for hf-tiny-model-private/tiny-random-Swin2SRModel\n",
            "Done for hf-tiny-model-private/tiny-random-Swinv2Model\n",
            "Done for hf-tiny-model-private/tiny-random-TableTransformerModel\n",
            "Done for hf-tiny-model-private/tiny-random-TimesformerModel\n",
            "Done for hf-tiny-model-private/tiny-random-VanModel\n",
            "Done for hf-tiny-model-private/tiny-random-VideoMAEModel\n",
            "Done for hf-tiny-model-private/tiny-random-ViTHybridModel\n",
            "Done for hf-tiny-model-private/tiny-random-ViTModel\n",
            "Done for hf-tiny-model-private/tiny-random-ViTMAEModel\n",
            "Done for hf-tiny-model-private/tiny-random-ViTMSNModel\n",
            "Done for hf-tiny-model-private/tiny-random-YolosModel\n",
            "Done for timm/eva02_base_patch14_224.mim_in22k\n",
            "Done for timm/eva02_large_patch14_224.mim_in22k\n",
            "Done for timm/eva02_large_patch14_224.mim_m38m\n",
            "Done for timm/eva02_small_patch14_224.mim_in22k\n",
            "Done for timm/eva02_tiny_patch14_224.mim_in22k\n",
            "Done for Xenova/vit-base-patch16-224-in21k\n",
            "Done for timm/vit_base_patch16_224.mae\n",
            "Done for timm/vit_huge_patch14_224.mae\n",
            "Done for timm/vit_large_patch16_224.mae\n",
            "Done for timm/vit_base_patch14_dinov2.lvd142m\n",
            "Done for timm/vit_giant_patch14_dinov2.lvd142m\n",
            "Done for timm/vit_large_patch14_dinov2.lvd142m\n",
            "Done for timm/vit_small_patch14_dinov2.lvd142m\n",
            "Done for andrei-saceleanu/vit-base-vocalsound\n",
            "Done for andrei-saceleanu/vit-base-vocalsound-logmel\n",
            "Done for D-Roberts/tf-efficientformer-l1-300-dev1\n",
            "Done for D-Roberts/tf-efficientformer-l3-300-dev1\n",
            "Done for timm/samvit_base_patch16.sa1b\n",
            "Done for timm/samvit_huge_patch16.sa1b\n",
            "Done for timm/samvit_large_patch16.sa1b\n",
            "Done for D-Roberts/tf-efficientformer-l1-300-dev2\n",
            "Done for D-Roberts/tf-efficientformer-l3-300-dev3\n",
            "Done for andrei-saceleanu/vit-base-fixmatch\n",
            "Done for Xenova/dino-vitb16\n",
            "Done for Xenova/dino-vits8\n",
            "Done for Xenova/dino-vitb8\n",
            "Done for Xenova/dino-vits16\n",
            "Done for andrei-saceleanu/vit-base-freematch\n",
            "Done for dhhd255/parkinsons_pred0.1\n",
            "Done for dhhd255/EfficientNet_ParkinsonsPred\n",
            "Done for andrei-saceleanu/vit-base-mixmatch\n",
            "Done for Prem11100/Clustering-embeddings\n",
            "Done for Prem11100/Clustering-embeddings1\n",
            "Done for internetoftim/dinov2-base\n",
            "Done for niki-stha/asl-detector\n",
            "Done for Ihjass/detr-finetuned-115samples\n",
            "Done for Ihjass/detr-finetuned-135samples\n",
            "Done for Dimmas/Finetuned_facebook_dino-vitb14_98x98_flowers\n",
            "Done for facebook/dinov2-large\n",
            "Done for facebook/dinov2-giant\n",
            "Done for MarvinMartin24/SharkViT\n",
            "Done for facebook/dinov2-small\n",
            "Done for BAAI/bge-reranker-v2-m3\n",
            "Done for RLHFlow/ArmoRM-Llama3-8B-v0.1\n",
            "Done for mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n",
            "Done for cardiffnlp/twitter-roberta-base-sentiment-latest\n",
            "Done for SamLowe/roberta-base-go_emotions\n",
            "Done for lxyuan/distilbert-base-multilingual-cased-sentiments-student\n",
            "Done for distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
            "Done for ProsusAI/finbert\n",
            "Done for saribasmetehan/bert-base-turkish-sentiment-analysis\n",
            "Done for BAAI/bge-reranker-base\n",
            "Done for vectara/hallucination_evaluation_model\n",
            "Done for sfairXC/FsfairX-LLaMA3-RM-v0.1\n",
            "Done for protectai/deberta-v3-base-prompt-injection-v2\n",
            "Done for StevenLimcorn/indonesian-roberta-base-emotion-classifier\n",
            "Done for cardiffnlp/twitter-roberta-base-irony\n",
            "Done for finiteautomata/bertweet-base-sentiment-analysis\n",
            "Done for lincoln/flaubert-mlsum-topic-classification\n",
            "Done for martin-ha/toxic-comment-model\n",
            "Done for mdhugol/indonesia-bert-sentiment-classification\n",
            "Done for nlptown/bert-base-multilingual-uncased-sentiment\n",
            "Done for oliverguhr/german-sentiment-bert\n",
            "Done for papluca/xlm-roberta-base-language-detection\n",
            "Done for savasy/bert-turkish-text-classification\n",
            "Done for siebert/sentiment-roberta-large-english\n",
            "Done for w11wo/indonesian-roberta-base-sentiment-classifier\n",
            "Done for rdpahalavan/bert-network-packet-flow-header-payload\n",
            "Done for c299m/japanese_stock_sentiment\n",
            "Done for Falconsai/intent_classification\n",
            "Done for eliasalbouzidi/distilbert-nsfw-text-classifier\n",
            "Done for openai-community/roberta-base-openai-detector\n",
            "Done for AkshatSurolia/ICD-10-Code-Prediction\n",
            "Done for Fujitsu/AugCode\n",
            "Done for amberoad/bert-multilingual-passage-reranking-msmarco\n",
            "Done for arpanghoshal/EmoRoBERTa\n",
            "Done for avichr/heBERT_sentiment_analysis\n",
            "Done for ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa\n",
            "Done for bhadresh-savani/bert-base-uncased-emotion\n",
            "Done for blanchefort/rubert-base-cased-sentiment\n",
            "Done for bvanaken/clinical-assertion-negation-bert\n",
            "Done for cardiffnlp/twitter-roberta-base-emotion\n",
            "Done for cardiffnlp/twitter-roberta-base-offensive\n",
            "Done for chkla/roberta-argument\n",
            "Done for climatebert/distilroberta-base-climate-detector\n",
            "Done for climatebert/distilroberta-base-climate-sentiment\n",
            "Done for AMHR/adversarial-paraphrasing-detector\n",
            "Done for cross-encoder/ms-marco-MiniLM-L-12-v2\n",
            "Done for cross-encoder/ms-marco-MiniLM-L-4-v2\n",
            "Done for elozano/bert-base-cased-news-category\n",
            "Done for fnlp/cpt-large\n",
            "Done for j-hartmann/emotion-english-distilroberta-base\n",
            "Done for j-hartmann/purchase-intention-english-roberta-large\n",
            "Done for juliensimon/reviews-sentiment-analysis\n",
            "Done for keras-io/sentiment-analysis\n",
            "Done for m-newhauser/distilbert-political-tweets\n",
            "Done for madhurjindal/autonlp-Gibberish-Detector-492513457\n",
            "Done for mazancourt/politics-sentence-classifier\n",
            "Done for microsoft/Multilingual-MiniLM-L12-H384\n",
            "Done for microsoft/xtremedistil-l6-h256-uncased\n",
            "Done for philschmid/distilbert-base-multilingual-cased-sentiment-2\n",
            "Done for razent/SciFive-base-Pubmed\n",
            "Done for savasy/bert-base-turkish-sentiment-cased\n",
            "Done for shahrukhx01/question-vs-statement-classifier\n",
            "Done for tals/albert-xlarge-vitaminc-mnli\n",
            "Done for uer/roberta-base-finetuned-dianping-chinese\n",
            "Done for unitary/toxic-bert\n",
            "Done for unitary/unbiased-toxic-roberta\n",
            "Done for w11wo/indonesian-roberta-base-indolem-sentiment-classifier-fold-0\n",
            "Done for ynie/xlnet-large-cased-snli_mnli_fever_anli_R1_R2_R3-nli\n",
            "Done for AnReu/albert-for-math-ar-base-ft\n",
            "Done for ml6team/cross-encoder-mmarco-german-distilbert-base\n",
            "Done for tomh/toxigen_roberta\n",
            "Done for cardiffnlp/tweet-topic-21-multi\n",
            "Done for facebook/roberta-hate-speech-dynabench-r4-target\n",
            "Done for Lurunchik/nf-cats\n",
            "Done for Ammar-alhaj-ali/arabic-MARBERT-sentiment\n",
            "Done for thearod5/pl-bert\n",
            "Done for kit-nlp/bert-base-japanese-sentiment-cyberbullying\n",
            "Done for bdotloh/distilbert-base-uncased-empathetic-dialogues-context\n",
            "Done for lschlessinger/bert-finetuned-math-prob-classification\n",
            "Done for cardiffnlp/tweet-topic-latest-multi\n",
            "Done for EIStakovskii/french_toxicity_classifier_plus_v2\n",
            "Done for michellejieli/NSFW_text_classifier\n",
            "Done for nanelimon/bert-base-turkish-job-advertisement\n",
            "Done for nickwong64/bert-base-uncased-poems-sentiment\n",
            "Done for NLP-LTU/distilbert-sexism-detector\n",
            "Done for cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\n",
            "Done for maymuni/bert-base-turkish-cased-emotion-analysis\n",
            "Done for cardiffnlp/twitter-roberta-base-hate-latest\n",
            "Done for oracat/bert-paper-classifier-arxiv\n",
            "Done for Xenova/distilbert-base-uncased-finetuned-sst-2-english\n",
            "Done for dima806/medium-article-titles-engagement\n",
            "Done for Haldis/multiclassification_NBbert_3classes_crossval\n",
            "Done for dima806/chatgpt-tweets-engagement\n",
            "Done for Den4ikAI/ruBert-tiny-questions-classifier\n",
            "Done for serpapi/bert-base-local-results\n",
            "Done for mtebad/classification_model\n",
            "Done for dima806/medium-article-titles-engagement-all\n",
            "Done for FredZhang7/one-for-all-toxicity-v3\n",
            "Done for GroNLP/mdebertav3-subjectivity-multilingual\n",
            "Done for dima806/phishing-email-detection\n",
            "Done for hafidikhsan/distilbert-base-uncased-english-cefr-lexical-evaluation-dt-v6\n",
            "Done for SchuylerH/bert-multilingual-go-emtions\n",
            "Done for dima806/disaster-tweet-distilbert-classification\n",
            "Done for EuropeanParliament/eurovoc_en\n",
            "Done for DataMonke/bert-base-uncased-finetuned-review-sentiment-analysis\n",
            "Done for dima806/strong-password-checker-bert\n",
            "Done for dima806/fake-news-classifier\n",
            "Done for Xenova/bge-reranker-base\n",
            "Done for dima806/data-science-article-titles-engagement\n",
            "Done for SamLowe/roberta-base-go_emotions-onnx\n",
            "Done for EuropeanParliament/eurovoc_eu\n",
            "Done for dsfsi/PuoBERTa-News\n",
            "Done for dima806/text-emotion-classifier-distilbert\n",
            "Done for dima806/tweets-gender-classifier-distilbert\n",
            "Done for dima806/tweets-financial-classifier-distilbert\n",
            "Done for dima806/toxic-comments-classifier-distilbert\n",
            "Done for dima806/sarcasm-detection-distilbert\n",
            "Done for fzanartu/flicc\n",
            "Done for dima806/friends-emotions-detection-distilbert\n",
            "Done for poltextlab/xlm-roberta-large-french-cap-v3\n",
            "Done for cardiffnlp/twitter-roberta-large-hate-latest\n",
            "Done for protectai/codebert-base-Malicious_URLs-onnx\n",
            "Done for seyyaw/poem_sentiment\n",
            "Done for dima806/email-spam-detection-distilbert\n",
            "Done for h-e-l-l-o/email-spam-classification-merged\n",
            "Done for dima806/sms-spam-detection-distilbert\n",
            "Done for dima806/depressed-tweet-detection-distilbert\n",
            "Done for dima806/ai-generated-essay-detection-distilbert\n",
            "Done for pirocheto/phishing-url-detection\n",
            "Done for vibhorag101/roberta-base-suicide-prediction-phr\n",
            "Done for protectai/deberta-v3-base-prompt-injection\n",
            "Done for ncbi/MedCPT-Cross-Encoder\n",
            "Done for tomaarsen/setfit-all-MiniLM-L6-v2-sst2-32-shot\n",
            "Done for starmage520/Coderbert_finetuned_detect_vulnerability_on_MSR\n",
            "Done for Zabihin/Symptom_to_Diagnosis\n",
            "Done for yuchuantian/AIGC_detector_env1\n",
            "Done for bennexx/cl-tohoku-bert-base-japanese-v3-jlpt-classifier\n",
            "Done for kenhktsui/llm-data-textbook-quality-classifier-v1\n",
            "Done for yiyanghkust/finbert-tone-chinese\n",
            "Done for saridormi/commit-message-quality-codebert\n",
            "Done for malaysia-ai/malay-sentiment-deberta-xsmall\n",
            "Done for ClimatePolicyRadar/national-climate-targets\n",
            "Done for unsloth/gemma-2b-it-bnb-4bit\n",
            "Done for weqweasdas/RM-Gemma-2B\n",
            "Done for mixedbread-ai/mxbai-rerank-xsmall-v1\n",
            "Done for mixedbread-ai/mxbai-rerank-large-v1\n",
            "Done for kalobiralo/bert_cefr_model2\n",
            "Done for EmergentMethods/gliner_medium_news-v2.1\n",
            "Done for EmergentMethods/gliner_large_news-v2.1\n",
            "Done for EmergentMethods/gliner_small_news-v2.1\n",
            "Done for numind/NuNER_Zero\n",
            "Done for hantian/layoutreader\n",
            "Done for numind/NuNER-v2.0\n",
            "Done for dslim/bert-base-NER\n",
            "Done for DeepMount00/GLiNER_ITA_LARGE\n",
            "Done for CAMeL-Lab/bert-base-arabic-camelbert-msa-ner\n",
            "Done for Jean-Baptiste/camembert-ner-with-dates\n",
            "Done for ckiplab/albert-tiny-chinese-ws\n",
            "Done for ckiplab/bert-base-chinese-ner\n",
            "Done for CyberPeace-Institute/SecureBERT-NER\n",
            "Done for Isotonic/deberta-v3-base_finetuned_ai4privacy_v2\n",
            "Done for dslim/distilbert-NER\n",
            "Done for urchade/gliner_large-v2\n",
            "Done for urchade/gliner_multi-v2.1\n",
            "Done for urchade/gliner_multi_pii-v1\n",
            "Done for FacebookAI/xlm-roberta-large-finetuned-conll03-english\n",
            "Done for Babelscape/wikineural-multilingual-ner\n",
            "Done for Davlan/bert-base-multilingual-cased-ner-hrl\n",
            "Done for avichr/heBERT_NER\n",
            "Done for ckiplab/albert-base-chinese-ner\n",
            "Done for ckiplab/albert-base-chinese-ws\n",
            "Done for ckiplab/bert-base-chinese-ws\n",
            "Done for cmarkea/distilcamembert-base-ner\n",
            "Done for jiaqianjing/chinese-address-ner\n",
            "Done for dbmdz/bert-large-cased-finetuned-conll03-english\n",
            "Done for felflare/bert-restore-punctuation\n",
            "Done for flair/ner-english-large\n",
            "Done for flair/ner-german-large\n",
            "Done for oliverguhr/fullstop-punctuation-multilang-large\n",
            "Done for qanastek/pos-french-camembert\n",
            "Done for spacy/zh_core_web_lg\n",
            "Done for ugaray96/biobert_ncbi_disease_ner\n",
            "Done for KoichiYasuoka/bert-base-russian-upos\n",
            "Done for QCRI/bert-base-multilingual-cased-pos-english\n",
            "Done for shibing624/bert4ner-base-chinese\n",
            "Done for ckiplab/bert-tiny-chinese-ws\n",
            "Done for ckiplab/bert-tiny-chinese-ner\n",
            "Done for yanekyuk/bert-keyword-extractor\n",
            "Done for yanekyuk/camembert-keyword-extractor\n",
            "Done for yanekyuk/camembert-keyword-discriminator\n",
            "Done for pourmand1376/NER_Farsi\n",
            "Done for muhtasham/bert-tiny-finetuned-xglue-ner\n",
            "Done for tner/roberta-large-ontonotes5\n",
            "Done for busecarik/berturk-sunlp-ner-turkish\n",
            "Done for jurabi/bert-ner-japanese\n",
            "Done for tsmatz/xlm-roberta-ner-japanese\n",
            "Done for RJuro/SciNERTopic\n",
            "Done for aimarsg/bert-finetuned-ner-1\n",
            "Done for deprem-ml/adres_ner_v2_bert_128k\n",
            "Done for toastynews/electra-hongkongese-small-hk-ws\n",
            "Done for pierreguillou/layout-xlm-base-finetuned-with-DocLayNet-base-at-paragraphlevel-ml512\n",
            "Done for Leo97/KoELECTRA-small-v3-modu-ner\n",
            "Done for AnnemarieWittig/bert-address-de0.1.1\n",
            "Done for llm-book/bert-base-japanese-v3-ner-wikipedia-dataset\n",
            "Done for Gayu/my_sequence_labelling_model\n",
            "Done for unikei/distilbert-base-re-punctuate\n",
            "Done for yacht/latte-mc-bert-base-chinese-ws\n",
            "Done for yacht/latte-mc-bert-base-thai-ws\n",
            "Done for AmelieSchreiber/esm2_t6_8M_general_binding_sites\n",
            "Done for AmelieSchreiber/esm2_t6_8M_general_binding_sites_v2\n",
            "Done for numind/NuNER-multilingual-v0.1\n",
            "Done for SeyedAli/Persian-Text-NER-Bert-V1\n",
            "Done for dsfsi/PuoBERTa-POS\n",
            "Done for AmelieSchreiber/esm2_t12_35M_lora_binding_sites_v2_cp3\n",
            "Done for liyucheng/frame_finder\n",
            "Done for mdarhri00/named-entity-recognition\n",
            "Done for recruit-jp/japanese-typo-detector-roberta-base\n",
            "Done for barghavani/MITRE_cybersecurity\n",
            "Done for sgarbi/bert-fda-nutrition-ner\n",
            "Done for Isotonic/distilbert-base-german-cased_finetuned_ai4privacy_v2\n",
            "Done for Isotonic/mdeberta-v3-base_finetuned_ai4privacy_v2\n",
            "Done for rohitdiwane/bert-finetuned-ner\n",
            "Done for urchade/gliner_base\n",
            "Done for ehri-ner/xlm-roberta-large-ehri-ner-all\n",
            "Done for DeepMount00/universal_ner_ita\n",
            "Done for microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\n",
            "Done for urchade/gliner_medium-v2.1\n",
            "Done for numind/NuNER_Zero-4k\n",
            "Done for SlavicNLP/slavicner-ner-cross-topic-large\n",
            "Done for DeepMount00/GLiNER_ITA_BASE\n",
            "Done for ronenh24/bert-finetuned-ner\n",
            "Done for gokulsarvesh/bert_base_uncase_Conll2012\n",
            "Done for FacebookAI/xlm-roberta-large-finetuned-conll03-german\n",
            "Done for 9pinus/macbert-base-chinese-medical-collation\n",
            "Done for 9pinus/macbert-base-chinese-medicine-recognition\n",
            "Done for AI4Sec/cyner-xlm-roberta-base\n",
            "Done for AI4Sec/cyner-xlm-roberta-large\n",
            "Done for Abhishek4/Cuad_Finetune_roberta\n",
            "Done for AbidHasan95/movieHunt2\n",
            "Done for AdapterHub/bert-base-uncased-pf-conll2000\n",
            "Done for AdapterHub/bert-base-uncased-pf-conll2003\n",
            "Done for AdapterHub/bert-base-uncased-pf-conll2003_pos\n",
            "Done for AdapterHub/bert-base-uncased-pf-fce_error_detection\n",
            "Done for AdapterHub/bert-base-uncased-pf-mit_movie_trivia\n",
            "Done for AdapterHub/bert-base-uncased-pf-pmb_sem_tagging\n",
            "Done for AdapterHub/bert-base-uncased-pf-ud_deprel\n",
            "Done for AdapterHub/bert-base-uncased-pf-ud_pos\n",
            "Done for AdapterHub/bert-base-uncased-pf-wnut_17\n",
            "Done for AdapterHub/roberta-base-pf-conll2000\n",
            "Done for AdapterHub/roberta-base-pf-conll2003\n",
            "Done for AdapterHub/roberta-base-pf-conll2003_pos\n",
            "Done for AdapterHub/roberta-base-pf-fce_error_detection\n",
            "Done for AdapterHub/roberta-base-pf-mit_movie_trivia\n",
            "Done for AdapterHub/roberta-base-pf-pmb_sem_tagging\n",
            "Done for AdapterHub/roberta-base-pf-ud_deprel\n",
            "Done for AdapterHub/roberta-base-pf-ud_pos\n",
            "Done for AdapterHub/roberta-base-pf-wnut_17\n",
            "Done for Alaeddin/convbert-base-turkish-ner-cased\n",
            "Done for Aleksandar/bert-srb-ner-setimes\n",
            "Done for Aleksandar/bert-srb-ner\n",
            "Done for Aleksandar/distilbert-srb-ner-setimes\n",
            "Done for Aleksandar/distilbert-srb-ner\n",
            "Done for Aleksandar/electra-srb-ner-setimes\n",
            "Done for Aleksandar/electra-srb-ner\n",
            "Done for AlexMaclean/sentence-compression-roberta\n",
            "Done for AlexMaclean/sentence-compression\n",
            "Done for Alexander-Learn/bert-finetuned-ner-accelerate\n",
            "Done for Alexander-Learn/bert-finetuned-ner\n",
            "Done for Andrey1989/mbert-finetuned-ner\n",
            "Done for Andrija/M-bert-NER\n",
            "Done for Andrija/SRoBERTa-L-NER\n",
            "Done for Andrija/SRoBERTa-NER\n",
            "Done for Andrija/SRoBERTa-NLP\n",
            "Done for Andrija/SRoBERTa-XL-NER\n",
            "Done for Andrija/SRoBERTa-base-NER\n",
            "Done for Ann2020/distilbert-base-uncased-finetuned-ner\n",
            "Done for ArBert/albert-base-v2-finetuned-ner-agglo-twitter\n",
            "Done for ArBert/albert-base-v2-finetuned-ner-agglo\n",
            "Done for ArBert/albert-base-v2-finetuned-ner-gmm-twitter\n",
            "Done for ArBert/albert-base-v2-finetuned-ner-gmm\n",
            "Done for ArBert/albert-base-v2-finetuned-ner-kmeans-twitter\n",
            "Done for ArBert/albert-base-v2-finetuned-ner-kmeans\n",
            "Done for ArBert/albert-base-v2-finetuned-ner\n",
            "Done for ArBert/bert-base-uncased-finetuned-ner-kmeans\n",
            "Done for ArBert/bert-base-uncased-finetuned-ner\n",
            "Done for ArBert/roberta-base-finetuned-ner-agglo-twitter\n",
            "Done for ArBert/roberta-base-finetuned-ner-kmeans-twitter\n",
            "Done for ArBert/roberta-base-finetuned-ner-kmeans\n",
            "Done for ArBert/roberta-base-finetuned-ner\n",
            "Done for ArseniyBolotin/bert-multi-PAD-ner\n",
            "Done for Azizun/Geotrend-10-epochs\n",
            "Done for BSC-LT/roberta-base-bne-capitel-ner-plus\n",
            "Done for BSC-LT/roberta-base-bne-capitel-ner\n",
            "Done for BSC-LT/roberta-base-bne-capitel-pos\n",
            "Done for BSC-LT/roberta-large-bne-capitel-ner\n",
            "Done for google/tapas-large-finetuned-wtq\n",
            "Done for juliagsy/tapas_fine_tuning\n",
            "Done for benschlagman/tapas_fine_tuning\n",
            "Done for google/tapas-base-finetuned-sqa\n",
            "Done for google/tapas-base-finetuned-wikisql-supervised\n",
            "Done for google/tapas-base-finetuned-wtq\n",
            "Done for google/tapas-large-finetuned-sqa\n",
            "Done for google/tapas-large-finetuned-wikisql-supervised\n",
            "Done for google/tapas-medium-finetuned-sqa\n",
            "Done for google/tapas-medium-finetuned-wikisql-supervised\n",
            "Done for google/tapas-medium-finetuned-wtq\n",
            "Done for google/tapas-mini-finetuned-sqa\n",
            "Done for google/tapas-mini-finetuned-wtq\n",
            "Done for google/tapas-small-finetuned-sqa\n",
            "Done for google/tapas-small-finetuned-wikisql-supervised\n",
            "Done for google/tapas-small-finetuned-wtq\n",
            "Done for google/tapas-tiny-finetuned-sqa\n",
            "Done for google/tapas-tiny-finetuned-wtq\n",
            "Done for juliagsy/tapas-fine-tuned\n",
            "Done for lysandre/tapas-temporary-repo\n",
            "Done for lysandre/tiny-tapas-random-sqa\n",
            "Done for lysandre/tiny-tapas-random-wtq\n",
            "Done for microsoft/tapex-base-finetuned-wikisql\n",
            "Done for microsoft/tapex-base\n",
            "Done for microsoft/tapex-large-finetuned-tabfact\n",
            "Done for navteca/tapas-large-finetuned-wtq\n",
            "Done for nielsr/tapex-large-finetuned-sqa\n",
            "Done for nielsr/tapex-large-finetuned-wikisql\n",
            "Done for nielsr/tapex-large-finetuned-wtq\n",
            "Done for microsoft/tapex-large-finetuned-wikisql\n",
            "Done for microsoft/tapex-large\n",
            "Done for microsoft/tapex-large-finetuned-wtq\n",
            "Done for microsoft/tapex-large-sql-execution\n",
            "Done for microsoft/tapex-base-finetuned-wtq\n",
            "Done for Meena/table-question-answering-tapas\n",
            "Done for PrimeQA/tapas-based-tableqa-wikisql-lookup\n",
            "Done for opticalmaterials/opticaltable_sqa\n",
            "Done for neulab/omnitab-large-finetuned-wtq\n",
            "Done for neulab/omnitab-large\n",
            "Done for neulab/omnitab-large-16shot-finetuned-wtq-16shot\n",
            "Done for neulab/omnitab-large-16shot\n",
            "Done for neulab/omnitab-large-128shot\n",
            "Done for neulab/omnitab-large-1024shot\n",
            "Done for neulab/omnitab-large-1024shot-finetuned-wtq-1024shot\n",
            "Done for neulab/omnitab-large-128shot-finetuned-wtq-128shot\n",
            "Done for ohsuz/koreapas-finetuned-korwikitq\n",
            "Done for ohsuz/koreapas-finetuned-korquad\n",
            "Done for dsba-lab/koreapas-finetuned-korwikitq\n",
            "Done for inedcom/clases\n",
            "Done for LBerndsen/my-awesome-model\n",
            "Done for LBerndsen/my-awesome-model-v2\n",
            "Done for LBerndsen/my-awesome-model-v3\n",
            "Done for LBerndsen/insurers-finetuned-wtq\n",
            "Done for RyanHaniff/concordia_class_schedule\n",
            "Done for RyanHaniff/concordia_trained_model\n",
            "Done for jhwgy/bookzrq\n",
            "Done for Yale-LILY/reastap-large\n",
            "Done for Haris5/AI\n",
            "Done for hf-tiny-model-private/tiny-random-TapasForQuestionAnswering\n",
            "Done for andkelly21/yummy-tapas\n",
            "Done for Yale-LILY/reastap-large-finetuned-wtq\n",
            "Done for Yale-LILY/reastap-large-finetuned-wikisql\n",
            "Done for alinh1803/opt-350-fine-tuning\n",
            "Done for Ezell/testModel\n",
            "Done for vaishali/multitabqa-base\n",
            "Done for Makmur1001/SIFOOD\n",
            "Done for rukanyan/rukanyanroom\n",
            "Done for vaishali/multitabqa-base-sql\n",
            "Done for vaishali/multitabqa-base-geoquery\n",
            "Done for vaishali/multitabqa-base-atis\n",
            "Done for freesky/T2T_metrics\n",
            "Done for Minhcdcd/Hjieu\n",
            "Done for rayshu/test\n",
            "Done for raghavneon/test_model\n",
            "Done for njt1980/JIRAHelper\n",
            "Done for Vesper27/TEST\n",
            "Done for core-outline/tapas-large-finetuned-wtq\n",
            "Done for Ade26/tapas_test\n",
            "Done for Lotem/check\n",
            "Done for Eudismay/Top\n",
            "Done for vanya203/table_question_answer_high_limit\n",
            "Done for genia-vdg/genia-modelo3\n",
            "Done for Nomedamai/custom_QA\n",
            "Done for Bikas0/Bengali-Question-Answer-Llama3\n",
            "Done for AIAT/Kiddee-qatable1\n",
            "Done for AIAT/The_Scamper-opt70bqt\n",
            "Done for aimedaresearch/lamma3finetuned\n",
            "Done for bragour/Camel-7b-chat\n",
            "Done for HPAI-BSC/Llama3-Aloe-8B-Alpha\n",
            "Done for deepset/roberta-base-squad2\n",
            "Done for shareAI/llama3-Chinese-chat-8b\n",
            "Done for timpal0l/mdeberta-v3-base-squad2\n",
            "Done for google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\n",
            "Done for distilbert/distilbert-base-cased-distilled-squad\n",
            "Done for distilbert/distilbert-base-uncased-distilled-squad\n",
            "Done for Intel/dynamic_tinybert\n",
            "Done for SajjadAyoubi/xlm-roberta-large-fa-qa\n",
            "Done for marzinouri/parsbert-finetuned-persianQA\n",
            "Done for pierreguillou/bert-large-cased-squad-v1.1-portuguese\n",
            "Done for twmkn9/distilbert-base-uncased-squad2\n",
            "Done for NchuNLP/Legal-Document-Question-Answering\n",
            "Done for IDEA-CCNL/Randeng-T5-784M-QA-Chinese\n",
            "Done for CATIE-AQ/QAmembert-large\n",
            "Done for lakshyasoni/my_awesome_qa_model\n",
            "Done for arabi-elidrisi/ArabicDistilBERT_QA\n",
            "Done for Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca\n",
            "Done for FinchResearch/llama2-stable-7b-lora\n",
            "Done for Jacaranda/UlizaLlama\n",
            "Done for IvanD2002/gemma-chatbot\n",
            "Done for Vanessasml/cyber-risk-llama-2-7b\n",
            "Done for shareAI/Phi-3-mini-128k-instruct-Chinese\n",
            "Done for gp-tar4/QA_FineTuned_Arabert\n",
            "Done for CONCREE/adia-llm\n",
            "Done for ronenh24/bert-finetuned-squad\n",
            "Done for bsgglobal/my_awesome_qa_model\n",
            "Done for prabinpanta0/ZenGQ\n",
            "Done for asif00/bangla-llama\n",
            "Done for google-bert/bert-large-cased-whole-word-masking-finetuned-squad\n",
            "Done for AdapterHub/bert-base-uncased-pf-comqa\n",
            "Done for AdapterHub/bert-base-uncased-pf-cq\n",
            "Done for AdapterHub/bert-base-uncased-pf-drop\n",
            "Done for AdapterHub/bert-base-uncased-pf-duorc_p\n",
            "Done for AdapterHub/bert-base-uncased-pf-duorc_s\n",
            "Done for AdapterHub/bert-base-uncased-pf-hotpotqa\n",
            "Done for AdapterHub/bert-base-uncased-pf-newsqa\n",
            "Done for AdapterHub/bert-base-uncased-pf-quoref\n",
            "Done for AdapterHub/bert-base-uncased-pf-squad\n",
            "Done for AdapterHub/bert-base-uncased-pf-squad_v2\n",
            "Done for AdapterHub/bert-base-uncased-pf-wikihop\n",
            "Done for AdapterHub/roberta-base-pf-comqa\n",
            "Done for AdapterHub/roberta-base-pf-cq\n",
            "Done for AdapterHub/roberta-base-pf-drop\n",
            "Done for AdapterHub/roberta-base-pf-duorc_p\n",
            "Done for AdapterHub/roberta-base-pf-duorc_s\n",
            "Done for AdapterHub/roberta-base-pf-hotpotqa\n",
            "Done for AdapterHub/roberta-base-pf-newsqa\n",
            "Done for AdapterHub/roberta-base-pf-quoref\n",
            "Done for AdapterHub/roberta-base-pf-squad\n",
            "Done for AdapterHub/roberta-base-pf-squad_v2\n",
            "Done for AdapterHub/roberta-base-pf-wikihop\n",
            "Done for Akari/albert-base-v2-finetuned-squad\n",
            "Done for Aleksandra/herbert-base-cased-finetuned-squad\n",
            "Done for AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\n",
            "Done for Alexander-Learn/bert-finetuned-squad\n",
            "Done for AlirezaBaneshi/testPersianQA\n",
            "Done for AmazonScience/qanlu\n",
            "Done for Andranik/TestQA2\n",
            "Done for Andranik/TestQaV1\n",
            "Done for AndrewChar/model-QA-5-epoch-RU\n",
            "Done for AnonymousSub/EManuals_BERT_squad2.0\n",
            "Done for AnonymousSub/EManuals_RoBERTa_squad2.0\n",
            "Done for AnonymousSub/bert-base-uncased_squad2.0\n",
            "Done for AnonymousSub/cline-emanuals-techqa\n",
            "Done for AnonymousSub/cline-techqa\n",
            "Done for AnonymousSub/cline_squad2.0\n",
            "Done for AnonymousSub/consert-techqa\n",
            "Done for AnonymousSub/declutr-emanuals-techqa\n",
            "Done for AnonymousSub/declutr-model_squad2.0\n",
            "Done for AnonymousSub/declutr-techqa\n",
            "Done for AnonymousSub/roberta-base_squad2.0\n",
            "Done for AnonymousSub/rule_based_bert_quadruplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_bert_triplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_hier_quadruplet_0.1_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_hier_quadruplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_hier_triplet_0.1_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_hier_triplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_only_classfn_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_bert_quadruplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_bert_triplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_hier_quadruplet_0.1_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_hier_quadruplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_hier_triplet_0.1_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_hier_triplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_only_classfn_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_only_classfn_twostage_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_twostage_quadruplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_twostagequadruplet_hier_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_twostagetriplet_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/rule_based_roberta_twostagetriplet_hier_epochs_1_shard_1_squad2.0\n",
            "Done for AnonymousSub/specter-bert-model_squad2.0\n",
            "Done for AnonymousSub/unsup-consert-base_squad2.0\n",
            "Done for ArpanZS/debug_squad\n",
            "Done for Ateeb/QA\n",
            "Done for Aybars/ModelOnTquad\n",
            "Done for Aybars/ModelOnWhole\n",
            "Done for Aybars/XLM_Turkish\n",
            "Done for AyushPJ/ai-club-inductions-21-nlp-ALBERT\n",
            "Done for AyushPJ/ai-club-inductions-21-nlp-ELECTRA-base-squad\n",
            "Done for AyushPJ/ai-club-inductions-21-nlp-XLNet\n",
            "Done for AyushPJ/ai-club-inductions-21-nlp-distilBERT\n",
            "Done for AyushPJ/ai-club-inductions-21-nlp-roBERTa-base-squad-v2\n",
            "Done for AyushPJ/ai-club-inductions-21-nlp-roBERTa\n",
            "Done for AyushPJ/test-squad-trained-finetuned-squad\n",
            "Done for BSC-LT/roberta-base-bne-sqac\n",
            "Done for BSC-LT/roberta-large-bne-sqac\n",
            "Done for Barleysack/AERoberta\n",
            "Done for Barleysack/AERoberta2\n",
            "Done for BatuhanYilmaz/distilbert-base-uncased-finetuned-squad-d5716d28\n",
            "Done for Beri/legal-qa\n",
            "Done for CNT-UPenn/RoBERTa_for_seizureFrequency_QA\n",
            "Done for dccuchile/albert-base-spanish-finetuned-qa-mlqa\n",
            "Done for dccuchile/albert-large-spanish-finetuned-qa-mlqa\n",
            "Done for dccuchile/albert-tiny-spanish-finetuned-qa-mlqa\n",
            "Done for dccuchile/albert-xlarge-spanish-finetuned-qa-mlqa\n",
            "Done for dccuchile/albert-xxlarge-spanish-finetuned-qa-mlqa\n",
            "Done for dccuchile/bert-base-spanish-wwm-cased-finetuned-qa-mlqa\n",
            "Done for dccuchile/bert-base-spanish-wwm-uncased-finetuned-qa-mlqa\n",
            "Done for dccuchile/distilbert-base-spanish-uncased-finetuned-qa-mlqa\n",
            "Done for Ching/negation_detector\n",
            "Done for CodeNinja1126/xlm-roberta-large-kor-mrc\n",
            "Done for DHBaek/xlm-roberta-large-korquad-mask\n",
            "Done for DaisyMak/bert-finetuned-squad-accelerate-10epoch_transformerfrozen\n",
            "Done for DaisyMak/bert-finetuned-squad-transformerfrozen-testtoken\n",
            "Done for Dongjae/mrc2reader\n",
            "Done for Doohae/roberta\n",
            "Done for EasthShin/Klue-CommonSense-model\n",
            "Done for FOFer/distilbert-base-uncased-finetuned-squad\n",
            "Done for FardinSaboori/bert-finetuned-squad\n",
            "Done for Firat/albert-base-v2-finetuned-squad\n",
            "Done for Firat/distilbert-base-uncased-finetuned-squad\n",
            "Done for Firat/roberta-base-finetuned-squad\n",
            "Done for FirmanBr/FirmanIndoLanguageModel\n",
            "Done for FirmanBr/chibibot\n",
            "Done for ForutanRad/bert-fa-QA-v1\n",
            "Done for FuriouslyAsleep/markuplm-large-finetuned-qa\n",
            "Done for Gantenbein/ADDI-CH-RoBERTa\n",
            "Done for Gantenbein/ADDI-CH-XLM-R\n",
            "Done for Gantenbein/ADDI-DE-RoBERTa\n",
            "Done for Gantenbein/ADDI-DE-XLM-R\n",
            "Done for Gantenbein/ADDI-FI-RoBERTa\n",
            "Done for Gantenbein/ADDI-FI-XLM-R\n",
            "Done for Gantenbein/ADDI-FR-RoBERTa\n",
            "Done for Gantenbein/ADDI-FR-XLM-R\n",
            "Done for Gantenbein/ADDI-IT-RoBERTa\n",
            "Done for Gantenbein/ADDI-IT-XLM-R\n",
            "Done for Gayathri/distilbert-base-uncased-finetuned-squad\n",
            "Done for facebook/bart-large-mnli\n",
            "Done for MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\n",
            "Done for sileod/deberta-v3-small-tasksource-nli\n",
            "Done for MoritzLaurer/deberta-v3-large-zeroshot-v2.0\n",
            "Done for cross-encoder/nli-roberta-base\n",
            "Done for joeddav/xlm-roberta-large-xnli\n",
            "Done for valhalla/distilbart-mnli-12-1\n",
            "Done for morit/spanish_xlm_xnli\n",
            "Done for sileod/mdeberta-v3-base-tasksource-nli\n",
            "Done for knowledgator/comprehend_it-multilingual-t5-base\n",
            "Done for ClaudeYang/awesome_fb_model\n",
            "Done for Jiva/xlm-roberta-large-it-mnli\n",
            "Done for KheireddineDaouadi/ZeroAraElectra\n",
            "Done for MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
            "Done for MoritzLaurer/DeBERTa-v3-base-mnli\n",
            "Done for MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary\n",
            "Done for MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\n",
            "Done for MoritzLaurer/xtremedistil-l6-h256-mnli-fever-anli-ling-binary\n",
            "Done for NDugar/1epochv3\n",
            "Done for NDugar/2epochv3mlni\n",
            "Done for NDugar/3epoch-3large\n",
            "Done for NDugar/ZSD-microsoft-v2xxlmnli\n",
            "Done for NDugar/deberta-v2-xlarge-mnli\n",
            "Done for NDugar/debertav3-mnli-snli-anli\n",
            "Done for NDugar/v2xl-again-mnli\n",
            "Done for NDugar/v3-Large-mnli\n",
            "Done for NDugar/v3large-1epoch\n",
            "Done for NDugar/v3large-2epoch\n",
            "Done for Narsil/deberta-large-mnli-zero-cls\n",
            "Done for NbAiLab/nb-bert-base-mnli\n",
            "Done for Recognai/bert-base-spanish-wwm-cased-xnli\n",
            "Done for Recognai/zeroshot_selectra_medium\n",
            "Done for Recognai/zeroshot_selectra_small\n",
            "Done for Sahajtomar/German_Zeroshot\n",
            "Done for cmarkea/distilcamembert-base-nli\n",
            "Done for cointegrated/rubert-base-cased-nli-threeway\n",
            "Done for cointegrated/rubert-base-cased-nli-twoway\n",
            "Done for cointegrated/rubert-tiny-bilingual-nli\n",
            "Done for cross-encoder/nli-MiniLM2-L6-H768\n",
            "Done for cross-encoder/nli-deberta-base\n",
            "Done for cross-encoder/nli-deberta-v3-base\n",
            "Done for cross-encoder/nli-deberta-v3-large\n",
            "Done for cross-encoder/nli-deberta-v3-small\n",
            "Done for cross-encoder/nli-deberta-v3-xsmall\n",
            "Done for cross-encoder/nli-distilroberta-base\n",
            "Done for digitalepidemiologylab/covid-twitter-bert-v2-mnli\n",
            "Done for emrecan/bert-base-multilingual-cased-allnli_tr\n",
            "Done for emrecan/bert-base-multilingual-cased-multinli_tr\n",
            "Done for emrecan/bert-base-multilingual-cased-snli_tr\n",
            "Done for emrecan/bert-base-turkish-cased-allnli_tr\n",
            "Done for emrecan/bert-base-turkish-cased-multinli_tr\n",
            "Done for emrecan/bert-base-turkish-cased-snli_tr\n",
            "Done for emrecan/convbert-base-turkish-mc4-cased-allnli_tr\n",
            "Done for emrecan/convbert-base-turkish-mc4-cased-multinli_tr\n",
            "Done for emrecan/convbert-base-turkish-mc4-cased-snli_tr\n",
            "Done for emrecan/distilbert-base-turkish-cased-allnli_tr\n",
            "Done for emrecan/distilbert-base-turkish-cased-multinli_tr\n",
            "Done for emrecan/distilbert-base-turkish-cased-snli_tr\n",
            "Done for joeddav/bart-large-mnli-yahoo-answers\n",
            "Done for lighteternal/nli-xlm-r-greek\n",
            "Done for navteca/bart-large-mnli\n",
            "Done for oigele/Fb_improved_zeroshot\n",
            "Done for oigele/awesome_fb_model\n",
            "Done for osanseviero/test_zero\n",
            "Done for seduerr/paiintent\n",
            "Done for svalabs/gbert-large-zeroshot-nli\n",
            "Done for symanto/mpnet-base-snli-mnli\n",
            "Done for symanto/xlm-roberta-base-snli-mnli-anli-xnli\n",
            "Done for typeform/distilbert-base-uncased-mnli\n",
            "Done for typeform/mobilebert-uncased-mnli\n",
            "Done for typeform/roberta-large-mnli\n",
            "Done for typeform/squeezebert-mnli\n",
            "Done for valhalla/distilbart-mnli-12-3\n",
            "Done for valhalla/distilbart-mnli-12-6\n",
            "Done for valhalla/distilbart-mnli-12-9\n",
            "Done for vicgalle/xlm-roberta-large-xnli-anli\n",
            "Done for navteca/nli-deberta-v3-xsmall\n",
            "Done for navteca/nli-deberta-v3-large\n",
            "Done for optimum/distilbert-base-uncased-mnli\n",
            "Done for somosnlp-hackathon-2022/bertin-roberta-base-zeroshot-esnli\n",
            "Done for HiTZ/A2T_RoBERTa_SMFA_ACE-arg\n",
            "Done for HiTZ/A2T_RoBERTa_SMFA_WikiEvents-arg_ACE-arg\n",
            "Done for HiTZ/A2T_RoBERTa_SMFA_WikiEvents-arg\n",
            "Done for HiTZ/A2T_RoBERTa_SMFA_ACE-arg_WikiEvents-arg\n",
            "Done for HiTZ/A2T_RoBERTa_SMFA_TACRED-re\n",
            "Done for eleldar/theme-classification\n",
            "Done for Narsil/bart-large-mnli-opti\n",
            "Done for MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\n",
            "Done for paulhindemith/test-zeroshot\n",
            "Done for paulhindemith/fasttext-classification\n",
            "Done for alexandrainst/scandi-nli-large\n",
            "Done for alexandrainst/scandi-nli-base\n",
            "Done for alexandrainst/scandi-nli-small\n",
            "Done for KBLab/megatron-bert-large-swedish-cased-165-zero-shot\n",
            "Done for morit/french_xlm_xnli\n",
            "Done for morit/english_xlm_xnli\n",
            "Done for morit/chinese_xlm_xnli\n",
            "Done for morit/german_xlm_xnli\n",
            "Done for morit/hindi_xlm_xnli\n",
            "Done for morit/arabic_xlm_xnli\n",
            "Done for PaddlePaddle/utc-large\n",
            "Done for sileod/deberta-v3-base-tasksource-nli\n",
            "Done for ilos-vigil/bigbird-small-indonesian-nli\n",
            "Done for morit/XLM-T-full-xnli\n",
            "Done for farouk1/kimo\n",
            "Done for BSC-LT/sciroshot\n",
            "Done for MoritzLaurer/xlm-v-base-mnli-xnli\n",
            "Done for arnov/name-gender\n",
            "Done for MoritzLaurer/multilingual-MiniLMv2-L6-mnli-xnli\n",
            "Done for MoritzLaurer/multilingual-MiniLMv2-L12-mnli-xnli\n",
            "Done for MoritzLaurer/ernie-m-base-mnli-xnli\n",
            "Done for MoritzLaurer/ernie-m-large-mnli-xnli\n",
            "Done for Warren2005/token_str\n",
            "Done for alramalho/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7-extended-labels\n",
            "Done for sileod/deberta-v3-large-tasksource-nli\n",
            "Done for mazeratti/creative\n",
            "Done for Mel-Iza0/zero-shot\n",
            "Done for AyoubChLin/bart_large_mnli_finetune_cnn_news\n",
            "Done for AyoubChLin/BART-mnli_cnn_256\n",
            "Done for AyoubChLin/Bart-MNLI-CNN_news\n",
            "Done for AyoubChLin/distilBART-mnli-cnn_news\n",
            "Done for Sleoruiz/longformer-base-4096-bne-es-nli\n",
            "Done for Xenova/distilbert-base-uncased-mnli\n",
            "Done for Xenova/bart-large-mnli\n",
            "Done for Xenova/mobilebert-uncased-mnli\n",
            "Done for mjwong/e5-large-mnli\n",
            "Done for TencentARC/QA-CLIP\n",
            "Done for mjwong/e5-large-mnli-anli\n",
            "Done for AntoineBlanot/flan-t5-xxl-classif-3way\n",
            "Done for claritylab/zero-shot-vanilla-binary-bert\n",
            "Done for Atharva192003/zero-shot-classfier\n",
            "Done for claritylab/zero-shot-implicit-binary-bert\n",
            "Done for claritylab/zero-shot-explicit-binary-bert\n",
            "Done for claritylab/zero-shot-vanilla-bi-encoder\n",
            "Done for claritylab/zero-shot-implicit-bi-encoder\n",
            "Done for claritylab/zero-shot-explicit-bi-encoder\n",
            "Done for DAMO-NLP-SG/zero-shot-classify-SSTuning-base\n",
            "Done for mjwong/contriever-mnli\n",
            "Done for mjwong/contriever-msmarco-mnli\n",
            "Done for projecte-aina/roberta-base-ca-v2-cawikitc\n",
            "Done for DAMO-NLP-SG/zero-shot-classify-SSTuning-large\n",
            "Done for DAMO-NLP-SG/zero-shot-classify-SSTuning-ALBERT\n",
            "Done for AntoineBlanot/roberta-nli\n",
            "Done for big91987/111222\n",
            "Done for mjwong/mcontriever-msmarco-xnli\n",
            "Done for mjwong/mcontriever-xnli\n",
            "Done for AyoubChLin/DistilBERT_ZeroShot\n",
            "Done for mjwong/e5-large-v2-mnli\n",
            "Done for mjwong/multilingual-e5-base-xnli\n",
            "Done for pongjin/roberta_with_kornli\n",
            "Done for google/madlad400-3b-mt\n",
            "Done for google-t5/t5-base\n",
            "Done for google-t5/t5-small\n",
            "Done for facebook/mbart-large-50-many-to-many-mmt\n",
            "Done for Helsinki-NLP/opus-mt-tc-big-en-tr\n",
            "Done for facebook/nllb-200-distilled-600M\n",
            "Done for Mitsua/elan-mt-bt-en-ja\n",
            "Done for Helsinki-NLP/opus-mt-es-en\n",
            "Done for NHNDQ/nllb-finetuned-ko2en\n",
            "Done for jbochi/madlad400-3b-mt\n",
            "Done for google-t5/t5-large\n",
            "Done for Helsinki-NLP/opus-mt-en-fr\n",
            "Done for Helsinki-NLP/opus-mt-ja-en\n",
            "Done for Helsinki-NLP/opus-mt-zh-en\n",
            "Done for NHNDQ/nllb-finetuned-en2ko\n",
            "Done for Babelscape/mrebel-large\n",
            "Done for webbigdata/C3TR-Adapter\n",
            "Done for Helsinki-NLP/opus-mt-ar-en\n",
            "Done for Helsinki-NLP/opus-mt-en-es\n",
            "Done for Helsinki-NLP/opus-mt-en-luo\n",
            "Done for Helsinki-NLP/opus-mt-en-zh\n",
            "Done for Helsinki-NLP/opus-mt-it-en\n",
            "Done for Helsinki-NLP/opus-mt-ru-en\n",
            "Done for Helsinki-NLP/opus-mt-tr-en\n",
            "Done for K024/mt5-zh-ja-en-trimmed\n",
            "Done for facebook/wmt21-dense-24-wide-en-x\n",
            "Done for huggingface-course/marian-finetuned-kde4-en-to-fr\n",
            "Done for raynardj/wenyanwen-ancient-translate-to-modern\n",
            "Done for somosnlp-hackathon-2022/t5-small-finetuned-spanish-to-quechua\n",
            "Done for staka/fugumt-en-ja\n",
            "Done for staka/fugumt-ja-en\n",
            "Done for facebook/nllb-200-3.3B\n",
            "Done for facebook/nllb-200-distilled-1.3B\n",
            "Done for nanelimon/bert-base-turkish-bullying\n",
            "Done for VietAI/envit5-translation\n",
            "Done for lgrobol/m2m100_418M_br_fr\n",
            "Done for Shularp/krirk-finetuned-Helsinki-NLP_opus-mt-ar-en\n",
            "Done for Unbabel/wmt22-comet-da\n",
            "Done for Xenova/nllb-200-distilled-600M\n",
            "Done for AI4PD/REXzyme\n",
            "Done for RUCAIBox/Erya4FT\n",
            "Done for Xenova/opus-mt-en-zh\n",
            "Done for DunnBC22/opus-mt-zh-en-Chinese_to_English\n",
            "Done for ayoubkirouane/Med_English2Spanish\n",
            "Done for google/madlad400-10b-mt\n",
            "Done for Unbabel/TowerBase-7B-v0.1\n",
            "Done for Unbabel/TowerInstruct-7B-v0.1\n",
            "Done for santhosh/madlad400-3b-ct2\n",
            "Done for AI4PD/REXzyme_aa\n",
            "Done for flutter-painter/nllb-fra-fuf-v2\n",
            "Done for Unbabel/TowerInstruct-13B-v0.1\n",
            "Done for webbigdata/C3TR-Adapter_gguf\n",
            "Done for oza75/nllb-600M-mt-french-bambara\n",
            "Done for whyJonkerswhy/Zhero\n",
            "Done for lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA\n",
            "Done for Mitsua/elan-mt-bt-ja-en\n",
            "Done for webbigdata/C3TR-Adapter_gptq\n",
            "Done for ronenh24/marian-finetuned-kde4-en-to-zh\n",
            "Done for rudrashah/RLM-hinglish-translator\n",
            "Done for rinto/transformer_wmt_en_de\n",
            "Done for google-t5/t5-11b\n",
            "Done for google-t5/t5-3b\n",
            "Done for Biniam/en_ti_translate\n",
            "Done for CLAck/en-km\n",
            "Done for CLAck/en-vi\n",
            "Done for CLAck/indo-mixed\n",
            "Done for CLAck/indo-pure\n",
            "Done for CLAck/vi-en\n",
            "Done for Helsinki-NLP/opus-mt-NORTH_EU-NORTH_EU\n",
            "Done for Helsinki-NLP/opus-mt-ROMANCE-en\n",
            "Done for Helsinki-NLP/opus-mt-SCANDINAVIA-SCANDINAVIA\n",
            "Done for Helsinki-NLP/opus-mt-aav-en\n",
            "Done for Helsinki-NLP/opus-mt-aed-es\n",
            "Done for Helsinki-NLP/opus-mt-af-de\n",
            "Done for Helsinki-NLP/opus-mt-af-en\n",
            "Done for Helsinki-NLP/opus-mt-af-eo\n",
            "Done for Helsinki-NLP/opus-mt-af-es\n",
            "Done for Helsinki-NLP/opus-mt-af-fi\n",
            "Done for Helsinki-NLP/opus-mt-af-fr\n",
            "Done for Helsinki-NLP/opus-mt-af-nl\n",
            "Done for Helsinki-NLP/opus-mt-af-ru\n",
            "Done for Helsinki-NLP/opus-mt-af-sv\n",
            "Done for Helsinki-NLP/opus-mt-afa-afa\n",
            "Done for Helsinki-NLP/opus-mt-afa-en\n",
            "Done for Helsinki-NLP/opus-mt-alv-en\n",
            "Done for Helsinki-NLP/opus-mt-am-sv\n",
            "Done for Helsinki-NLP/opus-mt-ar-de\n",
            "Done for Helsinki-NLP/opus-mt-ar-el\n",
            "Done for Helsinki-NLP/opus-mt-ar-eo\n",
            "Done for Helsinki-NLP/opus-mt-ar-es\n",
            "Done for Helsinki-NLP/opus-mt-ar-fr\n",
            "Done for Helsinki-NLP/opus-mt-ar-he\n",
            "Done for Helsinki-NLP/opus-mt-ar-it\n",
            "Done for Helsinki-NLP/opus-mt-ar-pl\n",
            "Done for Helsinki-NLP/opus-mt-ar-ru\n",
            "Done for Helsinki-NLP/opus-mt-ar-tr\n",
            "Done for Helsinki-NLP/opus-mt-art-en\n",
            "Done for Helsinki-NLP/opus-mt-ase-de\n",
            "Done for Helsinki-NLP/opus-mt-ase-en\n",
            "Done for Helsinki-NLP/opus-mt-ase-es\n",
            "Done for Helsinki-NLP/opus-mt-ase-fr\n",
            "Done for Helsinki-NLP/opus-mt-ase-sv\n",
            "Done for Helsinki-NLP/opus-mt-az-en\n",
            "Done for Helsinki-NLP/opus-mt-az-es\n",
            "Done for Helsinki-NLP/opus-mt-az-tr\n",
            "Done for Helsinki-NLP/opus-mt-bat-en\n",
            "Done for Helsinki-NLP/opus-mt-bcl-de\n",
            "Done for Helsinki-NLP/opus-mt-bcl-en\n",
            "Done for Helsinki-NLP/opus-mt-bcl-es\n",
            "Done for Helsinki-NLP/opus-mt-bcl-fi\n",
            "Done for Helsinki-NLP/opus-mt-bcl-fr\n",
            "Done for Helsinki-NLP/opus-mt-bcl-sv\n",
            "Done for Helsinki-NLP/opus-mt-be-es\n",
            "Done for Helsinki-NLP/opus-mt-bem-en\n",
            "Done for Helsinki-NLP/opus-mt-bem-es\n",
            "Done for Helsinki-NLP/opus-mt-bem-fi\n",
            "Done for Helsinki-NLP/opus-mt-bem-fr\n",
            "Done for Helsinki-NLP/opus-mt-bem-sv\n",
            "Done for Helsinki-NLP/opus-mt-ber-en\n",
            "Done for Helsinki-NLP/opus-mt-ber-es\n",
            "Done for Helsinki-NLP/opus-mt-ber-fr\n",
            "Done for Helsinki-NLP/opus-mt-bg-de\n",
            "Done for Helsinki-NLP/opus-mt-bg-en\n",
            "Done for Helsinki-NLP/opus-mt-bg-eo\n",
            "Done for Helsinki-NLP/opus-mt-bg-es\n",
            "Done for Helsinki-NLP/opus-mt-bg-fi\n",
            "Done for Helsinki-NLP/opus-mt-bg-fr\n",
            "Done for Helsinki-NLP/opus-mt-bg-it\n",
            "Done for Helsinki-NLP/opus-mt-bg-ru\n",
            "Done for Helsinki-NLP/opus-mt-bg-sv\n",
            "Done for Helsinki-NLP/opus-mt-bg-tr\n",
            "Done for Helsinki-NLP/opus-mt-bg-uk\n",
            "Done for Helsinki-NLP/opus-mt-bi-en\n",
            "Done for Helsinki-NLP/opus-mt-bi-es\n",
            "Done for Helsinki-NLP/opus-mt-bi-fr\n",
            "Done for Helsinki-NLP/opus-mt-bi-sv\n",
            "Done for Helsinki-NLP/opus-mt-bn-en\n",
            "Done for Helsinki-NLP/opus-mt-bnt-en\n",
            "Done for Helsinki-NLP/opus-mt-bzs-en\n",
            "Done for Helsinki-NLP/opus-mt-bzs-es\n",
            "Done for Helsinki-NLP/opus-mt-bzs-fi\n",
            "Done for Helsinki-NLP/opus-mt-bzs-fr\n",
            "Done for Helsinki-NLP/opus-mt-bzs-sv\n",
            "Done for Helsinki-NLP/opus-mt-ca-de\n",
            "Done for Helsinki-NLP/opus-mt-ca-en\n",
            "Done for Helsinki-NLP/opus-mt-ca-es\n",
            "Done for Helsinki-NLP/opus-mt-ca-fr\n",
            "Done for Helsinki-NLP/opus-mt-ca-it\n",
            "Done for facebook/bart-large-cnn\n",
            "Done for Falconsai/text_summarization\n",
            "Done for human-centered-summarization/financial-summarization-pegasus\n",
            "Done for utrobinmv/t5_summary_en_ru_zh_base_2048\n",
            "Done for google/pegasus-large\n",
            "Done for gsarti/it5-base-news-summarization\n",
            "Done for philschmid/bart-large-cnn-samsum\n",
            "Done for kabita-choudhary/finetuned-bart-for-conversation-summary\n",
            "Done for RussianNLP/FRED-T5-Summarizer\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_python_multitask_finetune\n",
            "Done for csebuetnlp/mT5_multilingual_XLSum\n",
            "Done for google/pegasus-cnn_dailymail\n",
            "Done for google/pegasus-xsum\n",
            "Done for plguillou/t5-base-fr-sum-cnndm\n",
            "Done for sshleifer/distilbart-cnn-12-6\n",
            "Done for csebuetnlp/mT5_m2o_chinese_simplified_crossSum\n",
            "Done for IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese\n",
            "Done for jordiclive/flan-t5-3b-summarizer\n",
            "Done for eenzeenee/t5-base-korean-summarization\n",
            "Done for MurkatG/bart-reviews\n",
            "Done for awaisakhtar/llama-2-7b-summarization-finetuned-on-xsum-lora-adapter\n",
            "Done for Falconsai/medical_summarization\n",
            "Done for UNIST-Eunchan/Research-Paper-Summarization-Pegasus-x-ArXiv\n",
            "Done for Huzaifa367/chat-summarizer\n",
            "Done for ronenh24/falconsai_billsum\n",
            "Done for ARTeLab/it5-summarization-fanpage\n",
            "Done for ARTeLab/it5-summarization-ilpost\n",
            "Done for ARTeLab/it5-summarization-mlsum\n",
            "Done for ARTeLab/mbart-summarization-fanpage\n",
            "Done for ARTeLab/mbart-summarization-ilpost\n",
            "Done for ARTeLab/mbart-summarization-mlsum\n",
            "Done for Callidior/bert2bert-base-arxiv-titlegen\n",
            "Done for CalvinHuang/mt5-small-finetuned-amazon-en-es\n",
            "Done for ELiRF/NASCA\n",
            "Done for ELiRF/NASES\n",
            "Done for Einmalumdiewelt/PegasusXSUM_GNAD\n",
            "Done for Einmalumdiewelt/T5-Base_GNAD\n",
            "Done for IlyaGusev/mbart_ru_sum_gazeta\n",
            "Done for IlyaGusev/rubert_telegram_headlines\n",
            "Done for IlyaGusev/rugpt3medium_sum_gazeta\n",
            "Done for IlyaGusev/rut5_base_headline_gen_telegram\n",
            "Done for IlyaGusev/rut5_base_sum_gazeta\n",
            "Done for LeoCordoba/beto2beto-cc-news-es-titles\n",
            "Done for LeoCordoba/beto2beto-mlsum\n",
            "Done for LeoCordoba/mt5-small-cc-news-es-titles\n",
            "Done for LeoCordoba/mt5-small-mlsum\n",
            "Done for LukasStankevicius/t5-base-lithuanian-news-summaries-175\n",
            "Done for MohamedZaitoon/T5-CNN\n",
            "Done for MohamedZaitoon/bart-fine-tune\n",
            "Done for NYTK/summarization-hi-bart-base-1024-hungarian\n",
            "Done for NYTK/summarization-hi-bart-hungarian\n",
            "Done for NYTK/summarization-nol-bart-hungarian\n",
            "Done for Narrativa/bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization\n",
            "Done for Rostlab/prot_t5_base_mt_uniref50\n",
            "Done for SEBIS/code_trans_t5_base_api_generation\n",
            "Done for SEBIS/code_trans_t5_base_api_generation_multitask\n",
            "Done for SEBIS/code_trans_t5_base_api_generation_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_api_generation_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_comment_generation_java\n",
            "Done for SEBIS/code_trans_t5_base_code_comment_generation_java_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_comment_generation_java_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_comment_generation_java_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_go\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_go_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_go_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_go_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_java\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_java_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_java_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_java_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_javascript\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_javascript_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_javascript_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_javascript_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_php\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_php_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_php_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_php_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_python\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_python_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_python_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_ruby\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_ruby_multitask\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_ruby_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_code_documentation_generation_ruby_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_commit_generation\n",
            "Done for SEBIS/code_trans_t5_base_commit_generation_multitask\n",
            "Done for SEBIS/code_trans_t5_base_commit_generation_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_commit_generation_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_program_synthese\n",
            "Done for SEBIS/code_trans_t5_base_program_synthese_multitask\n",
            "Done for SEBIS/code_trans_t5_base_program_synthese_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_program_synthese_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_csharp\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_csharp_multitask\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_csharp_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_csharp_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_python\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_python_multitask\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_python_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_python_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_sql\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_sql_multitask\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_sql_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_base_source_code_summarization_sql_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_api_generation_multitask\n",
            "Done for SEBIS/code_trans_t5_large_api_generation_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_api_generation_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_comment_generation_java_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_comment_generation_java_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_go_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_go_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_go_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_java_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_java_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_java_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_javascript_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_javascript_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_javascript_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_php_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_php_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_php_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_python_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_ruby_multitask\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_ruby_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_code_documentation_generation_ruby_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_commit_generation_multitask\n",
            "Done for SEBIS/code_trans_t5_large_commit_generation_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_commit_generation_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_program_synthese_multitask\n",
            "Done for SEBIS/code_trans_t5_large_program_synthese_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_program_synthese_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_csharp_multitask\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_csharp_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_csharp_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_python_multitask\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_python_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_sql_multitask\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_sql_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_large_source_code_summarization_sql_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_small_api_generation\n",
            "Done for SEBIS/code_trans_t5_small_api_generation_multitask\n",
            "Done for SEBIS/code_trans_t5_small_api_generation_multitask_finetune\n",
            "Done for SEBIS/code_trans_t5_small_api_generation_transfer_learning_finetune\n",
            "Done for SEBIS/code_trans_t5_small_code_comment_generation_java\n",
            "Done for SEBIS/code_trans_t5_small_code_comment_generation_java_multitask\n",
            "Done for BAAI/bge-large-zh-v1.5\n",
            "Done for intfloat/multilingual-e5-large\n",
            "Done for BAAI/bge-large-en-v1.5\n",
            "Done for BAAI/bge-reranker-large\n",
            "Done for mixedbread-ai/mxbai-embed-large-v1\n",
            "Done for intfloat/e5-mistral-7b-instruct\n",
            "Done for dayyass/universal-sentence-encoder-multilingual-large-3-pytorch\n",
            "Done for microsoft/codebert-base\n",
            "Done for Salesforce/SFR-Embedding-Mistral\n",
            "Done for intfloat/multilingual-e5-large-instruct\n",
            "Done for facebook/w2v-bert-2.0\n",
            "Done for BAAI/bge-large-en\n",
            "Done for BAAI/bge-small-en-v1.5\n",
            "Done for jinaai/jina-embeddings-v2-base-zh\n",
            "Done for DeepPavlov/rubert-base-cased\n",
            "Done for BAAI/bge-large-zh\n",
            "Done for BAAI/bge-base-en\n",
            "Done for jinaai/jina-embeddings-v2-base-en\n",
            "Done for jinaai/jina-embeddings-v2-base-code\n",
            "Done for WhereIsAI/UAE-Large-V1\n",
            "Done for DMetaSoul/Dmeta-embedding-zh\n",
            "Done for Xenova/bge-m3\n",
            "Done for jinaai/jina-reranker-v1-turbo-en\n",
            "Done for nvidia/dragon-multiturn-query-encoder\n",
            "Done for nvidia/dragon-multiturn-context-encoder\n",
            "Done for cointegrated/LaBSE-en-ru\n",
            "Done for scutcyr/SoulChat\n",
            "Done for scutcyr/BianQue-2\n",
            "Done for BAAI/bge-base-en-v1.5\n",
            "Done for jinaai/jina-embeddings-v2-small-en\n",
            "Done for BAAI/llm-embedder\n",
            "Done for nvidia/RADIO\n",
            "Done for Mozilla/mxbai-embed-large-v1-llamafile\n",
            "Done for Fujitsu/pytorrent\n",
            "Done for Gilles/FongBERT\n",
            "Done for dmis-lab/biobert-v1.1\n",
            "Done for facebook/bart-large\n",
            "Done for facebook/dpr-question_encoder-single-nq-base\n",
            "Done for facebook/hubert-base-ls960\n",
            "Done for facebook/hubert-large-ll60k\n",
            "Done for gsarti/biobert-nli\n",
            "Done for microsoft/wavlm-base-plus\n",
            "Done for microsoft/wavlm-large\n",
            "Done for ntu-spml/distilhubert\n",
            "Done for razent/cotext-2-cc\n",
            "Done for AiLab-IMCS-UL/lvbert\n",
            "Done for microsoft/BiomedNLP-KRISSBERT-PubMed-UMLS-EL\n",
            "Done for junnyu/structbert-large-zh\n",
            "Done for BM-K/KoSimCSE-roberta-multitask\n",
            "Done for TencentGameMate/chinese-hubert-base\n",
            "Done for TencentGameMate/chinese-hubert-large\n",
            "Done for facebook/dragon-plus-context-encoder\n",
            "Done for netradrishti/u2net-saliency\n",
            "Done for facebook/fasttext-bo-vectors\n",
            "Done for Xipotzzz/blip2zh-chatglm-6b\n",
            "Done for MCFred/bert-base-swedish-uncased-certainly\n",
            "Done for severinsimmler/xlm-roberta-longformer-base-16384\n",
            "Done for Xenova/all-MiniLM-L6-v2\n",
            "Done for almanach/camemberta-base\n",
            "Done for Xenova/paraphrase-multilingual-MiniLM-L12-v2\n",
            "Done for facebook/encodec_24khz\n",
            "Done for BAAI/bge-small-en\n",
            "Done for numind/NuSentiment-multilingual\n",
            "Done for unum-cloud/uform-vl-multilingual-v2\n",
            "Done for sensenova/piccolo-large-zh\n",
            "Done for ShengbinYue/DISC-LawLLM\n",
            "Done for owkin/phikon\n",
            "Done for ibm/MoLFormer-XL-both-10pct\n",
            "Done for ncbi/MedCPT-Article-Encoder\n",
            "Done for ncbi/MedCPT-Query-Encoder\n",
            "Done for laion/larger_clap_music\n",
            "Done for laion/larger_clap_music_and_speech\n",
            "Done for jamesgpt1/sf_model_e5\n",
            "Done for nvidia/E-RADIO\n",
            "Done for danielheinz/e5-base-sts-en-de\n",
            "Done for jinaai/jina-embeddings-v2-base-de\n",
            "Done for ragavsachdeva/magi\n",
            "Done for netease-youdao/Qwen-7B-QAnything\n",
            "Done for jiandong/crimson-embedding-v1.5\n",
            "Done for BAAI/bge-m3-retromae\n",
            "Done for jondurbin/bagel-dpo-20b-v04\n",
            "Done for jondurbin/bagel-20b-v04\n",
            "Done for BAAI/EVA-CLIP-18B\n",
            "Done for hustcw/clap-asm\n",
            "Done for mixedbread-ai/mxbai-embed-2d-large-v1\n",
            "Done for ZhiyuanChen/rnafm\n",
            "Done for DMetaSoul/Dmeta-embedding-zh-small\n",
            "Done for unum-cloud/uform3-image-text-english-small\n",
            "Done for unum-cloud/uform3-image-text-english-base\n",
            "Done for unum-cloud/uform3-image-text-multilingual-base\n",
            "Done for Sunanhe/MedDr_0401\n",
            "Done for amazon/Titan-text-embeddings-v2\n",
            "Done for AI4Chem/ChemLLM-20B-Chat-DPO\n",
            "Done for Avditvs/multilingual-e5-small-distill-base-0.1\n",
            "Done for AbeHou/SemStamp-c4-sbert\n",
            "Done for PhilipGAQ/BGE_M3_Mindspore\n",
            "Done for mahanova/Sichen-Law-7B\n",
            "Done for 3koozy/gpt2-HxH\n",
            "Done for AG/pretraining\n",
            "Done for AlbertHSU/ChineseFoodBert\n",
            "Done for Anonymous/ReasonBERT-BERT\n",
            "Done for Anonymous/ReasonBERT-RoBERTa\n",
            "Done for Anonymous/ReasonBERT-TAPAS\n",
            "Done for AnonymousSub/AR_EManuals-BERT\n",
            "Done for AnonymousSub/AR_EManuals-RoBERTa\n",
            "Done for AnonymousSub/AR_SDR_HF_model_base\n",
            "Done for AnonymousSub/AR_bert-base-uncased\n",
            "Done for AnonymousSub/AR_cline\n",
            "Done for AnonymousSub/AR_consert\n",
            "Done for AnonymousSub/AR_declutr\n",
            "Done for AnonymousSub/AR_rule_based_bert_quadruplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_bert_triplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_hier_quadruplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_hier_triplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_only_classfn_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_only_classfn_twostage_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_bert_quadruplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_bert_quadruplet_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_bert_triplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_bert_triplet_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_hier_quadruplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_hier_quadruplet_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_hier_triplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_hier_triplet_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_only_classfn_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_only_classfn_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_only_classfn_twostage_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_only_classfn_twostage_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostage_quadruplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostage_quadruplet_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostagequadruplet_hier_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostagequadruplet_hier_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostagetriplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostagetriplet_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostagetriplet_hier_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_roberta_twostagetriplet_hier_epochs_1_shard_10\n",
            "Done for AnonymousSub/AR_rule_based_twostage_quadruplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_twostagequadruplet_hier_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_twostagetriplet_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_rule_based_twostagetriplet_hier_epochs_1_shard_1\n",
            "Done for AnonymousSub/AR_specter\n",
            "Done for AnonymousSub/EManuals_BERT_copy\n",
            "Done for AnonymousSub/SDR_HF_model_base\n",
            "Done for AnonymousSub/SR_EManuals-BERT\n",
            "Done for AnonymousSub/SR_EManuals-RoBERTa\n",
            "Done for AnonymousSub/SR_SDR_HF_model_base\n",
            "Done for AnonymousSub/SR_bert-base-uncased\n",
            "Done for AnonymousSub/SR_cline\n",
            "Done for AnonymousSub/SR_consert\n",
            "Done for microsoft/Phi-3-vision-128k-instruct\n",
            "Done for microsoft/Phi-3-medium-128k-instruct\n",
            "Done for THUDM/cogvlm2-llama3-chat-19B\n",
            "Done for microsoft/Phi-3-medium-4k-instruct\n",
            "Done for microsoft/Phi-3-small-128k-instruct\n",
            "Done for abacusai/Smaug-Llama-3-70B-Instruct\n",
            "Done for microsoft/Phi-3-small-8k-instruct\n",
            "Done for openchat/openchat-3.6-8b-20240522\n",
            "Done for microsoft/Phi-3-mini-128k-instruct\n",
            "Done for microsoft/Phi-3-mini-4k-instruct\n",
            "Done for Sao10K/L3-8B-Stheno-v3.1\n",
            "Done for THUDM/cogvlm2-llama3-chinese-chat-19B\n",
            "Done for shenzhi-wang/Llama3-8B-Chinese-Chat\n",
            "Done for NousResearch/Hermes-2-Theta-Llama-3-8B\n",
            "Done for tiiuae/falcon-11B\n",
            "Done for MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
            "Done for nvidia/Llama3-ChatQA-1.5-8B\n",
            "Done for deepseek-ai/DeepSeek-V2-Lite-Chat\n",
            "Done for cognitivecomputations/dolphin-2.9.1-mixtral-1x22b\n",
            "Done for gradientai/Llama-3-8B-Instruct-Gradient-1048k\n",
            "Done for MaziyarPanahi/Mistral-7B-Instruct-v0.3-GGUF\n",
            "Done for ytu-ce-cosmos/Turkish-Llama-8b-v0.1\n",
            "Done for deepseek-ai/DeepSeek-V2-Chat\n",
            "Done for abacusai/Llama-3-Smaug-8B\n",
            "Done for bartowski/LLaMA3-iterative-DPO-final-GGUF\n",
            "Done for bartowski/Phi-3-medium-4k-instruct-GGUF\n",
            "Done for 01-ai/Yi-1.5-34B-Chat\n",
            "Done for bartowski/aya-23-8B-GGUF\n",
            "Done for microsoft/Phi-3-mini-4k-instruct-gguf\n",
            "Done for bartowski/Phi-3-medium-128k-instruct-GGUF\n",
            "Done for RLHFlow/LLaMA3-iterative-DPO-final\n",
            "Done for openai-community/gpt2\n",
            "Done for NousResearch/Hermes-2-Pro-Llama-3-8B\n",
            "Done for shenzhi-wang/Llama3-70B-Chinese-Chat\n",
            "Done for 01-ai/Yi-1.5-34B-32K\n",
            "Done for cognitivecomputations/dolphin-2.9-llama3-8b\n",
            "Done for RLHFlow/pair-preference-model-LLaMA3-8B\n",
            "Done for cognitivecomputations/dolphin-2.9.1-llama-3-70b\n",
            "Done for bartowski/openchat-3.6-8b-20240522-GGUF\n",
            "Done for Qwen/CodeQwen1.5-7B-Chat\n",
            "Done for unsloth/Phi-3-medium-4k-instruct\n",
            "Done for DiscoResearch/Llama3-German-8B\n",
            "Done for defog/llama-3-sqlcoder-8b\n",
            "Done for 01-ai/Yi-1.5-9B-Chat-16K\n",
            "Done for Nitral-AI/Poppy_Porpoise-0.85-L3-8B\n",
            "Done for IlyaGusev/saiga_llama3_8b\n",
            "Done for lmms-lab/llama3-llava-next-8b\n",
            "Done for nvidia/Llama3-ChatQA-1.5-70B\n",
            "Done for Gryphe/Pantheon-RP-1.0-8b-Llama-3\n",
            "Done for deepseek-ai/DeepSeek-V2-Lite\n",
            "Done for gorilla-llm/gorilla-openfunctions-v2\n",
            "Done for deepseek-ai/DeepSeek-V2\n",
            "Done for aaditya/Llama3-OpenBioLLM-70B\n",
            "Done for hfl/llama-3-chinese-8b-instruct-v2\n",
            "Done for leafspark/DeepSeek-V2-Chat-GGUF\n",
            "Done for cognitivecomputations/dolphin-2.9.1-yi-1.5-34b\n",
            "Done for failspy/Llama-3-70B-Instruct-abliterated-v3\n",
            "Done for microsoft/Phi-3-medium-128k-instruct-onnx-cuda\n",
            "Done for kalo-team/llama3-4x8b-pythonT2_step_final\n",
            "Done for Collective-Ai/collective-v0.1-chinese-roleplay-8b\n",
            "Done for bartowski/Mistral-7B-Instruct-v0.3-GGUF\n",
            "Done for bigscience/bloom\n",
            "Done for alpindale/WizardLM-2-8x22B\n",
            "Done for QuantFactory/Meta-Llama-3-8B-Instruct-GGUF\n",
            "Done for McGill-NLP/Llama-3-8B-Web\n",
            "Done for 01-ai/Yi-1.5-9B-Chat\n",
            "Done for 01-ai/Yi-1.5-34B-Chat-16K\n",
            "Done for lmstudio-community/Mistral-7B-Instruct-v0.3-GGUF\n",
            "Done for failspy/Phi-3-medium-4k-instruct-abliterated-v3\n",
            "Done for HuggingFaceH4/zephyr-7b-beta\n",
            "Done for TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
            "Done for Qwen/CodeQwen1.5-7B\n",
            "Done for unsloth/llama-3-8b-Instruct-bnb-4bit\n",
            "Done for refuelai/Llama-3-Refueled\n",
            "Done for NeverSleep/Llama-3-Lumimaid-8B-v0.1-OAS\n",
            "Done for xxx777xxxASD/L3_SnowStorm_4x8B\n",
            "Done for failspy/Phi-3-medium-4k-instruct-abliterated-v3-GGUF\n",
            "Done for allganize/Llama-3-Alpha-Ko-8B-Instruct\n",
            "Done for bartowski/aya-23-35B-GGUF\n",
            "Done for microsoft/Phi-3-mini-4k-instruct-onnx\n",
            "Done for Orenguteng/Llama-3-8B-Lexi-Uncensored\n",
            "Done for 01-ai/Yi-1.5-9B-32K\n",
            "Done for princeton-nlp/Llama-3-Instruct-8B-SimPO\n",
            "Done for bartowski/dolphin-2.9.1-yi-1.5-9b-GGUF\n",
            "Done for failspy/Meta-Llama-3-8B-Instruct-abliterated-v3\n",
            "Done for TheDrummer/Cream-Phi-3-14B-v1\n",
            "Done for adept/fuyu-8b\n",
            "Done for Qwen/Qwen1.5-110B-Chat\n",
            "Done for ibm-granite/granite-8b-code-instruct\n",
            "Done for Bllossom/llama-3-Korean-Bllossom-70B\n",
            "Done for cognitivecomputations/dolphin-2.9.1-yi-1.5-9b\n",
            "Done for grimjim/rogue-enchantress-32k-7B\n",
            "Done for Aratako/Ninja-v1-RP-expressive\n",
            "Done for neuralmagic/Mistral-7B-Instruct-v0.3-GPTQ-4bit\n",
            "Done for shenzhi-wang/Mistral-7B-v0.3-Chinese-Chat\n",
            "Done for microsoft/phi-2\n",
            "Done for Qwen/Qwen1.5-7B-Chat\n",
            "Done for bigcode/starcoder2-15b\n",
            "Done for xai-org/grok-1\n",
            "Done for wenbopan/Faro-Yi-9B-DPO\n",
            "Done for Vikhrmodels/Vikhr-7B-instruct_0.4\n",
            "Done for MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF\n",
            "Done for Snowflake/snowflake-arctic-instruct\n",
            "Done for shenzhi-wang/Llama3-8B-Chinese-Chat-GGUF-8bit\n",
            "Done for lightblue/suzume-llama-3-8B-multilingual\n",
            "Done for NTQAI/Nxcode-CQ-7B-orpo\n",
            "Done for unsloth/Phi-3-mini-4k-instruct\n",
            "Done for 01-ai/Yi-1.5-34B\n",
            "Done for qnguyen3/Master-Yi-9B\n",
            "Done for microsoft/Phi-3-small-128k-instruct-onnx-cuda\n",
            "Done for cognitivecomputations/Dolphin-2.9.1-Phi-3-Kensho-4.5B-abliterated-v3\n",
            "Done for bartowski/Smaug-Llama-3-70B-Instruct-GGUF\n",
            "Done for failspy/Smaug-Llama-3-70B-Instruct-abliterated-v3\n",
            "Done for Undi95/Llama-3-Chatty-2x8B\n",
            "Done for TheBloke/Llama-2-7B-Chat-GGML\n",
            "Done for BioMistral/BioMistral-7B\n",
            "Done for m-a-p/OpenCodeInterpreter-DS-33B\n",
            "Done for sophosympatheia/Midnight-Miqu-70B-v1.5\n",
            "Done for NexaAIDev/Octopus-v2\n",
            "Done for HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1\n",
            "Done for lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\n",
            "Done for CohereForAI/aya-101\n",
            "Done for prometheus-eval/prometheus-7b-v2.0\n",
            "Done for google/flan-t5-base\n",
            "Done for facebook/blenderbot-400M-distill\n",
            "Done for google/flan-t5-xxl\n",
            "Done for MBZUAI/LaMini-Flan-T5-248M\n",
            "Done for dbernsohn/t5_wikisql_en2SQL\n",
            "Done for facebook/mbart-large-50-many-to-one-mmt\n",
            "Done for google/mt5-base\n",
            "Done for google/t5-v1_1-xxl\n",
            "Done for UrukHan/t5-russian-summarization\n",
            "Done for google/switch-c-2048\n",
            "Done for juierror/text-to-sql-with-table-schema\n",
            "Done for lmsys/fastchat-t5-3b-v1.0\n",
            "Done for starmpcc/Asclepius-Llama2-7B\n",
            "Done for prometheus-eval/prometheus-13b-v1.0\n",
            "Done for Vikhrmodels/VikhrT5-240m\n",
            "Done for Vikhrmodels/VikhrT5-3b\n",
            "Done for boun-tabi-LMG/TURNA\n",
            "Done for tarudesu/ViHateT5-base-HSD\n",
            "Done for prometheus-eval/prometheus-8x7b-v2.0\n",
            "Done for SwastikM/bart-large-nl2sql\n",
            "Done for Babelscape/rebel-large\n",
            "Done for ai4bharat/IndicBART\n",
            "Done for dbernsohn/t5_wikisql_SQL2en\n",
            "Done for dbmdz/t5-base-conll03-english\n",
            "Done for facebook/m2m100_1.2B\n",
            "Done for facebook/m2m100_418M\n",
            "Done for flax-community/t5-recipe-generation\n",
            "Done for fnlp/bart-large-chinese\n",
            "Done for google/byt5-small\n",
            "Done for google/mt5-large\n",
            "Done for google/mt5-small\n",
            "Done for google/mt5-xl\n",
            "Done for google/t5-efficient-xxl\n",
            "Done for hyunwoongko/asian-bart-ecjk\n",
            "Done for mrm8488/t5-base-finetuned-emotion\n",
            "Done for mrm8488/t5-base-finetuned-summarize-news\n",
            "Done for mrm8488/t5-base-finetuned-wikiSQL\n",
            "Done for persiannlp/mt5-small-parsinlu-translation_en_fa\n",
            "Done for ai-forever/ruT5-base\n",
            "Done for transformersbook/pegasus-samsum\n",
            "Done for tuner007/pegasus_paraphrase\n",
            "Done for uer/t5-base-chinese-cluecorpussmall\n",
            "Done for vennify/t5-base-grammar-correction\n",
            "Done for allenai/PRIMERA\n",
            "Done for ml6team/mt5-small-german-query-generation\n",
            "Done for google/ul2\n",
            "Done for KeLiu/QETRA_PHP\n",
            "Done for allenai/primera-multi_lexsum-source-long\n",
            "Done for ElnaggarLab/ankh-base\n",
            "Done for Voicelab/vlt5-base-keywords\n",
            "Done for microsoft/GODEL-v1_1-base-seq2seq\n",
            "Done for microsoft/GODEL-v1_1-large-seq2seq\n",
            "Done for bigscience/mt0-small\n",
            "Done for sander-wood/text-to-music\n",
            "Done for google/t5_xxl_true_nli_mixture\n",
            "Done for ybelkada/flan-t5-xl-sharded-bf16\n",
            "Done for merve/chatgpt-prompt-generator-v12\n",
            "Done for Maciel/T5Corrector-base-v2\n",
            "Done for humarin/chatgpt_paraphraser_on_T5_base\n",
            "Done for BelleGroup/BELLE-LLaMA-13B-2M-enc\n",
            "Done for yuyijiong/T5-large-sentiment-analysis-Chinese\n",
            "Done for gaussalgo/T5-LM-Large-text2sql-spider\n",
            "Done for yuyijiong/T5-large-sentiment-analysis-Chinese-MultiTask\n",
            "Done for Salesforce/instructcodet5p-16b\n",
            "Done for unikei/t5-base-split-and-rephrase\n",
            "Done for spacemanidol/flan-t5-large-website-summarizer\n",
            "Done for MRNH/mbart-english-grammar-corrector\n",
            "Done for rkamimae/t5-base-japanese-amazon-title-generation-japanese\n",
            "Done for bond005/FRED-T5-large-ods-ner-2023\n",
            "Done for NEU-HAI/mental-flan-t5-xxl\n",
            "Done for marcchew/LaMini-Flan-T5-248M-Orca-12.5K\n",
            "Done for EleutherAI/pile-t5-large\n",
            "Done for mohitsha/tiny-random-testing-bert2gpt2\n",
            "Done for dima806/flan-t5-small-with-ppo\n",
            "Done for SnypzZz/Llama2-13b-Language-translate\n",
            "Done for Jayveersinh-Raj/hindi-summarizer-small\n",
            "Done for csdc-atl/dialogue-rewriter\n",
            "Done for lmz/candle-blip\n",
            "Done for HiTZ/Medical-mT5-large\n",
            "Done for chentong00/propositionizer-wiki-flan-t5-large\n",
            "Done for TIGER-Lab/TIGERScore-13B\n",
            "Done for rashid996958/machine-tranlation-model\n",
            "Done for castorini/afriteva_v2_base\n",
            "Done for vahn9995/longt5-stable-diffusion-prompt\n",
            "Done for EleutherAI/pile-t5-xxl\n",
            "Done for ashishkgpian/full_v4_astromistral_final\n",
            "Done for gonglinyuan/ast_t5_base\n",
            "Done for lachkarsalim/Helsinki-translation-English_Moroccan-Arabic\n",
            "Done for kcoopermiller/aya-101-GGUF\n",
            "Done for soketlabs/pragna-1b\n",
            "Done for Mr-Vicky-01/Fine_tune_english_to_tamil\n",
            "Done for ai-forever/sage-fredt5-large\n",
            "Done for suriya7/t5-base-text-to-sql\n",
            "Done for tincans-ai/gazelle-v0.2-dpo\n",
            "Done for vngrs-ai/VBART-Small-Base\n",
            "Done for bond005/FRED-T5-large-instruct-v0.1\n",
            "Done for Jeruen/classical_zh_modern_zh\n",
            "Done for Mr-Vicky-01/Facebook-Bart-Qna\n",
            "Done for suriya7/Gemma2B-Finetuned-Sql-Generator\n",
            "Done for Louisko/Policies_summarization\n",
            "Done for zhenchuan/marian-finetuned-kde4-en-to-cn-accelerate\n",
            "Done for textdetox/mt5-xl-detox-baseline\n",
            "Done for atlasia/Transliteration-Moroccan-Darija\n",
            "Done for insilicomedicine/nach0_base\n",
            "Done for yukiarimo/yuna-ai-v3\n",
            "Done for atlasia/Terjman-Large-v0\n",
            "Done for atlasia/Terjman-Supreme\n",
            "Done for atlasia/Terjman-Nano\n",
            "Done for LeroyDyer/Mixtral_AI_LCARS_\n",
            "Done for SlavicNLP/slavicner-lemma-cross-topic-large\n",
            "Done for SlavicNLP/slavicner-linking-cross-topic-large\n",
            "Done for KomeijiForce/Meta-Llama-3-8B-AutoPersona-Chinese\n",
            "Done for Shorya22/BART-Large-Fine_Tunned\n",
            "Done for atlasia/Terjman-Supreme-v2\n",
            "Done for krotima1/BARF-Loop\n",
            "Done for krotima1/AlignSum\n",
            "Done for krotima1/BARF-Align\n",
            "Done for martinkorelic/doc2query-slo-jezikac-v1\n",
            "Done for Xenova/propositionizer-wiki-flan-t5-large\n",
            "Done for antolin/csn-small-biased-random-encoder-decoder-20\n",
            "Done for 0x7o/keyt5-base\n",
            "Done for 0x7o/keyt5-large\n",
            "Done for 13on/kw2t-wishes\n",
            "Done for AI-Lab-Makerere/en_lg\n",
            "Done for AI-Lab-Makerere/lg_en\n",
            "Done for Ahmad/parsT5-base\n",
            "Done for Ahmad/parsT5\n",
            "Done for AhmedSSoliman/MarianCG-CoNaLa\n",
            "Done for AimB/mT5-en-kr-natural\n",
            "Done for Ajaykannan6/autonlp-manthan-16122692\n",
            "Done for AkshaySg/gramCorrection\n",
            "Done for AlekseyKulnevich/Pegasus-HeaderGeneration\n",
            "Done for AlekseyKulnevich/Pegasus-QuestionGeneration\n",
            "Done for AlekseyKulnevich/Pegasus-Summarization\n",
            "Done for Aloka/mbart50-ft-si-en\n",
            "Done for AndreLiu1225/t5-news-summarizer\n",
            "Done for AndreLiu1225/t5-news\n",
            "Done for AnonymousSub/SciFive_pubmedqa_question_generation\n",
            "Done for AnonymousSub/T5_pubmedqa_question_generation\n",
            "Done for Anorak/nirvana\n",
            "Done for Apoorva/k2t-test\n",
            "Done for Aries/T5_question_answering\n",
            "Done for Aries/T5_question_generation\n",
            "Done for Arpita/opus-mt-en-ro-finetuned-syn-to-react\n",
            "Done for ielabgroup/BiTAG-t5-large\n",
            "Done for google-bert/bert-base-uncased\n",
            "Done for google-bert/bert-base-chinese\n",
            "Done for FacebookAI/roberta-base\n",
            "Done for google-bert/bert-large-cased\n",
            "Done for distilbert/distilbert-base-multilingual-cased\n",
            "Done for microsoft/deberta-v3-base\n",
            "Done for microsoft/deberta-v3-large\n",
            "Done for ctheodoris/Geneformer\n",
            "Done for google-bert/bert-base-cased\n",
            "Done for google-bert/bert-base-multilingual-cased\n",
            "Done for google-bert/bert-base-multilingual-uncased\n",
            "Done for google-bert/bert-large-uncased\n",
            "Done for distilbert/distilbert-base-uncased\n",
            "Done for Rostlab/prot_bert\n",
            "Done for asafaya/bert-base-arabic\n",
            "Done for climatebert/distilroberta-base-climate-f\n",
            "Done for microsoft/graphcodebert-base\n",
            "Done for onlplab/alephbert-base\n",
            "Done for naver/splade-cocondenser-ensembledistil\n",
            "Done for ckiplab/bert-tiny-chinese\n",
            "Done for naver/efficient-splade-VI-BT-large-doc\n",
            "Done for Twitter/twhin-bert-large\n",
            "Done for jjzha/jobberta-base\n",
            "Done for InstaDeepAI/nucleotide-transformer-500m-human-ref\n",
            "Done for hazyresearch/M2-BERT-128-Retrieval-Encoder-V1\n",
            "Done for ShortText/JLBert\n",
            "Done for 5CD-AI/viso-twhin-bert-large\n",
            "Done for lots-o/ko-albert-large-v1\n",
            "Done for albert/albert-large-v2\n",
            "Done for distilbert/distilroberta-base\n",
            "Done for FacebookAI/xlm-roberta-large\n",
            "Done for Ayou/chinese_mobile_bert\n",
            "Done for CLTL/MedRoBERTa.nl\n",
            "Done for DeepChem/ChemBERTa-10M-MLM\n",
            "Done for HooshvareLab/bert-base-parsbert-uncased\n",
            "Done for HooshvareLab/bert-fa-base-uncased\n",
            "Done for NbAiLab/nb-bert-base\n",
            "Done for TurkuNLP/bert-base-finnish-cased-v1\n",
            "Done for ahmedrachid/FinancialBERT\n",
            "Done for airesearch/wangchanberta-base-att-spm-uncased\n",
            "Done for anferico/bert-for-patents\n",
            "Done for bayartsogt/structbert-large\n",
            "Done for beomi/kcbert-base\n",
            "Done for cahya/distilbert-base-indonesian\n",
            "Done for castorini/afriberta_base\n",
            "Done for ckiplab/albert-tiny-chinese\n",
            "Done for ckiplab/bert-base-chinese\n",
            "Done for dbernsohn/roberta-php\n",
            "Done for dccuchile/bert-base-spanish-wwm-cased\n",
            "Done for dccuchile/bert-base-spanish-wwm-uncased\n",
            "Done for emilyalsentzer/Bio_ClinicalBERT\n",
            "Done for facebook/xlm-roberta-xxl\n",
            "Done for flax-community/indonesian-roberta-base\n",
            "Done for hfl/chinese-bert-wwm-ext\n",
            "Done for hfl/chinese-roberta-wwm-ext-large\n",
            "Done for huggingface/CodeBERTa-small-v1\n",
            "Done for indigo-ai/BERTino\n",
            "Done for jackaduma/SecBERT\n",
            "Done for jackaduma/SecRoBERTa\n",
            "Done for microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\n",
            "Done for microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract\n",
            "Done for microsoft/deberta-v2-xlarge\n",
            "Done for microsoft/deberta-v2-xxlarge\n",
            "Done for microsoft/deberta-v3-xsmall\n",
            "Done for microsoft/mpnet-base\n",
            "Done for moussaKam/barthez\n",
            "Done for neuralmind/bert-base-portuguese-cased\n",
            "Done for neuralmind/bert-large-portuguese-cased\n",
            "Done for nlpaueb/bert-base-greek-uncased-v1\n",
            "Done for nlpaueb/legal-bert-base-uncased\n",
            "Done for pucpr/biobertpt-all\n",
            "Done for recobo/agriculture-bert-uncased\n",
            "Done for rinna/japanese-roberta-base\n",
            "Done for ai-forever/ruBert-base\n",
            "Done for ai-forever/ruBert-large\n",
            "Done for seyonec/ChemBERTa-zinc-base-v1\n",
            "Done for seyonec/SMILES_tokenized_PubChem_shard00_160k\n",
            "Done for uer/albert-base-chinese-cluecorpussmall\n",
            "Done for uer/chinese_roberta_L-6_H-768\n",
            "Done for yiyanghkust/finbert-pretrain\n",
            "Done for ukr-models/xlm-roberta-base-uk\n",
            "Done for jjzha/jobbert-base-cased\n",
            "Done for Davlan/afro-xlmr-base\n",
            "Done for avichr/Legal-heBERT\n",
            "Done for pile-of-law/legalbert-large-1.7M-2\n",
            "Done for StanfordAIMI/RadBERT\n",
            "Done for pablocosta/bertabaporu-base-uncased\n",
            "Done for maximus12793/CodeBERTa-small-v1-finetuned-cpp\n",
            "Done for Charangan/MedBERT\n",
            "Done for almanach/camembert-bio-base\n",
            "Done for medicalai/ClinicalBERT\n",
            "Done for naver/splade_v2_distil\n",
            "Done for minhtoan/roberta-masked-lm-vietnamese-nom\n",
            "Done for PORTULAN/albertina-900m-portuguese-ptbr-encoder\n",
            "Done for clincolnoz/LessSexistBERT\n",
            "Done for jerteh/Jerteh-355\n",
            "Done for dsfsi/zabantu-xlm-roberta\n",
            "Done for indiejoseph/bert-base-cantonese\n",
            "Done for PORTULAN/albertina-1b5-portuguese-ptbr-encoder\n",
            "Done for togethercomputer/m2-bert-80M-2k\n",
            "Done for PORTULAN/albertina-1b5-portuguese-ptbr-encoder-256\n",
            "Done for hazyresearch/M2-BERT-32K-Retrieval-Encoder-V1\n",
            "Done for Sci-fi-vy/dummy-model\n",
            "Done for eduagarcia/RoBERTaLexPT-base\n",
            "Done for prithivida/Splade_PP_en_v2\n",
            "Done for faisalq/SaudiBERT\n",
            "Done for 5CD-AI/visobert-14gb-corpus\n",
            "Done for hon9kon9ize/bert-large-cantonese\n",
            "Done for isemmanuelolowe/BerKANT_171M\n",
            "Done for neody/ja-bert-1\n",
            "Done for prithivMLmods/Betelgeuse-bert-base-uncased\n",
            "Done for ronenh24/distilbert-base-uncased-finetuned-imdb\n",
            "Done for antolin/csn-small-biased-random-20\n",
            "Done for hazyresearch/M2-BERT-2k-Retrieval-Encoder-V1\n",
            "Done for hazyresearch/M2-BERT-8k-Retrieval-Encoder-V1\n",
            "Done for antolin/csn-small-unbiased-random-20\n",
            "Done for antolin/csn-small-biased-random-20-l6\n",
            "Done for adibvafa/CodonTransformer\n",
            "Done for albert/albert-base-v1\n",
            "Done for albert/albert-base-v2\n",
            "Done for albert/albert-large-v1\n",
            "Done for albert/albert-xlarge-v1\n",
            "Done for albert/albert-xlarge-v2\n",
            "Done for albert/albert-xxlarge-v1\n",
            "Done for albert/albert-xxlarge-v2\n",
            "Done for google-bert/bert-base-cased-finetuned-mrpc\n",
            "Done for google-bert/bert-base-german-cased\n",
            "Done for google-bert/bert-base-german-dbmdz-cased\n",
            "Done for google-bert/bert-base-german-dbmdz-uncased\n",
            "Done for google-bert/bert-large-cased-whole-word-masking\n",
            "Done for google-bert/bert-large-uncased-whole-word-masking\n",
            "Done for almanach/camembert-base\n",
            "Done for distilbert/distilbert-base-cased\n",
            "Done for distilbert/distilbert-base-german-cased\n",
            "Done for FacebookAI/roberta-large\n",
            "Done for FacebookAI/xlm-clm-ende-1024\n",
            "Done for FacebookAI/xlm-clm-enfr-1024\n",
            "Done for FacebookAI/xlm-mlm-100-1280\n",
            "Done for FacebookAI/xlm-mlm-17-1280\n",
            "Done for FacebookAI/xlm-mlm-en-2048\n",
            "Done for FacebookAI/xlm-mlm-ende-1024\n",
            "Done for FacebookAI/xlm-mlm-enfr-1024\n",
            "Done for FacebookAI/xlm-mlm-enro-1024\n",
            "Done for FacebookAI/xlm-mlm-tlm-xnli15-1024\n",
            "Done for FacebookAI/xlm-mlm-xnli15-1024\n",
            "Done for sentence-transformers/all-MiniLM-L6-v2\n",
            "Done for BAAI/bge-m3\n",
            "Done for nomic-ai/nomic-embed-text-v1.5\n",
            "Done for sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "Done for sentence-transformers/all-mpnet-base-v2\n",
            "Done for aspire/acge_text_embedding\n",
            "Done for Alibaba-NLP/gte-large-en-v1.5\n",
            "Done for hkunlp/instructor-xl\n",
            "Done for nomic-ai/nomic-embed-text-v1\n",
            "Done for intfloat/multilingual-e5-base\n",
            "Done for sentence-transformers/all-MiniLM-L12-v2\n",
            "Done for shibing624/text2vec-base-chinese\n",
            "Done for intfloat/e5-large-v2\n",
            "Done for Snowflake/snowflake-arctic-embed-l\n",
            "Done for McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised\n",
            "Done for jhgan/ko-sroberta-multitask\n",
            "Done for hkunlp/instructor-large\n",
            "Done for intfloat/multilingual-e5-small\n",
            "Done for thenlper/gte-large\n",
            "Done for dangvantuan/sentence-camembert-large\n",
            "Done for mrp/simcse-model-m-bert-thai-cased\n",
            "Done for sentence-transformers/LaBSE\n",
            "Done for sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
            "Done for sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
            "Done for sentence-transformers/paraphrase-xlm-r-multilingual-v1\n",
            "Done for bespin-global/klue-sroberta-base-continue-learning-by-mnr\n",
            "Done for basel/ATTACK-BERT\n",
            "Done for intfloat/e5-base-v2\n",
            "Done for NeuML/pubmedbert-base-embeddings\n",
            "Done for thenlper/gte-large-zh\n",
            "Done for antoinelouis/colbert-xm\n",
            "Done for infgrad/stella-base-zh-v3-1792d\n",
            "Done for manu/bge-m3-custom-fr\n",
            "Done for Alibaba-NLP/gte-base-en-v1.5\n",
            "Done for LazarusNLP/all-nusabert-large-v4\n",
            "Done for ashrafulparan/Semantic-Textual-Relatedness-Telugu\n",
            "Done for AI-Growth-Lab/PatentSBERTa\n",
            "Done for Muennighoff/SGPT-125M-mean-nli\n",
            "Done for Vasanth/multi-qa-MiniLM-L6-cos-v1-qa-squad2-retriever\n",
            "Done for flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\n",
            "Done for hiiamsid/sentence_similarity_spanish_es\n",
            "Done for jglaser/protein-ligand-mlp-3\n",
            "Done for jhgan/ko-sbert-nli\n",
            "Done for jhgan/ko-sbert-sts\n",
            "Done for pritamdeka/S-Scibert-snli-multinli-stsb\n",
            "Done for sentence-transformers/clip-ViT-B-32\n",
            "Done for sentence-transformers/distiluse-base-multilingual-cased-v2\n",
            "Done for sentence-transformers/gtr-t5-large\n",
            "Done for sentence-transformers/gtr-t5-xxl\n",
            "Done for sentence-transformers/msmarco-distilbert-cos-v5\n",
            "Done for sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n",
            "Done for sentence-transformers/paraphrase-MiniLM-L12-v2\n",
            "Done for sentence-transformers/paraphrase-MiniLM-L3-v2\n",
            "Done for sentence-transformers/paraphrase-MiniLM-L6-v2\n",
            "Done for sentence-transformers/paraphrase-distilroberta-base-v2\n",
            "Done for Voicelab/sbert-base-cased-pl\n",
            "Done for snunlp/KR-SBERT-V40K-klueNLI-augSTS\n",
            "Done for sdadas/st-polish-paraphrase-from-distilroberta\n",
            "Done for rufimelo/bert-large-portuguese-cased-sts\n",
            "Done for pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\n",
            "Done for PM-AI/bi-encoder_msmarco_bert-base_german\n",
            "Done for hkunlp/instructor-base\n",
            "Done for intfloat/e5-base\n",
            "Done for Sakil/sentence_similarity_semantic_search\n",
            "Done for GanymedeNil/text2vec-large-chinese\n",
            "Done for nickprock/sentence-bert-base-italian-xxl-uncased\n",
            "Done for intfloat/e5-small-v2\n",
            "Done for jinaai/jina-embedding-l-en-v1\n",
            "Done for thenlper/gte-small\n",
            "Done for TaylorAI/bge-micro-v2\n",
            "Done for Seznam/simcse-retromae-small-cs\n",
            "Done for togethercomputer/m2-bert-80M-8k-retrieval\n",
            "Done for togethercomputer/m2-bert-80M-32k-retrieval\n",
            "Done for Amu/tao-8k\n",
            "Done for thenlper/gte-base-zh\n",
            "Done for kev216/sentence-embedding-LaBSE\n",
            "Done for togethercomputer/m2-bert-80M-2k-retrieval\n",
            "Done for kornwtp/SCT-model-wangchanberta\n",
            "Done for avsolatorio/GIST-Embedding-v0\n",
            "Done for antoinelouis/dpr-xm\n",
            "Done for infgrad/stella-large-zh-v3-1792d\n",
            "Done for sosoai/multilingual-mpnet-base-v2-embedding-all-safetensor\n",
            "Done for NeuML/pubmedbert-base-embeddings-matryoshka\n",
            "Done for infgrad/stella-mrl-large-zh-v3.5-1792d\n",
            "Done for siberian-lang-lab/evenki-russian-parallel-corpora\n",
            "Done for bclavie/JaColBERTv2\n",
            "Done for BEE-spoke-data/bert-plus-L8-v1.0-syntheticSTS-4k\n",
            "Done for lang-uk/ukr-paraphrase-multilingual-mpnet-base\n",
            "Done for infgrad/puff-base-v1\n",
            "Done for dwulff/mpnet-personality\n",
            "Done for Snowflake/snowflake-arctic-embed-m\n",
            "Done for Snowflake/snowflake-arctic-embed-m-long\n",
            "Done for ciCic/paraphrase-multilingual-MiniLM-L12-v2-sts-2d-matryoshka\n",
            "Done for pt-mteb/average_pt_nilc_fasttext_skip_s1000\n",
            "Done for pt-mteb/average_pt_nilc_glove_s1000\n",
            "Done for pt-mteb/average_pt_nilc_wang2vec_skip_s1000\n",
            "Done for pt-mteb/average_pt_nilc_word2vec_skip_s1000\n",
            "Done for dwzhu/e5rope-base\n",
            "Done for FinLang/finance-embeddings-investopedia\n",
            "Done for manu/sentence_croissant_alpha_v0.4\n",
            "Done for McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\n",
            "Done for h4g3n/multilingual-MiniLM-L12-de-en-es-fr-it-nl-pl-pt\n",
            "Done for belyakoff/XLM-RoBERTa-485\n",
            "Done for tim1900/BertChunker\n",
            "Done for pranay-j/quora-query-aligner-matryoshka\n",
            "Done for Baiming123/Connection_Building_Method_Disease\n",
            "Done for MOADdev/multilingual-e5-large-amethyst\n",
            "Done for bobox/DeBERTaV3-Large-SentenceTransformer-0.01\n",
            "Done for bobox/DeBERTaV2-XL-SentenceTransformer-0.02\n",
            "Done for nizamovtimur/multilingual-e5-large-wikiutmn\n",
            "Done for ashrafulparan/Semantic-Textual-Relatedness-English\n",
            "Done for ashrafulparan/Semantic-Textual-Relatedness-Spanish\n",
            "Done for ashrafulparan/Semantic-Textual-Relatedness-Marathi\n",
            "Done for thehosy/roberta-base-qa-vietnamese\n",
            "Done for AIDA-UPM/MSTSb_paraphrase-multilingual-MiniLM-L12-v2\n",
            "Done for AIDA-UPM/MSTSb_paraphrase-xlm-r-multilingual-v1\n",
            "Done for AIDA-UPM/MSTSb_stsb-xlm-r-multilingual\n",
            "Done for AIDA-UPM/mstsb-paraphrase-multilingual-mpnet-base-v2\n",
            "Done for DataikuNLP/average_word_embeddings_glove.6B.300d\n",
            "Done for DataikuNLP/distiluse-base-multilingual-cased-v1\n",
            "Done for DataikuNLP/paraphrase-MiniLM-L6-v2\n",
            "Done for DataikuNLP/paraphrase-albert-small-v2\n",
            "Done for DataikuNLP/paraphrase-multilingual-MiniLM-L12-v2\n",
            "Done for GPL/bioasq-1m-msmarco-distilbert-gpl\n",
            "Done for GPL/bioasq-1m-tsdae-msmarco-distilbert-gpl\n",
            "Done for GPL/cqadupstack-msmarco-distilbert-gpl\n",
            "Done for GPL/cqadupstack-tsdae-msmarco-distilbert-gpl\n",
            "Done for GPL/fiqa-msmarco-distilbert-gpl\n",
            "Done for GPL/fiqa-tsdae-msmarco-distilbert-gpl\n",
            "Done for GPL/robust04-msmarco-distilbert-gpl\n",
            "Done for GPL/robust04-tsdae-msmarco-distilbert-gpl\n",
            "Done for GPL/scifact-msmarco-distilbert-gpl\n",
            "Done for GPL/trec-covid-v2-msmarco-distilbert-gpl\n",
            "Done for GeniusVoice/gv-semanticsearch-dutch-cased\n",
            "Done for Humair/all-mpnet-base-v2-finetuned-v2\n",
            "Done for KBLab/sentence-bert-swedish-cased\n",
            "Done for Muennighoff/SBERT-base-msmarco-asym\n",
            "Done for Muennighoff/SBERT-base-msmarco-bitfit\n",
            "Done for Muennighoff/SBERT-base-msmarco\n",
            "Done for Muennighoff/SBERT-base-nli-stsb-v2\n",
            "Done for Muennighoff/SBERT-base-nli-v2-bitfit\n",
            "Done for Muennighoff/SBERT-base-nli-v2\n",
            "Done for Muennighoff/SBERT-large-nli-v2\n",
            "Done for Muennighoff/SGPT-1.3B-mean-nli\n",
            "Done for Muennighoff/SGPT-1.3B-weightedmean-nli-bitfit\n",
            "Done for Muennighoff/SGPT-1.3B-weightedmean-nli\n",
            "Done for Muennighoff/SGPT-125M-lasttoken-msmarco-specb\n",
            "Done for Muennighoff/SGPT-125M-lasttoken-nli\n",
            "Done for Muennighoff/SGPT-125M-learntmean-nli\n",
            "Done for coqui/XTTS-v2\n",
            "Done for parler-tts/parler-tts-mini-expresso\n",
            "Done for myshell-ai/OpenVoiceV2\n",
            "Done for suno/bark\n",
            "Done for WhisperSpeech/WhisperSpeech\n",
            "Done for parler-tts/parler_tts_mini_v0.1\n",
            "Done for microsoft/speecht5_tts\n",
            "Done for fishaudio/fish-speech-1\n",
            "Done for suno/bark-small\n",
            "Done for facebook/seamless-streaming\n",
            "Done for metavoiceio/metavoice-1B-v0.1\n",
            "Done for myshell-ai/MeloTTS-English\n",
            "Done for ShoukanLabs/Vokan\n",
            "Done for capleaf/viXTTS\n",
            "Done for nvidia/tts_en_fastpitch\n",
            "Done for facebook/mms-tts\n",
            "Done for facebook/mms-tts-fon\n",
            "Done for audo/seamless-m4t-v2-large\n",
            "Done for kotoba-tech/kotoba-speech-v0.1\n",
            "Done for NeuML/ljspeech-jets-onnx\n",
            "Done for facebook/mms-tts-eng\n",
            "Done for facebook/mms-tts-crh\n",
            "Done for coqui/XTTS-v1\n",
            "Done for facebook/hf-seamless-m4t-large\n",
            "Done for SeyedAli/Arabic-Speech-synthesis-MMS\n",
            "Done for Xenova/mms-tts-por\n",
            "Done for MomoyamaSawa/GPT-SoVITS_KusanagiNene\n",
            "Done for AIHeaven/piper_unofficial_voices\n",
            "Done for MBZUAI/speecht5_tts_clartts_ar\n",
            "Done for Pendrokar/xvapitch_nvidia\n",
            "Done for shibing624/parrots-gpt-sovits-speaker\n",
            "Done for shibing624/parrots-gpt-sovits-speaker-maimai\n",
            "Done for myshell-ai/MeloTTS-Spanish\n",
            "Done for myshell-ai/MeloTTS-Chinese\n",
            "Done for ThePioneer/MyVoiceClone-Style-Bert-VITS2\n",
            "Done for songboai/SoVITS_sunwukong\n",
            "Done for Naozumi0512/bert-vits2-yue\n",
            "Done for RaivisDejus/Piper-lv_LV-Aivars-medium\n",
            "Done for utrobinmv/tts_ru_free_hf_vits_low_multispeaker\n",
            "Done for GunnarThor/talromur_f_tacotron2\n",
            "Done for bayartsogt/tts_transformer-mn-mbspeech\n",
            "Done for dathudeptrai/tts-tacotron2-synpaflex-fr\n",
            "Done for espnet/kan-bayashi_csmsc_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_csmsc_fastspeech\n",
            "Done for espnet/kan-bayashi_csmsc_fastspeech2\n",
            "Done for espnet/kan-bayashi_csmsc_full_band_vits\n",
            "Done for espnet/kan-bayashi_csmsc_tacotron2\n",
            "Done for espnet/kan-bayashi_csmsc_transformer\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_conformer_fastspeech2_raw_phn_pypinyin_g2p_phone_train.loss.ave\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_fastspeech2_raw_phn_pypinyin_g2p_phone_train.loss.ave\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_fastspeech_raw_phn_pypinyin_g2p_phone_train.loss.best\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_full_band_vits_raw_phn_pypinyin_g2p_phone_train.total_count.ave\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_tacotron2_raw_phn_pypinyin_g2p_phone_train.loss.best\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_transformer_raw_phn_pypinyin_g2p_phone_train.loss.ave\n",
            "Done for espnet/kan-bayashi_csmsc_tts_train_vits_raw_phn_pypinyin_g2p_phone_train.total_count.ave\n",
            "Done for espnet/kan-bayashi_csmsc_vits\n",
            "Done for espnet/kan-bayashi_jsut_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_jsut_conformer_fastspeech2_accent\n",
            "Done for espnet/kan-bayashi_jsut_conformer_fastspeech2_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jsut_conformer_fastspeech2_tacotron2_prosody\n",
            "Done for espnet/kan-bayashi_jsut_conformer_fastspeech2_transformer_prosody\n",
            "Done for espnet/kan-bayashi_jsut_fastspeech\n",
            "Done for espnet/kan-bayashi_jsut_fastspeech2\n",
            "Done for espnet/kan-bayashi_jsut_fastspeech2_accent\n",
            "Done for espnet/kan-bayashi_jsut_fastspeech2_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jsut_full_band_vits_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jsut_full_band_vits_prosody\n",
            "Done for espnet/kan-bayashi_jsut_tacotron2\n",
            "Done for espnet/kan-bayashi_jsut_tacotron2_accent\n",
            "Done for espnet/kan-bayashi_jsut_tacotron2_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jsut_tacotron2_prosody\n",
            "Done for espnet/kan-bayashi_jsut_transformer\n",
            "Done for espnet/kan-bayashi_jsut_transformer_accent\n",
            "Done for espnet/kan-bayashi_jsut_transformer_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jsut_transformer_prosody\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_raw_phn_jaconv_pyopenjtalk_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_tacotron2_teacher_raw-truncated-15ef5f\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_tacotron2_teacher_raw-truncated-a7f080\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_tacotron2_teacher_raw-truncated-569e81\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_transformer_teacher_r-truncated-35ef5a\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_transformer_teacher_r-truncated-74c1b4\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_conformer_fastspeech2_transformer_teacher_r-truncated-f43d8f\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_fastspeech2_raw_phn_jaconv_pyopenjtalk_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_fastspeech2_tacotron2_teacher_raw_phn_jacon-truncated-f45dcb\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_fastspeech2_tacotron2_teacher_raw_phn_jacon-truncated-e5d906\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_fastspeech2_transformer_teacher_raw_phn_jac-truncated-6f4cf5\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_fastspeech2_transformer_teacher_raw_phn_jac-truncated-60fc24\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_fastspeech_raw_phn_jaconv_pyopenjtalk_train.loss.best\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_full_band_vits_raw_phn_jaconv_pyopenjtalk_a-truncated-d7d5d0\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_full_band_vits_raw_phn_jaconv_pyopenjtalk_p-truncated-66d5fc\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_tacotron2_raw_phn_jaconv_pyopenjtalk_accent_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_tacotron2_raw_phn_jaconv_pyopenjtalk_accent_with_pause_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_tacotron2_raw_phn_jaconv_pyopenjtalk_prosody_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_tacotron2_raw_phn_jaconv_pyopenjtalk_train.loss.best\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_transformer_raw_phn_jaconv_pyopenjtalk_accent_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_transformer_raw_phn_jaconv_pyopenjtalk_acce-truncated-be0f66\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_transformer_raw_phn_jaconv_pyopenjtalk_prosody_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_transformer_raw_phn_jaconv_pyopenjtalk_train.loss.ave\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_vits_raw_phn_jaconv_pyopenjtalk_accent_with-truncated-ba3566\n",
            "Done for espnet/kan-bayashi_jsut_tts_train_vits_raw_phn_jaconv_pyopenjtalk_prosody_train.total_count.ave\n",
            "Done for espnet/kan-bayashi_jsut_vits_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jsut_vits_prosody\n",
            "Done for espnet/kan-bayashi_jvs_jvs001_vits_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jvs_jvs010_vits_accent_with_pause\n",
            "Done for espnet/kan-bayashi_jvs_jvs010_vits_prosody\n",
            "Done for espnet/kan-bayashi_jvs_tts_finetune_jvs001_jsut_vits_raw_phn_jaconv_pyopenjta-truncated-178804\n",
            "Done for espnet/kan-bayashi_jvs_tts_finetune_jvs010_jsut_vits_raw_phn_jaconv_pyopenjta-truncated-d57a28\n",
            "Done for espnet/kan-bayashi_jvs_tts_finetune_jvs010_jsut_vits_raw_phn_jaconv_pyopenjtalk_prosody_latest\n",
            "Done for espnet/kan-bayashi_libritts_gst_xvector_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_libritts_gst_xvector_trasnformer\n",
            "Done for espnet/kan-bayashi_libritts_tts_train_gst_xvector_conformer_fastspeech2_trans-truncated-c3209b\n",
            "Done for espnet/kan-bayashi_libritts_tts_train_gst_xvector_trasnformer_raw_phn_tacotro-truncated-250027\n",
            "Done for espnet/kan-bayashi_libritts_tts_train_xvector_conformer_fastspeech2_transform-truncated-42b443\n",
            "Done for espnet/kan-bayashi_libritts_tts_train_xvector_trasnformer_raw_phn_tacotron_g2-truncated-e5fb13\n",
            "Done for espnet/kan-bayashi_libritts_tts_train_xvector_vits_raw_phn_tacotron_g2p_en_no-truncated-09d645\n",
            "Done for espnet/kan-bayashi_libritts_xvector_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_libritts_xvector_trasnformer\n",
            "Done for espnet/kan-bayashi_libritts_xvector_vits\n",
            "Done for espnet/kan-bayashi_ljspeech_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_ljspeech_fastspeech\n",
            "Done for espnet/kan-bayashi_ljspeech_fastspeech2\n",
            "Done for espnet/kan-bayashi_ljspeech_joint_finetune_conformer_fastspeech2_hifigan\n",
            "Done for espnet/kan-bayashi_ljspeech_joint_train_conformer_fastspeech2_hifigan\n",
            "Done for espnet/kan-bayashi_ljspeech_tacotron2\n",
            "Done for espnet/kan-bayashi_ljspeech_transformer\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_finetune_joint_conformer_fastspeech2_hifigan_-truncated-737899\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_conformer_fastspeech2_raw_phn_tacotron_-truncated-ec9e34\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_fastspeech2_raw_phn_tacotron_g2p_en_no_space_train.loss.ave\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_fastspeech_raw_phn_tacotron_g2p_en_no_space_train.loss.best\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_joint_conformer_fastspeech2_hifigan_raw-truncated-af8fe0\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train.loss.best\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_transformer_raw_phn_tacotron_g2p_en_no_space_train.loss.ave\n",
            "Done for espnet/kan-bayashi_ljspeech_tts_train_vits_raw_phn_tacotron_g2p_en_no_space_train.total_count.ave\n",
            "Done for espnet/kan-bayashi_ljspeech_vits\n",
            "Done for espnet/kan-bayashi_tsukuyomi_full_band_vits_prosody\n",
            "Done for espnet/kan-bayashi_tsukuyomi_tts_finetune_full_band_jsut_vits_raw_phn_jaconv_pyopenjtalk_prosody_latest\n",
            "Done for espnet/kan-bayashi_vctk_full_band_multi_spk_vits\n",
            "Done for espnet/kan-bayashi_vctk_gst_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_vctk_gst_fastspeech\n",
            "Done for espnet/kan-bayashi_vctk_gst_fastspeech2\n",
            "Done for espnet/kan-bayashi_vctk_gst_tacotron2\n",
            "Done for espnet/kan-bayashi_vctk_gst_transformer\n",
            "Done for espnet/kan-bayashi_vctk_gst_xvector_conformer_fastspeech2\n",
            "Done for espnet/kan-bayashi_vctk_gst_xvector_tacotron2\n",
            "Done for espnet/kan-bayashi_vctk_gst_xvector_transformer\n",
            "Done for espnet/kan-bayashi_vctk_multi_spk_vits\n",
            "Done for espnet/kan-bayashi_vctk_tts_train_full_band_multi_spk_vits_raw_phn_tacotron_g-truncated-50b003\n",
            "Done for espnet/kan-bayashi_vctk_tts_train_gst_conformer_fastspeech2_raw_phn_tacotron_-truncated-69081b\n",
            "Done for espnet/kan-bayashi_vctk_tts_train_gst_fastspeech2_raw_phn_tacotron_g2p_en_no_space_train.loss.ave\n",
            "Done for espnet/kan-bayashi_vctk_tts_train_gst_fastspeech_raw_phn_tacotron_g2p_en_no_space_train.loss.best\n",
            "Done for facebook/musicgen-small\n",
            "Done for nateraw/musicgen-songstarter-v0.2\n",
            "Done for facebook/musicgen-stereo-melody-large\n",
            "Done for facebook/musicgen-melody\n",
            "Done for facebook/musicgen-medium\n",
            "Done for facebook/musicgen-large\n",
            "Done for facebook/musicgen-melody-large\n",
            "Done for declare-lab/mustango-pretrained\n",
            "Done for procit001/vits_welsh_female_monospeaker_dutch_female_v2\n",
            "Done for Xenova/musicgen-small\n",
            "Done for declare-lab/tango2\n",
            "Done for mrmuminov/speecht5_tts_common_voice_uz\n",
            "Done for bfh-genai/meditation-musicgen\n",
            "Done for karlwennerstrom/text-to-music\n",
            "Done for sweet-dreambooths/musicgen-songstarter-v0.2-hf\n",
            "Done for riffusion/riffusion-model-v1\n",
            "Done for flax/riffusion-model-v1\n",
            "Done for jm12138/riffusion-model-v1\n",
            "Done for flax/anything-v3-vae-swapped\n",
            "Done for flax/dreamlike-diffusion-1.0\n",
            "Done for flax/Analog-Diffusion\n",
            "Done for flax/openjourney-v2\n",
            "Done for flax/vintedois-diffusion-v0-1\n",
            "Done for flax/knollingcase\n",
            "Done for flax/Comic-Diffusion\n",
            "Done for flax/Complex-Lineart\n",
            "Done for flax/SynthwavePunk-v2\n",
            "Done for jumang4423/ninjumango-jumango-v1-0\n",
            "Done for Matthijs/speecht5_tts_voxpopuli_nl\n",
            "Done for lysandre/text-to-speech-pipeline\n",
            "Done for SHENMU007/speecht5_tts_voxpopuli_nl\n",
            "Done for emre/speecht5_tts_tr\n",
            "Done for declare-lab/tango\n",
            "Done for csalguer/speecht5_tts_vivos\n",
            "Done for SHENMU007/neunit0424\n",
            "Done for ralsuwaidi/speecht5_tts_voxpopuli_nl\n",
            "Done for SHENMU007/neunit0425\n",
            "Done for SHENMU007/neunit0425_base\n",
            "Done for SHENMU007/neunit0425_v1\n",
            "Done for SHENMU007/neunit_BASE\n",
            "Done for SHENMU007/neunit_BASE_V2\n",
            "Done for SHENMU007/neunit_BASE_V3\n",
            "Done for Ganyarnat/speecht5_tts_voxpopuli_nl\n",
            "Done for LisanneH/speecht5_tts_voxpopuli_nl\n",
            "Done for JSimaj7337/speecht5_tts_voxpopuli_es\n",
            "Done for SHENMU007/neunit_BASE_V4\n",
            "Done for SHENMU007/neunit_BASE_V5\n",
            "Done for SHENMU007/neunit_BASE_V5.1\n",
            "Done for abhinav3333/speecht5_tts_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_BASE_V5.2\n",
            "Done for YeQing/speecht5_tts_voxpopuli_nl\n",
            "Done for YeQing/speecht5_tts_commonvioce_zh\n",
            "Done for SaberMolaei/speecht5_ckb\n",
            "Done for SaberMolaei/speecht5_tts_ckb\n",
            "Done for Saifkhan0012/speecht5_tts_voxpopuli_nl\n",
            "Done for KauPage/speecht5_tts_SVM_mr\n",
            "Done for SaberMolaei/speecht5_tts_ckb0\n",
            "Done for SaberMolaei/speecht5_tts_ckb5\n",
            "Done for premgadwal/speecht5_tts_voxpopuli_nl\n",
            "Done for kika2000/speecht5_tts_voxpopuli_nl\n",
            "Done for Ktang2k/speecht5_tts_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_test\n",
            "Done for sofa566/speecht5_finetuned_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_testv1.1\n",
            "Done for SHENMU007/neunit_tts_1.0\n",
            "Done for SHENMU007/neunit_tts_1.1\n",
            "Done for SHENMU007/neunit_tts_BASE_V4.1\n",
            "Done for SHENMU007/neunit_tts_BASE_V4.2\n",
            "Done for takapiro99/speecht5_tts_voxpopuli_nl\n",
            "Done for spygaurad/speecht5_tts_ne_v2\n",
            "Done for SHENMU007/neunit_tts_BASE_V4.3\n",
            "Done for junyinc/LING575-SPR-TTS\n",
            "Done for theothertom/emo_t5_speech_chkpt\n",
            "Done for SHENMU007/neunit_tts_BASE_V1.0\n",
            "Done for SurendraKumarDhaka/speecht5_finetuned_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_tts_BASE_V1.1\n",
            "Done for SHENMU007/neunit_tts_BASE_V1.2\n",
            "Done for SHENMU007/neunit_tts_BASE_V1.3\n",
            "Done for declare-lab/tango-full-ft-audiocaps\n",
            "Done for thoth-AI/testing-TTS\n",
            "Done for SHENMU007/neunit_BASE_V7\n",
            "Done for LisanneH/speecht5_tts_commonvoice_nl\n",
            "Done for wetdog/speecht5_tts_commonvoice_ca\n",
            "Done for LisanneH/speecht5_tts_commonvoice_nl_1\n",
            "Done for SHENMU007/neunit_BASE_V7.1\n",
            "Done for SHENMU007/neunit_BASE_V7.2\n",
            "Done for SHENMU007/neunit_BASE_V7.3\n",
            "Done for SHENMU007/neunit_BASE_V7.4\n",
            "Done for SHENMU007/neunit_BASE_V7.5\n",
            "Done for espnet/fastspeech2_conformer\n",
            "Done for SHENMU007/neunit_BASE_V7.5.1\n",
            "Done for wuula/speecht5_tts_common_voice_zh\n",
            "Done for Avitas8485/speecht5_tts_commonvoice_en_02\n",
            "Done for SHENMU007/neunit_BASE_V7.6\n",
            "Done for SHENMU007/neunit_BASE_V7.7\n",
            "Done for SHENMU007/neunit_BASE_V7.8\n",
            "Done for GitMylo/riffusion-model-v1-small\n",
            "Done for SHENMU007/neunit_BASE_V8\n",
            "Done for lipo8081/speecht5_tts_voxpopuli_nl\n",
            "Done for mahendranitttrc/speecht5_tts_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_BASE_V8.2\n",
            "Done for SHENMU007/neunit_BASE_V9.1\n",
            "Done for SHENMU007/neunit_BASE_V9.2\n",
            "Done for SHENMU007/neunit_BASE_V9.3\n",
            "Done for SHENMU007/neunit_BASE_V9.4\n",
            "Done for SHENMU007/neunit_BASE_V9.5\n",
            "Done for ylacombe/bark-large\n",
            "Done for SHENMU007/neunit_BASE_V10.1\n",
            "Done for torphix/speecht5_tts_voxpopuli_nl\n",
            "Done for ManuD/speecht5_finetuned_voxpopuli_de\n",
            "Done for ManuD/speecht5_finetuned_voxpopuli_de_Merkel\n",
            "Done for SHENMU007/neunit_BASE_V10.2\n",
            "Done for SHENMU007/neunit_BASE_V10.3\n",
            "Done for SHENMU007/neunit_BASE_V10.4\n",
            "Done for RamWithAPlan/speecht5_tts_voxpopuli_nl\n",
            "Done for Matthijs/mms-tts-eng\n",
            "Done for Matthijs/mms-tts-nld\n",
            "Done for sanchit-gandhi/musicgen-small\n",
            "Done for AlexK-PL/speecht5_tts_fine-tuned_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_BASE_V10.5\n",
            "Done for SHENMU007/neunit_BASE_V10.6\n",
            "Done for josh13/speecht5_finetuned_voxpopuli_nl\n",
            "Done for Ocelotr/speecht5_tts-sil\n",
            "Done for SHENMU007/neunit_BASE_V10.7\n",
            "Done for SHENMU007/neunit_BASE_V10.8\n",
            "Done for Matthijs/vits-vctk\n",
            "Done for Matthijs/mms-tts-deu\n",
            "Done for Matthijs/vits-ljs\n",
            "Done for Matthijs/mms-tts-fra\n",
            "Done for Matthijs/mms-tts-ara\n",
            "Done for SHENMU007/neunit_BASE_V10.9\n",
            "Done for SHENMU007/neunit_BASE_V10.10\n",
            "Done for SHENMU007/neunit_BASE_V10.11\n",
            "Done for devslashrichie/speecht5_tts_voxpopuli_nl\n",
            "Done for romankovsv/speecht5_tts_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_BASE_V10.12\n",
            "Done for SHENMU007/neunit_BASE_V10.13\n",
            "Done for SHENMU007/neunit_BASE_V10.14\n",
            "Done for SHENMU007/neunit_BASE_V10.15\n",
            "Done for SHENMU007/neunit_BASE_V10.16\n",
            "Done for SHENMU007/neunit_BASE_V10.17\n",
            "Done for banlmonitor/speecht5_tts_voxpopuli_nl\n",
            "Done for tenebrisu/speecht5_tts_common_voice_uk\n",
            "Done for nillconill/speecht5_finetuned_voxpopuli_nl\n",
            "Done for newconew/speecht5_finetuned_voxpopuli_nl\n",
            "Done for Sourabh2/speecht5_finetuned_model\n",
            "Done for vineetsharma/speecht5_finetuned_voxpopuli_nl\n",
            "Done for SHENMU007/neunit_BASE_V10.18\n",
            "Done for SHENMU007/neunit_BASE_V10.19\n",
            "Done for magnustragardh/speecht5_finetuned_voxpopuli_nl\n",
            "Done for openai/whisper-large-v3\n",
            "Done for openai/whisper-large-v2\n",
            "Done for distil-whisper/distil-large-v3\n",
            "Done for jonatasgrosman/wav2vec2-large-xlsr-53-english\n",
            "Done for openai/whisper-tiny\n",
            "Done for BELLE-2/Belle-whisper-large-v3-zh\n",
            "Done for Systran/faster-whisper-large-v3\n",
            "Done for facebook/seamless-m4t-v2-large\n",
            "Done for distil-whisper/distil-small.en\n",
            "Done for openai/whisper-small\n",
            "Done for openai/whisper-large\n",
            "Done for nguyenvulebinh/wav2vec2-bartpho\n",
            "Done for distil-whisper/distil-medium.en\n",
            "Done for primeline/whisper-large-v3-german\n",
            "Done for primeline/distil-whisper-large-v3-german\n",
            "Done for Crystalcareai/Whisper-Medicalv1\n",
            "Done for kotoba-tech/kotoba-whisper-v1.1\n",
            "Done for nvidia/parakeet-tdt_ctc-1.1b\n",
            "Done for nvidia/parakeet-tdt_ctc-0.6b-ja\n",
            "Done for airesearch/wav2vec2-large-xlsr-53-th\n",
            "Done for facebook/wav2vec2-base-100h\n",
            "Done for facebook/wav2vec2-base-960h\n",
            "Done for facebook/wav2vec2-large-960h-lv60-self\n",
            "Done for facebook/wav2vec2-xls-r-2b-22-to-16\n",
            "Done for gchhablani/wav2vec2-large-xlsr-or\n",
            "Done for kresnik/wav2vec2-large-xlsr-korean\n",
            "Done for m3hrdadfi/wav2vec2-large-xlsr-persian-v3\n",
            "Done for jaeyeon/wav2vec2-child-en-tokenizer-4\n",
            "Done for aioxlabs/dvoice-darija\n",
            "Done for openai/whisper-small.en\n",
            "Done for ksoky/whisper-large-khmer-asr\n",
            "Done for gigant/whisper-medium-romanian\n",
            "Done for thennal/whisper-medium-ml\n",
            "Done for Jingmiao/whisper-small-zh_tw\n",
            "Done for jstoone/whisper-medium-da\n",
            "Done for xmzhu/whisper-tiny-zh\n",
            "Done for jwkritchie/whisper-small-defined-dot-ai-qc-fr-combined-dataset\n",
            "Done for vasista22/whisper-telugu-base\n",
            "Done for vasista22/whisper-telugu-large-v2\n",
            "Done for vasista22/whisper-tamil-large-v2\n",
            "Done for taesiri/whisper-small-fa-7\n",
            "Done for microsoft/speecht5_asr\n",
            "Done for alvanlii/whisper-largev2-cantonese-peft-lora\n",
            "Done for neongeckocom/stt_en_citrinet_512_gamma_0_25\n",
            "Done for AIFahim/whisper-medium-bn_our_dataset_positional_phoneme\n",
            "Done for lorenzoncina/whisper-medium-zh\n",
            "Done for Xenova/whisper-small.en\n",
            "Done for Xenova/whisper-tiny\n",
            "Done for dg96/whisper-finetuning-phoneme-transcription-g2p-large-dataset-space-seperated-phonemes\n",
            "Done for smcproject/vegam-whisper-medium-ml\n",
            "Done for facebook/mms-1b-all\n",
            "Done for alphacep/vosk-model-ru\n",
            "Done for facebook/seamless-m4t-medium\n",
            "Done for facebook/seamless-m4t-large\n",
            "Done for ai4bharat/indicwav2vec-odia\n",
            "Done for 64FC/whisper-small-dv\n",
            "Done for jbtruong/whisper-small-phonemes-test\n",
            "Done for jbtruong/whisper-small-phonemes-test-1e-4\n",
            "Done for zongxiao/whisper-small-zh-CN\n",
            "Done for hishab/hishab_bn_fastconformer\n",
            "Done for Minu1234/whisper-small-phonemes\n",
            "Done for Baghdad99/saad-speech-recognition-hausa-audio-to-text\n",
            "Done for bofenghuang/whisper-large-v3-french\n",
            "Done for espnet/owsm_v3.1_ebf\n",
            "Done for nvidia/parakeet-ctc-0.6b\n",
            "Done for BELLE-2/Belle-distilwhisper-large-v2-zh\n",
            "Done for Systran/faster-distil-whisper-large-v2\n",
            "Done for abdouaziiz/whisper_bambara\n",
            "Done for nvidia/canary-1b\n",
            "Done for NbAiLab/nb-whisper-large\n",
            "Done for UlutSoftLLC/whisper-small-kyrgyz\n",
            "Done for pyf98/owsm_ctc_v3.1_1B\n",
            "Done for HiTZ/stt_eu_conformer_transducer_large\n",
            "Done for ivrit-ai/whisper-large-v2-tuned\n",
            "Done for IbrahimSalah/Wav2vecXXl_quran_syllables\n",
            "Done for Systran/faster-distil-whisper-large-v3\n",
            "Done for AssistantApp/assistantapp-whisper-quran\n",
            "Done for kotoba-tech/kotoba-whisper-v1.0\n",
            "Done for primeline/whisper-tiny-german\n",
            "Done for Bluecast/wav2vec2-Malayalam\n",
            "Done for oza75/whisper-bambara-asr-001\n",
            "Done for RaivisDejus/whisper-tiny-lv\n",
            "Done for clinical-assistance/whisper_medium_clinical_assistance_10k\n",
            "Done for oza75/whisper-bambara-asr-002\n",
            "Done for RaivisDejus/whisper-small-lv\n",
            "Done for vonjack/whisper-large-v3-gguf\n",
            "Done for raghadOmar/whisper-quran\n",
            "Done for sujithvemi/whisper-medium-physician-dictation-gpt-4-turbo\n",
            "Done for antony66/whisper-large-v3-russian\n",
            "Done for mike249/whisper-small-he-v4\n",
            "Done for 13048909972/wav2vec2-common_voice-tr-demo\n",
            "Done for 13048909972/wav2vec2-large-xls-r-300m-tr-colab\n",
            "Done for 13048909972/wav2vec2-large-xlsr-53_common_voice_20211211085606\n",
            "Done for 202015004/wav2vec2-base-timit-demo-colab\n",
            "Done for 275Gameplay/test\n",
            "Done for AKulk/wav2vec2-base-timit-epochs10\n",
            "Done for AKulk/wav2vec2-base-timit-epochs15\n",
            "Done for AKulk/wav2vec2-base-timit-epochs5\n",
            "Done for Pinwheel/wav2vec2-base-timit-demo-colab\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-1b-hi-v2\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-1b-hi\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-1b-hindi\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-300m-50-hi\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-300m-hi-v2\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-300m-hi\n",
            "Done for Pinwheel/wav2vec2-large-xls-r-300m-tr-colab\n",
            "Done for Pinwheel/wav2vec2-large-xlsr-53-hi\n",
            "Done for Adil617/wav2vec2-base-timit-demo-colab\n",
            "Done for AigizK/wav2vec2-large-xls-r-300m-bashkir-cv7_opt\n",
            "Done for Akashpb13/Central_kurdish_xlsr\n",
            "Done for Akashpb13/Galician_xlsr\n",
            "Done for Akashpb13/Hausa_xlsr\n",
            "Done for Akashpb13/Kabyle_xlsr\n",
            "Done for Akashpb13/Swahili_xlsr\n",
            "Done for Akashpb13/xlsr_hungarian_new\n",
            "Done for Akashpb13/xlsr_kurmanji_kurdish\n",
            "Done for Akashpb13/xlsr_maltese_wav2vec2\n",
            "Done for AlexN/xls-r-300m-fr-0\n",
            "Done for AlexN/xls-r-300m-fr\n",
            "Done for AlexN/xls-r-300m-pt\n",
            "Done for Amrrs/wav2vec2-large-xlsr-53-tamil\n",
            "Done for AndrewMcDowell/wav2vec2-xls-r-1B-german\n",
            "Done for AndrewMcDowell/wav2vec2-xls-r-1b-arabic\n",
            "Done for AndrewMcDowell/wav2vec2-xls-r-1b-japanese-hiragana-katakana\n",
            "Done for AndrewMcDowell/wav2vec2-xls-r-300m-arabic\n",
            "Done for AndrewMcDowell/wav2vec2-xls-r-300m-german-de\n",
            "Done for AndrewMcDowell/wav2vec2-xls-r-300m-japanese\n",
            "Done for Arnold/wav2vec2-hausa2-demo-colab\n",
            "Done for Arnold/wav2vec2-large-xlsr-hausa2-demo-colab\n",
            "Done for Ayoola/cdial-yoruba-test\n",
            "Done for BSen/wav2vec2-base-timit-demo-colab\n",
            "Done for BSen/wav2vec2-large-xls-r-300m-turkish-colab\n",
            "Done for Bagus/wav2vec2-large-xlsr-bahasa-indonesia\n",
            "Done for Baybars/wav2vec2-xls-r-1b-turkish\n",
            "Done for Baybars/wav2vec2-xls-r-300m-cv8-turkish\n",
            "Done for Bharathdamu/wav2vec2-large-xls-r-300m-hindi-colab\n",
            "Done for Bharathdamu/wav2vec2-large-xls-r-300m-hindi\n",
            "Done for Brokette/projetCS\n",
            "Done for Cdial/hausa-asr\n",
            "Done for CuongLD/wav2vec2-large-xlsr-vietnamese\n",
            "Done for DeividasM/wav2vec2-large-xlsr-53-lithuanian\n",
            "Done for DewiBrynJones/wav2vec2-large-xlsr-welsh\n",
            "Done for Waynehillsdev/Waynehills-STT-doogie-server\n",
            "Done for Waynehillsdev/wav2vec2-base-timit-demo-colab\n",
            "Done for DrishtiSharma/wav2vec2-large-xls-r-300m-ab-CV7\n",
            "Done for DrishtiSharma/wav2vec2-large-xls-r-300m-ab-v4\n",
            "Done for blaise-tk/TITAN\n",
            "Done for ArkanDash/rvc-genshin-impact\n",
            "Done for qualcomm/Facebook-Denoiser\n",
            "Done for speechbrain/sepformer-wham\n",
            "Done for Awais/Audio_Source_Separation\n",
            "Done for microsoft/speecht5_vc\n",
            "Done for krasserm/perceiver-ar-sam-giant-midi\n",
            "Done for mrmocciai/Models\n",
            "Done for IAHispano/Applio\n",
            "Done for ResembleAI/resemble-enhance\n",
            "Done for JorisCos/ConvTasNet_Libri1Mix_enhsingle_16k\n",
            "Done for JorisCos/ConvTasNet_Libri2Mix_sepclean_16k\n",
            "Done for JorisCos/ConvTasNet_Libri2Mix_sepclean_8k\n",
            "Done for JorisCos/ConvTasNet_Libri2Mix_sepnoisy_16k\n",
            "Done for JorisCos/ConvTasNet_Libri2Mix_sepnoisy_8k\n",
            "Done for JorisCos/ConvTasNet_Libri3Mix_sepclean_16k\n",
            "Done for JorisCos/ConvTasNet_Libri3Mix_sepclean_8k\n",
            "Done for JorisCos/ConvTasNet_Libri3Mix_sepnoisy_16k\n",
            "Done for JorisCos/ConvTasNet_Libri3Mix_sepnoisy_8k\n",
            "Done for JorisCos/DCCRNet_Libri1Mix_enhsingle_16k\n",
            "Done for JorisCos/DCUNet_Libri1Mix_enhsingle_16k\n",
            "Done for JorisCos/DPRNNTasNet-ks2_Libri1Mix_enhsingle_16k\n",
            "Done for JorisCos/DPTNet_Libri1Mix_enhsingle_16k\n",
            "Done for cankeles/ConvTasNet_WHAMR_enhsingle_16k\n",
            "Done for cankeles/DPTNet_WHAMR_enhsingle_16k\n",
            "Done for espnet/Chenda_Li_wsj0_2mix_enh_train_enh_conv_tasnet_raw_valid.si_snr.ave\n",
            "Done for espnet/Chenda_Li_wsj0_2mix_enh_train_enh_rnn_tf_raw_valid.si_snr.ave\n",
            "Done for espnet/Wangyou_Zhang_chime4_enh_train_enh_beamformer_mvdr_raw\n",
            "Done for espnet/anogkongda-librimix_enh_train_raw_valid.si_snr.ave\n",
            "Done for espnet/anogkongda_librimix_enh_train_raw_valid.si_snr.ave\n",
            "Done for espnet/chenda-li-wsj0_2mix_enh_train_enh_conv_tasnet_raw_valid.si_snr.ave\n",
            "Done for espnet/chenda-li-wsj0_2mix_enh_train_enh_rnn_tf_raw_valid.si_snr.ave\n",
            "Done for espnet/yen-ju-lu-dns_ins20_enh_train_enh_blstm_tf_raw_valid.loss.best\n",
            "Done for facebook/xm_transformer_600m-en_ar-multi_domain\n",
            "Done for facebook/xm_transformer_600m-en_es-multi_domain\n",
            "Done for facebook/xm_transformer_600m-en_fr-multi_domain\n",
            "Done for facebook/xm_transformer_600m-en_ru-multi_domain\n",
            "Done for facebook/xm_transformer_600m-en_tr-multi_domain\n",
            "Done for facebook/xm_transformer_600m-en_vi-multi_domain\n",
            "Done for facebook/xm_transformer_600m-en_zh-multi_domain\n",
            "Done for facebook/xm_transformer_600m-es_en-multi_domain\n",
            "Done for facebook/xm_transformer_600m-fr_en-multi_domain\n",
            "Done for facebook/xm_transformer_600m-ru_en-multi_domain\n",
            "Done for groadabike/ConvTasNet_DAMP-VSEP_enhboth\n",
            "Done for groadabike/ConvTasNet_DAMPVSEP_EnglishNonEnglish_baseline\n",
            "Done for julien-c/DPRNNTasNet-ks16_WHAM_sepclean\n",
            "Done for lichenda/wsj0_2mix_skim_noncausal\n",
            "Done for mhu-coder/ConvTasNet_Libri1Mix_enhsingle\n",
            "Done for mpariente/ConvTasNet_Libri3Mix_sepnoisy\n",
            "Done for mpariente/ConvTasNet_WHAM_sepclean\n",
            "Done for mpariente/DPRNNTasNet-ks2_WHAM_sepclean\n",
            "Done for nateraw/audio-test\n",
            "Done for nateraw/audio-to-audio-test2\n",
            "Done for osanseviero/ConvTasNet_Libri1Mix_enhsingle_16k\n",
            "Done for osanseviero/audio_test\n",
            "Done for popcornell/FasNetTAC-paper\n",
            "Done for speechbrain/metricgan-plus-voicebank\n",
            "Done for speechbrain/mtl-mimic-voicebank\n",
            "Done for speechbrain/sepformer-wham-enhancement\n",
            "Done for speechbrain/sepformer-whamr-enhancement\n",
            "Done for speechbrain/sepformer-whamr\n",
            "Done for speechbrain/sepformer-whamr16k\n",
            "Done for speechbrain/sepformer-wsj02mix\n",
            "Done for speechbrain/sepformer-wsj03mix\n",
            "Done for templates/audio-to-audio\n",
            "Done for Johnson-Lsx/Shaoxiong_Lin_dns_ins20_enh_enh_train_enh_dccrn_raw\n",
            "Done for Yulinfeng/wsj0_2mix_enh_train_enh_dpcl_raw_valid.si_snr.ave\n",
            "Done for Yulinfeng/wsj0_2mix_enh_train_enh_dan_tf_raw_valid.si_snr.ave\n",
            "Done for Yulinfeng/wsj0_2mix_enh_train_enh_mdc_raw_valid.si_snr.ave\n",
            "Done for lichenda/chime4_fasnet_dprnn_tac\n",
            "Done for espnet/Wangyou_Zhang_chime4_enh_train_enh_dc_crn_mapping_snr_raw\n",
            "Done for lichenda/Chenda_Li_wsj0_2mix_enh_dprnn_tasnet\n",
            "Done for espnet/Wangyou_Zhang_chime4_enh_train_enh_conv_tasnet_raw\n",
            "Done for espnet/Wangyou_Zhang_wsj0_2mix_enh_dc_crn_mapping_snr_raw\n",
            "Done for popcornell/clarity21_train_enh_beamformer_mvdr\n",
            "Done for Zhaoheng/svoice_wsj0_2mix\n",
            "Done for espnet/dns_icassp21_enh_train_enh_tcn_tf_raw\n",
            "Done for nateraw/nu-wave-x2\n",
            "Done for espnet/Yen-Ju_Lu_l3das22_enh_train_dprnntac_fasnet_valid.loss.ave\n",
            "Done for speechbrain/resepformer-wsj02mix\n",
            "Done for espnet/Wangyou_Zhang_wsj0_2mix_enh_train_enh_dptnet_raw\n",
            "Done for speechbrain/sepformer-wham16k-enhancement\n",
            "Done for facebook/xm_transformer_s2ut_800m-es-en-st-asr-bt_h1_2022\n",
            "Done for espnet/Yen-Ju_Lu_l3das22_enh_train_enh_ineube_valid.loss.ave\n",
            "Done for speechbrain/sepformer-libri2mix\n",
            "Done for speechbrain/sepformer-libri3mix\n",
            "Done for facebook/xm_transformer_s2ut_en-hk\n",
            "Done for facebook/xm_transformer_s2ut_hk-en\n",
            "Done for facebook/xm_transformer_unity_hk-en\n",
            "Done for facebook/xm_transformer_unity_en-hk\n",
            "Done for facebook/xm_transformer_sm_all-en\n",
            "Done for facebook/textless_sm_cs_en\n",
            "Done for facebook/textless_sm_cs_fr\n",
            "Done for facebook/textless_sm_cs_es\n",
            "Done for facebook/textless_sm_pl_en\n",
            "Done for facebook/textless_sm_pl_es\n",
            "Done for facebook/textless_sm_pl_fr\n",
            "Done for facebook/textless_sm_de_en\n",
            "Done for facebook/textless_sm_es_en\n",
            "Done for facebook/textless_sm_et_en\n",
            "Done for facebook/textless_sm_fi_en\n",
            "Done for facebook/textless_sm_fr_en\n",
            "Done for facebook/textless_sm_hr_en\n",
            "Done for facebook/textless_sm_hu_en\n",
            "Done for facebook/textless_sm_it_en\n",
            "Done for facebook/textless_sm_nl_en\n",
            "Done for facebook/textless_sm_pt_en\n",
            "Done for facebook/textless_sm_ro_en\n",
            "Done for facebook/textless_sm_sk_en\n",
            "Done for facebook/textless_sm_sl_en\n",
            "Done for facebook/textless_sm_de_fr\n",
            "Done for facebook/textless_sm_en_fr\n",
            "Done for facebook/textless_sm_es_fr\n",
            "Done for facebook/textless_sm_et_fr\n",
            "Done for facebook/textless_sm_fi_fr\n",
            "Done for facebook/textless_sm_hr_fr\n",
            "Done for facebook/textless_sm_hu_fr\n",
            "Done for facebook/textless_sm_it_fr\n",
            "Done for facebook/textless_sm_nl_fr\n",
            "Done for facebook/textless_sm_pt_fr\n",
            "Done for facebook/textless_sm_ro_fr\n",
            "Done for facebook/textless_sm_sk_fr\n",
            "Done for facebook/textless_sm_sl_fr\n",
            "Done for facebook/textless_sm_de_es\n",
            "Done for facebook/textless_sm_en_es\n",
            "Done for facebook/textless_sm_et_es\n",
            "Done for facebook/textless_sm_fi_es\n",
            "Done for facebook/textless_sm_fr_es\n",
            "Done for facebook/textless_sm_hr_es\n",
            "Done for facebook/textless_sm_hu_es\n",
            "Done for facebook/textless_sm_it_es\n",
            "Done for facebook/textless_sm_nl_es\n",
            "Done for facebook/textless_sm_pt_es\n",
            "Done for facebook/textless_sm_ro_es\n",
            "Done for facebook/textless_sm_sk_es\n",
            "Done for facebook/textless_sm_sl_es\n",
            "Done for sparanoid/milky-green-diff-svc\n",
            "Done for sparanoid/milky-green-sovits\n",
            "Done for Fhrozen/voc_hifigan_multilingual\n",
            "Done for Fhrozen/voc_fastdiff_multilingual\n",
            "Done for Nekochu/Sci-FiSoundSFX\n",
            "Done for jaCappella/MRDLA_jaCappella_VES_48k\n",
            "Done for jaCappella/XUMX_jaCappella_VES_48k\n",
            "Done for jaCappella/DPTNet_jaCappella_VES_48k\n",
            "Done for tnkmr/sfi_convtasnet_fd_mgf_musdb18hq\n",
            "Done for tnkmr/sfi_convtasnet_td_mgf_musdb18hq\n",
            "Done for tnkmr/sfi_convtasnet_td_mpgtf_musdb18hq\n",
            "Done for ciferecavivon/so-vits-svc3.0_big\n",
            "Done for Amo/so-vits-svc-4.0_GA\n",
            "Done for MIT/ast-finetuned-audioset-10-10-0.4593\n",
            "Done for audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim\n",
            "Done for speechbrain/lang-id-voxlingua107-ecapa\n",
            "Done for dima806/musical_instrument_detection\n",
            "Done for Wiam/wav2vec2-lg-xlsr-en-speech-emotion-recognition-finetuned-ravdess-v8\n",
            "Done for Bagus/wav2vec2-xlsr-japanese-speech-emotion-recognition\n",
            "Done for superb/wav2vec2-base-superb-sid\n",
            "Done for MIT/ast-finetuned-speech-commands-v2\n",
            "Done for facebook/mms-lid-4017\n",
            "Done for speechbrain/emotion-diarization-wavlm-large\n",
            "Done for dima806/multiple_accent_classification\n",
            "Done for dima806/classical_composer_classification-new\n",
            "Done for lijialudew/wav2vec_children_ASR\n",
            "Done for magnjorg/ast-finetuned-guitar\n",
            "Done for magnjorg/wav2vec-finetuned-guitar\n",
            "Done for AkshaySg/langid\n",
            "Done for Bagus/wav2vec2-xlsr-greek-speech-emotion-recognition\n",
            "Done for NhatPham/wav2vec2-base-finetuned-ks\n",
            "Done for Rajaram1996/Hubert_emotion\n",
            "Done for TalTechNLP/voxlingua107-epaca-tdnn-ce\n",
            "Done for TalTechNLP/voxlingua107-epaca-tdnn\n",
            "Done for abdelhalim/Shower_Sound_Recognition\n",
            "Done for addy88/wav2vec2-base-finetuned-ks\n",
            "Done for anantoj/wav2vec2-adult-child-cls\n",
            "Done for anantoj/wav2vec2-large-xlsr-53-adult-child-cls\n",
            "Done for anantoj/wav2vec2-xls-r-300m-adult-child-cls\n",
            "Done for anton-l/distilhubert-ft-common-language\n",
            "Done for anton-l/distilhubert-ft-keyword-spotting\n",
            "Done for anton-l/hubert-base-ft-keyword-spotting\n",
            "Done for anton-l/sew-d-mid-400k-ft-keyword-spotting\n",
            "Done for anton-l/sew-mid-100k-ft-common-language\n",
            "Done for anton-l/sew-mid-100k-ft-keyword-spotting\n",
            "Done for anton-l/wav2vec2-base-finetuned-ks\n",
            "Done for anton-l/wav2vec2-base-ft-common-language\n",
            "Done for anton-l/wav2vec2-base-ft-keyword-spotting\n",
            "Done for anton-l/wav2vec2-base-keyword-spotting\n",
            "Done for anton-l/wav2vec2-base-lang-id\n",
            "Done for anton-l/wav2vec2-base-superb-sv\n",
            "Done for anton-l/wav2vec2-random-tiny-classifier\n",
            "Done for bookbot/distil-wav2vec2-adult-child-cls-37m\n",
            "Done for bookbot/distil-wav2vec2-adult-child-cls-52m\n",
            "Done for bookbot/distil-wav2vec2-xls-r-adult-child-cls-64m\n",
            "Done for bookbot/distil-wav2vec2-xls-r-adult-child-cls-89m\n",
            "Done for bookbot/wav2vec2-adult-child-cls\n",
            "Done for bookbot/wav2vec2-xls-r-adult-child-cls\n",
            "Done for dkurt/wav2vec2-base-ft-keyword-spotting-int8\n",
            "Done for ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\n",
            "Done for harshit345/xlsr-wav2vec-speech-emotion-recognition\n",
            "Done for mishig/test_regex_searchreplace\n",
            "Done for osanseviero/example_audio\n",
            "Done for speechbrain/emotion-recognition-wav2vec2-IEMOCAP\n",
            "Done for speechbrain/google_speech_command_xvector\n",
            "Done for speechbrain/lang-id-commonlanguage_ecapa\n",
            "Done for speechbrain/spkrec-xvect-voxceleb\n",
            "Done for speechbrain/urbansound8k_ecapa\n",
            "Done for superb/hubert-base-superb-er\n",
            "Done for superb/hubert-base-superb-ic\n",
            "Done for superb/hubert-base-superb-ks\n",
            "Done for superb/hubert-base-superb-sid\n",
            "Done for superb/hubert-large-superb-er\n",
            "Done for superb/hubert-large-superb-ic\n",
            "Done for superb/hubert-large-superb-ks\n",
            "Done for superb/hubert-large-superb-sid\n",
            "Done for superb/wav2vec2-base-superb-er\n",
            "Done for superb/wav2vec2-base-superb-ic\n",
            "Done for superb/wav2vec2-base-superb-ks\n",
            "Done for superb/wav2vec2-large-superb-er\n",
            "Done for superb/wav2vec2-large-superb-ic\n",
            "Done for superb/wav2vec2-large-superb-ks\n",
            "Done for superb/wav2vec2-large-superb-sid\n",
            "Done for sudoparsa/wav2vec2-base-finetuned-ks\n",
            "Done for lewtun/wav2vec2-base-100k-voxpopuli-finetuned-gtzan\n",
            "Done for alirezafarashah/wav2vec2-base-ks\n",
            "Done for alirezafarashah/wav2vec2-base-ks-2sec\n",
            "Done for pratt3000/wav2vec2-base-finetuned-ks\n",
            "Done for Mnauel/wav2vec2-base-finetuned-ks\n",
            "Done for anton-l/xtreme_s_xlsr_minds14_group_length\n",
            "Done for anton-l/xtreme_s_xlsr_minds14\n",
            "Done for anton-l/xtreme_s_xlsr_minds14_longer\n",
            "Done for lewtun/distilhubert-finetuned-gtzan\n",
            "Done for DrishtiSharma/wav2vec2-base-finetuned-ks\n",
            "Done for anton-l/xtreme_s_xlsr_minds14_upd\n",
            "Done for anton-l/xtreme_s_xlsr_300m_minds14\n",
            "Done for aaraki/wav2vec2-base-finetuned-ks\n",
            "Done for alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition\n",
            "Done for somosnlp-hackathon-2022/wav2vec2-base-finetuned-sentiment-mesd\n",
            "Done for DrishtiSharma/xls-r-es-test-lm-finetuned-sentiment-mesd\n",
            "Done for DrishtiSharma/wav2vec2-base-finetuned-sentiment-mesd-v2\n",
            "Done for DrishtiSharma/wav2vec2-base-finetuned-sentiment-mesd-v9\n",
            "Done for somosnlp-hackathon-2022/wav2vec2-base-finetuned-sentiment-classification-MESD\n",
            "Done for abdusah/aradia-class-v1\n",
            "Done for anton-l/xtreme_s_xlsr_300m_fleurs_langid_test\n",
            "Done for anton-l/xtreme_s_xlsr_300m_fleurs_langid_quicker_warmup\n",
            "Done for Graphcore/hubert-base-superb-ks\n",
            "Done for Graphcore/hubert-base-common-language\n",
            "Done for anton-l/xtreme_s_xlsr_300m_fleurs_langid\n",
            "Done for gary109/wav2vec2-base-finetuned-ks\n",
            "Done for gary109/wav2vec2-base-mirst500\n",
            "Done for gary109/wav2vec2-base-mirst500-ac\n",
            "Done for TalTechNLP/voxlingua107-xls-r-300m-wav2vec\n",
            "Done for ngwlh/wav2vec2-base-ft-keyword-spotting\n",
            "Done for learningdude/wav2vec2-base-finetuned-ks\n",
            "Done for learningdude/wav2vec2-base-sound2\n",
            "Done for bookbot/wav2vec2-xls-r-adult-child-id-cls\n",
            "Done for bookbot/wav2vec2-adult-child-id-cls\n",
            "Done for bookbot/distil-wav2vec2-adult-child-id-cls-52m\n",
            "Done for manthan40/wav2vec2-base-finetuned-manthan_base\n",
            "Done for manthan40/wav2vec2-base-finetuned-manthan-gujarati-digits\n",
            "Done for Nurr/wav2vec2-base-finetuned-ks\n",
            "Done for Aniemore/wav2vec2-xlsr-53-russian-emotion-recognition\n",
            "Done for nataliebhuerta/wav2vec2-base-finetuned-ks\n",
            "Done for lopushanskyy/music-generation\n",
            "Done for Splend1dchan/xtreme_s_xlsr_300m_minds14.en-US\n",
            "Done for Splend1dchan/xtreme_s_xlsr_300m_t5lephone_minds14.en-US_2\n",
            "Done for Splend1dchan/xtreme_s_xlsr_300m_minds14.en-US_2\n",
            "Done for Splend1dchan/xtreme_s_xlsr_minds14.en-all\n",
            "Done for Splend1dchan/xtreme_s_xlsr_300m_minds14\n",
            "Done for keras-io/english-speaker-accent-recognition-using-transfer-learning\n",
            "Done for sampras343/wav2vec2-keyword-spotting-int8\n",
            "Done for sampras343/wav2vec2-base-ft-keyword-spotting\n",
            "Done for soyul/wav2vec2-base-finetuned-ks\n",
            "Done for cotcode/wav2vec2-finetuned-ch-emotion-edu\n",
            "Done for Mahmoud1816Yasser/tmp_trainer\n",
            "Done for skpawar1305/wav2vec2-base-finetuned-ks\n",
            "Done for skpawar1305/wav2vec2-base-finetuned-digits\n",
            "Done for juliensimon/wav2vec2-conformer-rel-pos-large-finetuned-speech-commands\n",
            "Done for thelou1s/yamnet\n",
            "Done for skpawar1305/wav2vec2-base-finetuned-ks-de\n",
            "Done for skpawar1305/wav2vec2-large-xlsr-53-german-finetuned-ks-de\n",
            "Done for thelou1s/viggish\n",
            "Done for thelou1s/panns-inference\n",
            "Done for Talha/urdu-audio-emotions\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-Tess\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-Tess-finetuned-Tess\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-test-words\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-trained-3-languages\n",
            "Done for Hamzaaa/wav2vec2-base-960h-finetuned-trained-Crema_only\n",
            "Done for Hamzaaa/wav2vec2-base-960h-finetuned-trained-greek\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-emodb\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-savee\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-crema\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-greek\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-Tess-excluded\n",
            "Done for Hamzaaa/xlsr-wav2vec-speech-emotion-recognition-finetuned-Savee\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-Saveee\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-3-eng-greek\n",
            "Done for Professor/wav2vec2-base-960h-finetuned\n",
            "Done for Hamzaaa/wav2vec2-base-finetuned-trained-3-languages-finetuned-CremaD\n",
            "Done for AdamAbate1/wav2vec2-base-finetuned-ks\n",
            "Done for Jungwoo4021/wav2vec2-base-ks-finetuning\n",
            "Done for julien-c/voice-activity-detection\n",
            "Done for philschmid/pyannote-speaker-diarization-endpoint\n",
            "Done for anilbs/segmentation\n",
            "Done for philschmid/pyannote-segmentation\n",
            "Done for d4data/Indian-voice-cloning\n",
            "Done for popcornell/pyannote-segmentation-chime6-mixer6\n",
            "Done for johnislarry/cloned-pyannote-speaker-diarization-endpoint\n",
            "Done for funasr/fsmn-vad-onnx\n",
            "Done for Fuhuaujduu/Fu_hua-Honkai_impact3d\n",
            "Done for KIFF/pyannote-speaker-diarization-endpoint\n",
            "Done for Berndk/Anilerdemcevizci\n",
            "Done for sheLpersss7/Asahina-Mafuyu1014\n",
            "Done for Baratova/Eunil\n",
            "Done for thinkerrmode/voice_test\n",
            "Done for Polkijann/jann1\n",
            "Done for yutawatanabe/customhdlr\n",
            "Done for kyriacou2009/TVR-1\n",
            "Done for aavvmm/pru1\n",
            "Done for funasr/fsmn-vad\n",
            "Done for collinbarnwell/pyannote-segmentation-30\n",
            "Done for BoKnows/vad-endpoint\n",
            "Done for sanaweb/speech-to-text-fa\n",
            "Done for kamilakesbi/speaker-segmentation-fine-tuned-callhome-jpn\n",
            "Done for kamilakesbi/segmentation_model_pyannote\n",
            "Done for kamilakesbi/speaker-segmentation-test\n",
            "Done for yzhuang/MetaTree\n",
            "Done for julien-c/wine-quality\n",
            "Done for keras-io/TF_Decision_Trees\n",
            "Done for osanseviero/wine-quality\n",
            "Done for templates/tabular-classification\n",
            "Done for rajistics/autotrain-Adult-934630783\n",
            "Done for keras-io/collaborative-filtering-movielens\n",
            "Done for mindwrapped/collaborative-filtering-movielens-copy\n",
            "Done for keras-io/tab_transformer\n",
            "Done for keras-io/imbalanced_classification\n",
            "Done for keras-io/structured-data-classification-grn-vsn\n",
            "Done for abhishek/autotrain-iris-logistic-regression\n",
            "Done for abhishek/autotrain-iris-knn\n",
            "Done for abhishek/autotrain-iris-xgboost\n",
            "Done for abhishek/autotrain-adult-census-xgboost\n",
            "Done for osanseviero/tipsuhtxfu-sex-classification\n",
            "Done for maderix/titanic_traink4m62li8-survived-classification\n",
            "Done for merve/breast_cancernb8gjv4n-diagnosis-classification\n",
            "Done for luizapzbn/titanicht_mp88q-Survived-classification\n",
            "Done for cacauvicosa/heart1ohr2x9e-target-classification\n",
            "Done for Fulccrum/trainii_ac94u-label-classification\n",
            "Done for sahilrajpal121/train5a1e8w7-label-classification\n",
            "Done for ieborhan/irisg444_4c0-Species-classification\n",
            "Done for bhavesh/arinfo_sample_dataset_finaltffwjv58-model-classification\n",
            "Done for julien-c/skops-digits\n",
            "Done for scikit-learn/skops-blog-example\n",
            "Done for scikit-learn/tabular-playground\n",
            "Done for demo-org/tabular-playground\n",
            "Done for imodels/figs-compas-recidivism\n",
            "Done for vendorabc/modelhubexample\n",
            "Done for vendorabc/modeltest\n",
            "Done for vendorabc/tabular-playground\n",
            "Done for freddyaboulton/tabular-playground\n",
            "Done for merve/test-code-generation\n",
            "Done for Alexei1/imdb\n",
            "Done for kushkul/rf_model_skops\n",
            "Done for omarques/autotrain-in-class-test-demo-1659958764\n",
            "Done for omarques/autotrain-in-class-test-demo-1659958767\n",
            "Done for tejas23/autotrain-amx2-1702259725\n",
            "Done for tejas23/autotrain-amx2-1702259728\n",
            "Done for tejas23/autotrain-amx2-1702259729\n",
            "Done for halflings/pokemon_is_legendary\n",
            "Done for victor/titanic-survival-with-ml-console\n",
            "Done for osanseviero/titanic_mlconsole\n",
            "Done for rajistics/my-awesome-churn-model\n",
            "Done for rajistics/churn-model\n",
            "Done for jwan2021/autotrain-jwan-autotrain1-1768961489\n",
            "Done for pachi107/autotrain-in-class-test-1780161764\n",
            "Done for tehnlulz/pruned_datavq__ydnj-is_phishing-classification\n",
            "Done for kem000123/autotrain-model1-binary-class-1843363194\n",
            "Done for kyle-lucke/autotrain-planes-1918465011\n",
            "Done for Ramos-Ramos/emb-gam-dino\n",
            "Done for FaroukFaiz/nateraw_world-happiness_2018.csv\n",
            "Done for FaroukFaiz/nateraw_world-happiness_2018_2.csv\n",
            "Done for navidfk/autotrain-wine-1986366196\n",
            "Done for halflings/diabetes_detection_fixed2\n",
            "Done for halflings/diabetes_detection_fixed3\n",
            "Done for halflings/diabetes_detection_scaler\n",
            "Done for halflings/iris_classification\n",
            "Done for halflings/diabetes_detection_v2\n",
            "Done for robertbogdon/model_tuning_mindallee8kmcfjz-labels-classification\n",
            "Done for robertbogdon/model_tuning_mindalleeu83oz7r-labels-classification\n",
            "Done for robertbogdon/model_tuning_mindalle9_jsy6zj-labels-classification\n",
            "Done for Ramos-Ramos/emb-gam-resnet\n",
            "Done for Ramos-Ramos/emb-gam-vit\n",
            "Done for svnfs/rfc\n",
            "Done for Testys/diabetespmxrsn1x-diabetes-classification\n",
            "Done for svnfs/rfc-alias\n",
            "Done for rajistics/churn-model1\n",
            "Done for danupurnomo/dummy-titanic\n",
            "Done for merve/model-broken-config\n",
            "Done for Ramos-Ramos/emb-gam-dino-resnet\n",
            "Done for aliosmankaya/structured_arr_model_1_dim\n",
            "Done for aliosmankaya/reg_arr_model_2_dim\n",
            "Done for aliosmankaya/reg_arr_model_1_dim\n",
            "Done for scikit-learn/cancer-prediction-trees\n",
            "Done for Annabel/my-awesome-model\n",
            "Done for zakariaelaouene/predict-intrusion2\n",
            "Done for fyhao/autotrain-sentiment-analysis-2435575634\n",
            "Done for scikit-learn/blog-example\n",
            "Done for Ramos-Ramos/emb-gam-vicreg-resnet\n",
            "Done for moro23/ml-generation-failure-prediction\n",
            "Done for Alassea/middle-dutch-NER_passAgg\n",
            "Done for jirkoru/TemporalRegression\n",
            "Done for y1450/hf_hub_example-ff7aeda4-022b-47d2-bf00-0c241bc195f7\n",
            "Done for merve/my-awesome-model-blog\n",
            "Done for Ozziey/test-model\n",
            "Done for Ozziey/poet-type-model\n",
            "Done for Ozziey/poet-age-model\n",
            "Done for mahrukhw/DecisissionTreeClassifier\n",
            "Done for Alassea/middle-dutch-NER_passAgg_2\n",
            "Done for matheuscvp/predict_weather\n",
            "Done for uisikdag/soil_tabular_classification_yaren\n",
            "Done for uisikdag/school_indoor_tabular_classification\n",
            "Done for mklomo/rf-churn-model\n",
            "Done for tarakere/some_safetensors\n",
            "Done for jirkoru/TemporalRegressionV2\n",
            "Done for reesu/wine_quality\n",
            "Done for reesu/autotrain-wine_quality-3195889865\n",
            "Done for BenjaminB/test-skops-card-creator-02\n",
            "Done for marac5/autotrain-builty-2-table-searcher-3373492718\n",
            "Done for achiachi/accentcombinedlenous8ktq9-accent-classification\n",
            "Done for ahuber/knn-example-stock-067ecda5-11f2-4788-818f-707c3dd673e7\n",
            "Done for ahuber/knn-example-intelex-067ecda5-11f2-4788-818f-707c3dd673e7\n",
            "Done for Kluuking/autotrain-flight-delay-3621096840\n",
            "Done for Kluuking/Airlinesuiztcxpg-Delay-classification\n",
            "Done for BenjaminB/knn-example-intelex-c035ccff-d23b-4e02-97bd-14cf3cb0bde5\n",
            "Done for agucci/my-model\n",
            "Done for desertdev/autotrain-imdb-sentiment-analysis-44994113085\n",
            "Done for Johnson28/j-example\n",
            "Done for sklearn-docs/anomaly-detection\n",
            "Done for hbui/Drought_Vulnerability_Assessment\n",
            "Done for robingenz/huggingface-iris-inference-test\n",
            "Done for harshiv/prediction\n",
            "Done for haizad/ames-housing-lasso-predictor\n",
            "Done for haizad/ames-housing-gbdt-predictor\n",
            "Done for haizad/ames-housing-random-forest-predictor\n",
            "Done for harithapliyal/autotrain-tatanic-survival-51030121311\n",
            "Done for abhatt13/HeartDiseasePredictor\n",
            "Done for M-Ahmad-Abid/Diabetes_model\n",
            "Done for d2i-pti-iu/test_svc_model\n",
            "Done for d2i-pti-iu/iris_test\n",
            "Done for Danasoumoh/production_test\n",
            "Done for XaviArmengol/autotrain-titanic-54879128171\n",
            "Done for matth/flowformer\n",
            "Done for 0x-YuAN/autotrain-a_-55839129832\n",
            "Done for vvmnnnkv/wine-quality\n",
            "Done for adgrowr/autotrain-negative-keywords-classifier-61622134846\n",
            "Done for aduzlo/zello-valid-trial-v3.2\n",
            "Done for wisard/scheduling-suggestion\n",
            "Done for guvhers/dummy\n",
            "Done for ketong3906/autotrain-iris_truncated-64451135750\n",
            "Done for nvenhuizen14/mofodbtransactions\n",
            "Done for jrosenzw/autotrain-diabetes-detection-74053139456\n",
            "Done for jrosenzw/autotrain-diabetes-detection-2-74371139581\n",
            "Done for runMark/tttttxxx\n",
            "Done for reachosen/autotrain-palv1-76806140361\n",
            "Done for Q-bert/eartquake-model\n",
            "Done for dgergherherherhererher/dfsgs\n",
            "Done for JMullings/ts-xor-demo\n",
            "Done for sulpha/student_academic_success\n",
            "Done for sulpha/student_academic_success_1\n",
            "Done for Hossein69/test1\n",
            "Done for Nabil000/trial\n",
            "Done for wlaminack/testingmodel\n",
            "Done for sulpha/BDM_Preject_model\n",
            "Done for keras-io/timeseries-anomaly-detection\n",
            "Done for srg/outhimar_64-Close-regression\n",
            "Done for inayet/autotrain-price-prediction-1331950900\n",
            "Done for rajistics/MAPIE-TS-Electricity\n",
            "Done for rajistics/california_housing\n",
            "Done for scikit-learn/Fish-Weight\n",
            "Done for julien-c/pokemon-predict-hp\n",
            "Done for halflings/pokemon_hp\n",
            "Done for halflings/pokemon.csv\n",
            "Done for julien-c/avocado-prices\n",
            "Done for halflings/nateraw_world-happiness_2019.csv\n",
            "Done for halflings/nateraw_world-happiness_2018.csv\n",
            "Done for halflings/nateraw_avocado-prices_avocado.csv\n",
            "Done for halflings/nateraw_world-happiness_2018_2.csv\n",
            "Done for jwan2021/autotrain-us-housing-prices-1771761510\n",
            "Done for jwan2021/autotrain-us-housing-prices-1771761511\n",
            "Done for jwan2021/autotrain-us-housing-prices-1771761512\n",
            "Done for jwan2021/autotrain-us-housing-prices-1771761513\n",
            "Done for jwan2021/autotrain-us-housing-prices-1771761514\n",
            "Done for pcoloc/autotrain-only-rssi-1813762559\n",
            "Done for pcoloc/autotrain-600-dragino-1839063122\n",
            "Done for pcoloc/autotrain-mikrotik-7-7-1860563588\n",
            "Done for pcoloc/autotrain-mikrotik-7-7-1860563590\n",
            "Done for pcoloc/autotrain-mikrotik-7-7-1860563597\n",
            "Done for pcoloc/autotrain-dragino-7-7-1860763606\n",
            "Done for pcoloc/autotrain-dragino-7-7-max_495m-1860863627\n",
            "Done for pcoloc/autotrain-dragino-7-7-max_300m-1861063640\n",
            "Done for ayyuce/my_solar_model\n",
            "Done for halflings/house_price_prediction_ser\n",
            "Done for halflings/house_price_prediction_dev\n",
            "Done for halflings/house_price_prediction_ser2\n",
            "Done for Robertooo/autotrain-hmaet-2037366889\n",
            "Done for Robertooo/autotrain-hmaet-2037366891\n",
            "Done for IMFAA/Magnet_Tc_predictor\n",
            "Done for moro23/used-phones-price-prediction\n",
            "Done for scikit-learn/persistence\n",
            "Done for scikit-learn/passive-agressive-regressor\n",
            "Done for al02783013/autotrain-faseiii_diciembre-2311773112\n",
            "Done for dvgodoy/sklearn-mpg\n",
            "Done for uisikdag/boston_housing_regression\n",
            "Done for uisikdag/iris_classification\n",
            "Done for merve/xgboost-example\n",
            "Done for scikit-learn/xgboost-example\n",
            "Done for uisikdag/simple_clasi_dataexp2weka\n",
            "Done for samyak152002/cat_boost_regressor\n",
            "Done for geninhu/skops_logistics\n",
            "Done for vumichien/skops_logistics\n",
            "Done for halflings/julien-c_kaggle-rounakbanik-pokemon_pokemon.csv\n",
            "Done for BenjaminB/example-california-housing\n",
            "Done for wangdy/autotrain-godaddy2-38507101578\n",
            "Done for farouk97/autotrain-test7-2644pc-linearregr-38619101723\n",
            "Done for halflings/house_price_prediction_testmarch2023\n",
            "Done for bibekbehera/autotrain-numeric_prediction-40376105012\n",
            "Done for bibekbehera/autotrain-numeric_prediction-40376105019\n",
            "Done for wangdy/autotrain-goddy3-40913105966\n",
            "Done for FaroukFaiz/test\n",
            "Done for FaroukFaiz/house_price_prediction2\n",
            "Done for habbibi/habi\n",
            "Done for kochetkovIT/autotrain-ironhack-49741119788\n",
            "Done for FaroukFaiz/house_price_prediction3\n",
            "Done for harshiv/placementrep\n",
            "Done for vyver7952/autotrain-foreign-exchange-idr-usd-50442120505\n",
            "Done for vyver7952/autotrain-foreign-exchange-idr-usd-50442120506\n",
            "Done for vyver7952/autotrain-foreign-exchange-idr-usd-50442120507\n",
            "Done for vyver7952/autotrain-foreign-exchange-idr-usd-50442120508\n",
            "Done for vyver7952/autotrain-foreign-exchange-idr-usd-50442120509\n",
            "Done for Arahant/Data500.csv\n",
            "Done for Kartheesh/MLproject\n",
            "Done for Ahmadswaid/california_housing\n",
            "Done for Ahmadswaid/sklearn-mpg\n",
            "Done for Ahmadswaid/example-california-housing\n",
            "Done for rgeorgescu/agri-template\n",
            "Done for rgeorgescu/agricultural_yield_transformer\n",
            "Done for frncscp/ms-azure-bike-rentals\n",
            "Done for Jayabalambika/MCI\n",
            "Done for jucamohedano/example-california-housing\n",
            "Done for B0b91/AILearnsToMultiply2\n",
            "Done for Oshan/regressor\n",
            "Done for mzallaghi4/OptimalData\n",
            "Done for Notaspy1234/Autotrain3-0\n",
            "Done for arviszeile/autotrain-golf-winner-2-87274143423\n",
            "Done for arviszeile/autotrain-golf-winner-2-87274143425\n",
            "Done for will-clarke/km3p-5cou-dikk-0\n",
            "Done for MasumBhuiyan/linear-regression\n",
            "Done for FreekyMeeky/autotrain-tm-pricepredictor-98386147082\n",
            "Done for Fatihrizkia/autotrain-xauusdh4timestamp-100145147571\n",
            "Done for bcwarner/audit-icu-gpt2-25_3M\n",
            "Done for bcwarner/audit-icu-gpt2-131_6M\n",
            "Done for bcwarner/audit-icu-gpt2-46_5M\n",
            "Done for bcwarner/audit-icu-gpt2-89_0M\n",
            "Done for bcwarner/audit-icu-llama-112_0M\n",
            "Done for bcwarner/audit-icu-llama-219_8M\n",
            "Done for bcwarner/audit-icu-rwkv-127_2M\n",
            "Done for bcwarner/audit-icu-rwkv-65_7M\n",
            "Done for bcwarner/audit-icu-llama-58_1M\n",
            "Done for flaviaggp/LinearRegression_californiahousing\n",
            "Done for nicoler229/p2\n",
            "Done for Mayank-2002/House_Prediction-Bengaluru_India\n",
            "Done for gvozdev/ratings-prediction\n",
            "Done for Dhananjay14/LR\n",
            "Done for diffuser34/autotrain-uzdtm-nwkp2\n",
            "Done for tmohoric-ewc/safer-skin\n",
            "Done for pgurazada1/diamond-price-predictor\n",
            "Done for silk-road/simple-face-recognition\n",
            "Done for SenecaCloudG4/laptop_price_prediction_v1\n",
            "Done for SenecaCloudG4/Project2\n",
            "Done for ZackJones/TDM\n",
            "Done for ZackJones/PDM\n",
            "Done for MelioAI/california-housing\n",
            "Done for jul-fls/autotrain-fbyte-l9vfz\n",
            "Done for as-cle-bert/carbon-footprint-prediction\n",
            "Done for google/timesfm-1.0-200m\n",
            "Done for amazon/chronos-t5-large\n",
            "Done for AutonLab/MOMENT-1-large\n",
            "Done for amazon/chronos-t5-small\n",
            "Done for autogluon/chronos-t5-tiny\n",
            "Done for keras-io/timeseries_transformer_classification\n",
            "Done for keras-io/timeseries_forecasting_for_weather\n",
            "Done for time-series-foundation-models/Lag-Llama\n",
            "Done for amazon/chronos-t5-mini\n",
            "Done for amazon/chronos-t5-base\n",
            "Done for amazon/chronos-t5-tiny\n",
            "Done for autogluon/chronos-t5-mini\n",
            "Done for autogluon/chronos-t5-small\n",
            "Done for autogluon/chronos-t5-base\n",
            "Done for autogluon/chronos-t5-large\n",
            "Done for jcomputer/timefs\n",
            "Done for sadhaklal/linear-regression-geron-time-series\n",
            "Done for sadhaklal/mlp-geron-time-series\n",
            "Done for jat-project/jat\n",
            "Done for edbeeching/decision-transformer-gym-hopper-expert\n",
            "Done for edbeeching/doom_health_gathering_supreme_2222\n",
            "Done for eloialonso/diamond\n",
            "Done for starBot/q-FrozenLake-v1-4x4-noSlippery\n",
            "Done for pierrelb/ppo-Huggy\n",
            "Done for ThomasSimonini/ML-Agents-SnowballFight-1vs1\n",
            "Done for ThomasSimonini/demo-hf-CartPole-v1\n",
            "Done for ThomasSimonini/mlagents-snowballfight-1vs1-ppo\n",
            "Done for ThomasSimonini/ppo-AntBulletEnv-v0\n",
            "Done for ThomasSimonini/ppo-BreakoutNoFrameskip-v4\n",
            "Done for ThomasSimonini/ppo-LunarLander-v2\n",
            "Done for ThomasSimonini/ppo-PongNoFrameskip-v4\n",
            "Done for ThomasSimonini/ppo-QbertNoFrameskip-v4\n",
            "Done for ThomasSimonini/ppo-SeaquestNoFrameskip-v4\n",
            "Done for ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4\n",
            "Done for ThomasSimonini/ppo-Walker2DBulletEnv-v0\n",
            "Done for ThomasSimonini/stable-baselines3-ppo-LunarLander-v2\n",
            "Done for carlosaguayo/Simonini-ppo-LunarLander-v2\n",
            "Done for edbeeching/decision_transformer_atari\n",
            "Done for mrm8488/a2c-Pong-v0\n",
            "Done for mrm8488/a2c-PongNoFrameskip-v0\n",
            "Done for osanseviero/ppo-LunarLander-v2\n",
            "Done for sb3/demo-hf-CartPole-v1\n",
            "Done for edbeeching/decision-transformer-gym-halfcheetah-expert\n",
            "Done for edbeeching/decision-transformer-gym-halfcheetah-medium\n",
            "Done for edbeeching/decision-transformer-gym-halfcheetah-medium-replay\n",
            "Done for edbeeching/decision-transformer-gym-hopper-medium\n",
            "Done for edbeeching/decision-transformer-gym-hopper-medium-replay\n",
            "Done for edbeeching/decision-transformer-gym-walker2d-expert\n",
            "Done for edbeeching/decision-transformer-gym-walker2d-medium\n",
            "Done for edbeeching/decision-transformer-gym-walker2d-medium-replay\n",
            "Done for ThomasSimonini/MLAgents-Pyramids\n",
            "Done for TestSB3/ppo-CartPole-v1\n",
            "Done for AlekseyKorshuk/tic-tac-toe\n",
            "Done for osanseviero/TEST_VM_ppo-SpaceInvadersNoFrameskip-v43\n",
            "Done for TrabajoAprendizajeProfundo/Trabajo\n",
            "Done for ThomasSimonini/Ball\n",
            "Done for osanseviero/Ball_test\n",
            "Done for osanseviero/TEST_COLAB_ppo-SpaceInvadersNoFrameskip-v4\n",
            "Done for ThomasSimonini/ppo-Huggy\n",
            "Done for osanseviero/test_sb3\n",
            "Done for sb3/ppo-Pendulum-v1\n",
            "Done for osanseviero/TEST2ppo-LunarLander-v3\n",
            "Done for SuperSecureHuman/Lunar-Landing-PPO\n",
            "Done for epsil/ppo-LunarLander-v2\n",
            "Done for LidarRL/TEST2ppo-LunarLander-v2\n",
            "Done for DBusAI/ppo-LunarLander-v2\n",
            "Done for Phaneo/ppo-LunarLander-v2\n",
            "Done for NorbertRop/PPO-MlpPolicy-LunarLander-v2\n",
            "Done for CWhy/ppo-LunarLander-v2\n",
            "Done for DarthVadar/TEST3ppo-LunarLander-v2\n",
            "Done for epsil/dqn-LunarLander-v2\n",
            "Done for seriy21/ppo-LunarLander-v2\n",
            "Done for Guillaume63/ppo-LunarLander-v2\n",
            "Done for arkadip/ppo-LunarLander-v2\n",
            "Done for jamm/ppo-LunarLander-v2\n",
            "Done for livac/ppo-LunarLander-v2\n",
            "Done for robertou2/TEST2ppo-LunarLander-v2\n",
            "Done for Erland/ppo-LunarLander-v2\n",
            "Done for seriy21/ppo-LunarLander-v2_tst2\n",
            "Done for rynsy/ppo-LunarLander-v2\n",
            "Done for demdecuong/ppo-LunarLander-v2\n",
            "Done for Sami/PPO-LunarLander-v2\n",
            "Done for Erland/ppo-LunarLander-v3\n",
            "Done for riteshhf/TEST1ppo-LunarLander-v2\n",
            "Done for Harri/ppo-LunarLander-v2\n",
            "Done for Jaechang/ppo-LunarLander-v2\n",
            "Done for NessrineT/ppo-LunarLander-v2\n",
            "Done for Harri/2nd_try_ppo-LunarLander-v2\n",
            "Done for CWhy/given-ppo-LunarLander-v2\n",
            "Done for prithvinambiar/LunarLander-v2\n",
            "Done for nondevs/TEST2ppo-LunarLander-v2\n",
            "Done for Sami/PPO-LunarLander-v2-test\n",
            "Done for AndreyM/rl_course_luner_lander\n",
            "Done for SaiShashank1303/ch-1-ppo-LunarLander-v2\n",
            "Done for elotech/ppo-LunarLander-v2\n",
            "Done for CWhy/thicc-ppo-LunarLander-v2\n",
            "Done for garybake/TEST2ppo-LunarLander-v2\n",
            "Done for utkusaglm/ppo-LunarLander-v1\n",
            "Done for mmangino/ppo-LunarLander-v2\n",
            "Done for elotech/ppo-LunarLander-v0\n",
            "Done for vkost/TEST2ppo-LunarLander-v3\n",
            "Done for araffin/ppo-LunarLander-v2\n",
            "Done for berrzy/LunarLander-v2\n",
            "Done for Giallar/TEST_UNIT_1_ppo-LunarLander-v2\n",
            "Done for akkasayaz/ppo-LunarLander-v2\n",
            "Done for christy/TEST2ppo-LunarLander-v2\n",
            "Done for dalvarez/PPO-LunarLander-v2\n",
            "Done for heriosousa/ppo-LunarLander-v2\n",
            "Done for Dugerij/PPO-LunarLander-v2\n",
            "Done for magitz/ppo-LunarLander-v2-HFcourse\n",
            "Done for cj-mills/ppo-LunarLander-v2\n",
            "Done for vickyjm/ppo-LunarLander-v2\n",
            "Done for GuanOrg/DeepRLCourse2022\n",
            "Done for mindwrapped/ppo-LunarLander-v2\n",
            "Done for saeedHedayatian/ppo-LunarLander\n",
            "Done for vebie91/ppo-LunarLander-v2_v1.0\n",
            "Done for vickyjm/dqn-LunarLander-v2\n",
            "Done for dbarbedillo/ppo-LunarLander-v2\n",
            "Done for vtorg/rl-course-unit-1-ppo-lunarlander-v2\n",
            "Done for dk-crazydiv/LunarLander-v2\n",
            "Done for DrvAgwl/ppo-LunarLander-v2\n",
            "Done for mcditoos/PPO-LunarLander-v2\n",
            "Done for Rai220/lunar-test\n",
            "Done for Jezzarax/TEST2ppo-LunarLander-v2\n",
            "Done for marleyshan21/ppo-LunarLander-v2\n",
            "Done for deutschmann/ppo-LunarLander-v2\n",
            "Done for utkusaglm/ppo-LunarLander-v0\n",
            "Done for lazyrama/ppo-LunarLander-v2\n",
            "Done for nondevs/100k-ppo-LunarLander-v2\n",
            "Done for ceyda/RLcourse-ppo-LunarLanderv2\n",
            "Done for awalmeida/TEST2ppo-LunarLander-v2\n",
            "Done for arsenplus/TEST2ppo-LunarLander-v2\n",
            "Done for nbvanting/unit1-ppo-LunarLander-v2\n",
            "Done for katta/PPO-LunarLander-v2\n",
            "Done for i8pxgd2s/ppo-LunarLander-v2\n",
            "Done for Mp93/ppo-LunarLander-v2\n",
            "Done for utsavnandi/LunarLander-v2_ppo-mlp-0505_02\n",
            "Done for DeepRoller/rl-model\n",
            "Done for diskshima/deep-rl-class-unit01-LunarLander-v2\n",
            "Done for mnpinto/TESTppo-LunarLander-v2\n",
            "Done for angelinux/PPO-LunarLander-v1\n",
            "Done for jcranney/ppo2-LunarLander-v2\n",
            "Done for kmicha/TEST2ppo-LunarLander-v2\n",
            "Done for NeutralBlaster/ppo-LunarLander\n",
            "Done for DBusAI/ppo-LunarLander-v2_v3\n",
            "Done for Bibhabasu/ppo-LunarLander-v2\n",
            "Done for AdmiralTaco/TEST2ppo-LunarLander-v2\n",
            "Done for Mizzy/TESTppo-LunarLander-v0\n",
            "Done for fmcurti/PPO-LunarLander-v2\n",
            "Done for vkost/ppo-LunarLander-v4\n",
            "Done for hugoguh/ppo-LunarLander-v2\n",
            "Done for silentOne/firstRep\n",
            "Done for mnpinto/TEST2ppo-LunarLander-v2\n",
            "Done for DarthGrogu/TEST2ppo-LunarLander-v2\n",
            "Done for pjarbas312/ppo-LunarLander-v2\n",
            "Done for fmcurti/A2C-LunarLander-v2\n",
            "Done for minemile/rl\n",
            "Done for alelola/ppo-LunarLander-v2\n",
            "Done for luizapzbn/PPO-LunarLander-v2\n",
            "Done for fmcurti/DQN-LunarLander-v2\n",
            "Done for alelola/ppo-LunarLander-v2_try2\n",
            "Done for Se1ryu/TEST2ppo-LunarLander-v2\n",
            "Done for ThetaPhiPsi/TEST2ppo-LunarLander-v2\n",
            "Done for moertelk/unit1-ppo-LunarLander-v2\n",
            "Done for AgeevRoma/LunarLander-v2-LunarLander-v2\n",
            "Done for Aanisha/LunarLander_exp1\n",
            "Done for repst/TESTppo-LunarLander-v2\n",
            "Done for SteveR/TEST2ppo-LunarLander-v1\n",
            "Done for rail-berkeley/octo-base-1.5\n",
            "Done for lerobot/diffusion_pusht\n",
            "Done for lerobot/act_aloha_sim_transfer_cube_human\n",
            "Done for camusean/grasp_diffusion\n",
            "Done for Antheia/Hanna\n",
            "Done for Bbyaz/robotics-deep-rl-grasping\n",
            "Done for facebook/vc1-base\n",
            "Done for facebook/vc1-large\n",
            "Done for Beemarkethk/Beemarket\n",
            "Done for Gage888/GageAI\n",
            "Done for Sehwan/R-Pred\n",
            "Done for MetaSLAM/AutoMerge\n",
            "Done for HCW1202/test\n",
            "Done for notmahi/dobb-e\n",
            "Done for shadyy/ARIA-7b-v0.1\n",
            "Done for rail-berkeley/octo-base\n",
            "Done for rail-berkeley/octo-small\n",
            "Done for MetaSLAM/CyberGPT\n",
            "Done for pleasefill/mesolo\n",
            "Done for AscendRobotics/AscendAI\n",
            "Done for DrXperia011/ReoxAI-Alpha\n",
            "Done for varunbel/crossway_diffusion\n",
            "Done for opensdetenn/resnet18_linear_v1\n",
            "Done for nagayama0706/administrative_processing_model\n",
            "Done for peterdavidfagan/transporter_networks\n",
            "Done for transic-robot/models\n",
            "Done for Kandreowathreo/Zoni_Model\n",
            "Done for rail-berkeley/octo-small-1.5\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://huggingface.co/models'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "types_of_tasks = []\n",
        "types = soup.find_all('div', class_='mb-3 text-sm font-medium text-gray-500')\n",
        "for typ in types:\n",
        "    types_of_tasks.append(typ.text)\n",
        "\n",
        "tasks_of_model = []\n",
        "tasks = soup.find_all('div', class_='flex flex-wrap')\n",
        "for task in tasks:\n",
        "  for i in task:\n",
        "    tasks_of_model.append(i.text)\n",
        "\n",
        "clean_tasks = [s.strip() for s in tasks_of_model]\n",
        "clean_types = [s.strip() for s in types_of_tasks]\n",
        "\n",
        "clean_tasks = [item.lower().replace(' ', '-') for item in clean_tasks]\n",
        "\n",
        "group_ranges = [\n",
        "    (0, 2),    # Multimodal\n",
        "    (3, 19),   # Computer Vision\n",
        "    (20, 31),  # Natural Language Processing\n",
        "    (32, 37),  # Audio\n",
        "    (38, 40),  # Tabular\n",
        "    (41, 42),  # Reinforcement Learning\n",
        "    (43, 43)   # Graph Machine Learning\n",
        "]\n",
        "\n",
        "clean_tasks = [clean_tasks[start:end + 1] for start, end in group_ranges]\n",
        "\n",
        "types_with_tasks = {clean_types[i]:clean_tasks[i] for i in range(len(clean_types))}\n",
        "\n",
        "# taskToBeSearch = input('Enter your task name :')\n",
        "total_model_ids = []\n",
        "\n",
        "for tasks in clean_tasks:\n",
        "    for task in tasks:\n",
        "        for pageNo in range(5):\n",
        "            url = f'https://huggingface.co/models?pipeline_tag={task}&p={pageNo}&sort=trending'\n",
        "            response = requests.get(url)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            if soup:\n",
        "                model_ids = []\n",
        "                articles = soup.find_all('article', class_=\"overview-card-wrapper group/repo\")\n",
        "                for article in articles:\n",
        "                    h4_tag = article.find('h4', class_=\"text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-smd\")\n",
        "                    if h4_tag:\n",
        "                        h4_text = h4_tag.get_text(strip=True)\n",
        "                        model_ids.append(h4_text)\n",
        "\n",
        "            total_model_ids.extend(model_ids)\n",
        "        print(f'Done for {task} !')\n",
        "\n",
        "\n",
        "def get_model_data(model_id):\n",
        "  url = f\"https://huggingface.co/api/models/{model_id}\"\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    model_info = response.json()\n",
        "    return model_info\n",
        "\n",
        "models_data = []\n",
        "if total_model_ids:\n",
        "  for model_id in total_model_ids:\n",
        "    model_data = get_model_data(model_id=model_id)\n",
        "    if model_data is not None:\n",
        "      models_data.append(model_data)\n",
        "      print(f'Done for {model_id}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P09MFYS7xdGW"
      },
      "outputs": [],
      "source": [
        "len(total_model_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUUcy3d6yUga"
      },
      "outputs": [],
      "source": [
        "len(models_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RGH6rkxgDofe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>id</th>\n",
              "      <th>modelId</th>\n",
              "      <th>author</th>\n",
              "      <th>sha</th>\n",
              "      <th>lastModified</th>\n",
              "      <th>private</th>\n",
              "      <th>disabled</th>\n",
              "      <th>gated</th>\n",
              "      <th>pipeline_tag</th>\n",
              "      <th>...</th>\n",
              "      <th>model-index</th>\n",
              "      <th>config</th>\n",
              "      <th>cardData</th>\n",
              "      <th>transformersInfo</th>\n",
              "      <th>siblings</th>\n",
              "      <th>spaces</th>\n",
              "      <th>createdAt</th>\n",
              "      <th>safetensors</th>\n",
              "      <th>widgetData</th>\n",
              "      <th>mask_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65e60cda4b2e0f45e49dc03d</td>\n",
              "      <td>vikhyatk/moondream2</td>\n",
              "      <td>vikhyatk/moondream2</td>\n",
              "      <td>vikhyatk</td>\n",
              "      <td>fa8398d264205ac3890b62e97d3c588268ed9ec4</td>\n",
              "      <td>2024-05-22T19:59:36.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>image-text-to-text</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'architectures': ['Moondream'], 'auto_map': {...</td>\n",
              "      <td>{'license': 'apache-2.0', 'pipeline_tag': 'ima...</td>\n",
              "      <td>{'auto_model': 'AutoModelForCausalLM', 'custom...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[vikhyatk/moondream2, fffiloni/soft-video-unde...</td>\n",
              "      <td>2024-03-04T18:03:06.000Z</td>\n",
              "      <td>{'parameters': {'F16': 1866919792}, 'total': 1...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6615d61745336ca7744956a4</td>\n",
              "      <td>HuggingFaceM4/idefics2-8b</td>\n",
              "      <td>HuggingFaceM4/idefics2-8b</td>\n",
              "      <td>HuggingFaceM4</td>\n",
              "      <td>2c031da2dc71f3ac989f9efa9b8ff476df3842c0</td>\n",
              "      <td>2024-05-06T13:33:09.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>image-text-to-text</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'architectures': ['Idefics2ForConditionalGene...</td>\n",
              "      <td>{'license': 'apache-2.0', 'datasets': ['Huggin...</td>\n",
              "      <td>{'auto_model': 'AutoModelForPreTraining', 'pip...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[KingNish/OpenGPT-4o, HuggingFaceM4/idefics2_p...</td>\n",
              "      <td>2024-04-09T23:58:15.000Z</td>\n",
              "      <td>{'parameters': {'F32': 8402768112}, 'total': 8...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6638684accadfaaeac5637e4</td>\n",
              "      <td>Salesforce/xgen-mm-phi3-mini-instruct-r-v1</td>\n",
              "      <td>Salesforce/xgen-mm-phi3-mini-instruct-r-v1</td>\n",
              "      <td>Salesforce</td>\n",
              "      <td>854508f6f576cb52b7524416c67e0a9a3229c170</td>\n",
              "      <td>2024-05-24T23:16:26.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>image-text-to-text</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'architectures': ['XGenMMModelForConditionalG...</td>\n",
              "      <td>{'license': 'cc-by-nc-4.0', 'language': ['en']...</td>\n",
              "      <td>{'auto_model': 'AutoModelForVision2Seq', 'cust...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2024-05-06T05:19:06.000Z</td>\n",
              "      <td>{'parameters': {'F32': 4589362243}, 'total': 4...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65d45c6c492611d68f3084a2</td>\n",
              "      <td>llava-hf/llava-v1.6-mistral-7b-hf</td>\n",
              "      <td>llava-hf/llava-v1.6-mistral-7b-hf</td>\n",
              "      <td>llava-hf</td>\n",
              "      <td>a1d521368f8d353afa4da2ed2bb1bf646ef1ff5f</td>\n",
              "      <td>2024-05-09T20:11:08.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>image-text-to-text</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'architectures': ['LlavaNextForConditionalGen...</td>\n",
              "      <td>{'tags': ['vision', 'image-text-to-text'], 'li...</td>\n",
              "      <td>{'auto_model': 'AutoModelForPreTraining', 'pip...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[merve/llava-next, SeaLLMs/SeaLLM-7B, merve/co...</td>\n",
              "      <td>2024-02-20T08:01:48.000Z</td>\n",
              "      <td>{'parameters': {'F16': 7566747648}, 'total': 7...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>663397ff9e6df7d7d49971c5</td>\n",
              "      <td>HuggingFaceM4/idefics2-8b-chatty</td>\n",
              "      <td>HuggingFaceM4/idefics2-8b-chatty</td>\n",
              "      <td>HuggingFaceM4</td>\n",
              "      <td>2bad45267b4d212775cd89d07061ad6c2d1ac3e7</td>\n",
              "      <td>2024-05-06T13:33:23.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>image-text-to-text</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'architectures': ['Idefics2ForConditionalGene...</td>\n",
              "      <td>{'license': 'apache-2.0', 'datasets': ['Huggin...</td>\n",
              "      <td>{'auto_model': 'AutoModelForPreTraining', 'pip...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[KingNish/OpenGPT-4o, HuggingFaceM4/idefics2_p...</td>\n",
              "      <td>2024-05-02T13:41:19.000Z</td>\n",
              "      <td>{'parameters': {'F32': 8402768112}, 'total': 8...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id                                          id  \\\n",
              "0  65e60cda4b2e0f45e49dc03d                         vikhyatk/moondream2   \n",
              "1  6615d61745336ca7744956a4                   HuggingFaceM4/idefics2-8b   \n",
              "2  6638684accadfaaeac5637e4  Salesforce/xgen-mm-phi3-mini-instruct-r-v1   \n",
              "3  65d45c6c492611d68f3084a2           llava-hf/llava-v1.6-mistral-7b-hf   \n",
              "4  663397ff9e6df7d7d49971c5            HuggingFaceM4/idefics2-8b-chatty   \n",
              "\n",
              "                                      modelId         author  \\\n",
              "0                         vikhyatk/moondream2       vikhyatk   \n",
              "1                   HuggingFaceM4/idefics2-8b  HuggingFaceM4   \n",
              "2  Salesforce/xgen-mm-phi3-mini-instruct-r-v1     Salesforce   \n",
              "3           llava-hf/llava-v1.6-mistral-7b-hf       llava-hf   \n",
              "4            HuggingFaceM4/idefics2-8b-chatty  HuggingFaceM4   \n",
              "\n",
              "                                        sha              lastModified  \\\n",
              "0  fa8398d264205ac3890b62e97d3c588268ed9ec4  2024-05-22T19:59:36.000Z   \n",
              "1  2c031da2dc71f3ac989f9efa9b8ff476df3842c0  2024-05-06T13:33:09.000Z   \n",
              "2  854508f6f576cb52b7524416c67e0a9a3229c170  2024-05-24T23:16:26.000Z   \n",
              "3  a1d521368f8d353afa4da2ed2bb1bf646ef1ff5f  2024-05-09T20:11:08.000Z   \n",
              "4  2bad45267b4d212775cd89d07061ad6c2d1ac3e7  2024-05-06T13:33:23.000Z   \n",
              "\n",
              "   private  disabled  gated        pipeline_tag  ... model-index  \\\n",
              "0    False     False  False  image-text-to-text  ...        None   \n",
              "1    False     False  False  image-text-to-text  ...        None   \n",
              "2    False     False  False  image-text-to-text  ...        None   \n",
              "3    False     False  False  image-text-to-text  ...        None   \n",
              "4    False     False  False  image-text-to-text  ...        None   \n",
              "\n",
              "                                              config  \\\n",
              "0  {'architectures': ['Moondream'], 'auto_map': {...   \n",
              "1  {'architectures': ['Idefics2ForConditionalGene...   \n",
              "2  {'architectures': ['XGenMMModelForConditionalG...   \n",
              "3  {'architectures': ['LlavaNextForConditionalGen...   \n",
              "4  {'architectures': ['Idefics2ForConditionalGene...   \n",
              "\n",
              "                                            cardData  \\\n",
              "0  {'license': 'apache-2.0', 'pipeline_tag': 'ima...   \n",
              "1  {'license': 'apache-2.0', 'datasets': ['Huggin...   \n",
              "2  {'license': 'cc-by-nc-4.0', 'language': ['en']...   \n",
              "3  {'tags': ['vision', 'image-text-to-text'], 'li...   \n",
              "4  {'license': 'apache-2.0', 'datasets': ['Huggin...   \n",
              "\n",
              "                                    transformersInfo  \\\n",
              "0  {'auto_model': 'AutoModelForCausalLM', 'custom...   \n",
              "1  {'auto_model': 'AutoModelForPreTraining', 'pip...   \n",
              "2  {'auto_model': 'AutoModelForVision2Seq', 'cust...   \n",
              "3  {'auto_model': 'AutoModelForPreTraining', 'pip...   \n",
              "4  {'auto_model': 'AutoModelForPreTraining', 'pip...   \n",
              "\n",
              "                                            siblings  \\\n",
              "0  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "1  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "2  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "3  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "4  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "\n",
              "                                              spaces  \\\n",
              "0  [vikhyatk/moondream2, fffiloni/soft-video-unde...   \n",
              "1  [KingNish/OpenGPT-4o, HuggingFaceM4/idefics2_p...   \n",
              "2                                                 []   \n",
              "3  [merve/llava-next, SeaLLMs/SeaLLM-7B, merve/co...   \n",
              "4  [KingNish/OpenGPT-4o, HuggingFaceM4/idefics2_p...   \n",
              "\n",
              "                  createdAt  \\\n",
              "0  2024-03-04T18:03:06.000Z   \n",
              "1  2024-04-09T23:58:15.000Z   \n",
              "2  2024-05-06T05:19:06.000Z   \n",
              "3  2024-02-20T08:01:48.000Z   \n",
              "4  2024-05-02T13:41:19.000Z   \n",
              "\n",
              "                                         safetensors widgetData mask_token  \n",
              "0  {'parameters': {'F16': 1866919792}, 'total': 1...        NaN        NaN  \n",
              "1  {'parameters': {'F32': 8402768112}, 'total': 8...        NaN        NaN  \n",
              "2  {'parameters': {'F32': 4589362243}, 'total': 4...        NaN        NaN  \n",
              "3  {'parameters': {'F16': 7566747648}, 'total': 7...        NaN        NaN  \n",
              "4  {'parameters': {'F32': 8402768112}, 'total': 8...        NaN        NaN  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(models_data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5ftgeu-_IdRl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>id</th>\n",
              "      <th>modelId</th>\n",
              "      <th>author</th>\n",
              "      <th>sha</th>\n",
              "      <th>lastModified</th>\n",
              "      <th>private</th>\n",
              "      <th>disabled</th>\n",
              "      <th>gated</th>\n",
              "      <th>pipeline_tag</th>\n",
              "      <th>...</th>\n",
              "      <th>model-index</th>\n",
              "      <th>config</th>\n",
              "      <th>cardData</th>\n",
              "      <th>transformersInfo</th>\n",
              "      <th>siblings</th>\n",
              "      <th>spaces</th>\n",
              "      <th>createdAt</th>\n",
              "      <th>safetensors</th>\n",
              "      <th>widgetData</th>\n",
              "      <th>mask_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1864</th>\n",
              "      <td>6324070dc2d8cfcd809a62c3</td>\n",
              "      <td>Bingsu/clip-vit-base-patch32-ko</td>\n",
              "      <td>Bingsu/clip-vit-base-patch32-ko</td>\n",
              "      <td>Bingsu</td>\n",
              "      <td>844c6cd1d75e142331ffd451ad8a878191869322</td>\n",
              "      <td>2022-11-08T11:02:10.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>zero-shot-image-classification</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'architectures': ['CLIPModel'], 'model_type':...</td>\n",
              "      <td>{'widget': [{'src': 'https://huggingface.co/da...</td>\n",
              "      <td>{'auto_model': 'AutoModelForZeroShotImageClass...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[Bingsu/my-clip-model-test]</td>\n",
              "      <td>2022-09-16T05:18:05.000Z</td>\n",
              "      <td>{'parameters': {'F32': 151277312, 'I64': 127},...</td>\n",
              "      <td>[{'src': 'https://huggingface.co/datasets/mish...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>653a147c3483211cc7d22536</td>\n",
              "      <td>jalbrechts/vilt-finetuned-fashion-vqa</td>\n",
              "      <td>jalbrechts/vilt-finetuned-fashion-vqa</td>\n",
              "      <td>jalbrechts</td>\n",
              "      <td>a8771d8fdd9d65853e1e653d9a61fdc506e319b1</td>\n",
              "      <td>2023-10-26T10:05:19.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>visual-question-answering</td>\n",
              "      <td>...</td>\n",
              "      <td>[{'name': 'vilt-finetuned-fashion-vqa', 'resul...</td>\n",
              "      <td>{'architectures': ['ViltForQuestionAnswering']...</td>\n",
              "      <td>{'license': 'apache-2.0', 'base_model': 'dande...</td>\n",
              "      <td>{'auto_model': 'AutoModelForVisualQuestionAnsw...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[kpkom/jalbrechts-vilt-finetuned-fashion-vqa]</td>\n",
              "      <td>2023-10-26T07:25:48.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4965</th>\n",
              "      <td>63c96d634c74c79fff69c49e</td>\n",
              "      <td>merve/xgboost-example</td>\n",
              "      <td>merve/xgboost-example</td>\n",
              "      <td>merve</td>\n",
              "      <td>70beca484018e2959c72dbfb9d3eb575590a94d6</td>\n",
              "      <td>2023-01-19T16:18:48.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>tabular-regression</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>{'sklearn': {'model': {'file': 'model.pkl'}, '...</td>\n",
              "      <td>{'library_name': 'sklearn', 'tags': ['sklearn'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2023-01-19T16:18:43.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'structuredData': {'Fedu': [3, 3, 3], 'Fjob'...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4481</th>\n",
              "      <td>621ffdc136468d709f17ac3a</td>\n",
              "      <td>espnet/Wangyou_Zhang_chime4_enh_train_enh_beam...</td>\n",
              "      <td>espnet/Wangyou_Zhang_chime4_enh_train_enh_beam...</td>\n",
              "      <td>espnet</td>\n",
              "      <td>573b1a03ff782e264a235f470b3adba2ac092ea8</td>\n",
              "      <td>2022-02-11T06:24:00.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>audio-to-audio</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'tags': ['espnet', 'audio', 'audio-to-audio']...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2022-03-02T23:29:05.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>64afe2c1d3c077ff0232c1a2</td>\n",
              "      <td>ZoeVN/sam_full_finetune_breastcancer</td>\n",
              "      <td>ZoeVN/sam_full_finetune_breastcancer</td>\n",
              "      <td>ZoeVN</td>\n",
              "      <td>cf3d94f072caba70f306da2aecadcb641cc196d8</td>\n",
              "      <td>2023-07-13T11:41:28.000Z</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>mask-generation</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'architectures': ['SamModel'], 'model_type': ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'auto_model': 'AutoModelForMaskGeneration', '...</td>\n",
              "      <td>[{'rfilename': '.gitattributes'}, {'rfilename'...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2023-07-13T11:40:49.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           _id  \\\n",
              "1864  6324070dc2d8cfcd809a62c3   \n",
              "236   653a147c3483211cc7d22536   \n",
              "4965  63c96d634c74c79fff69c49e   \n",
              "4481  621ffdc136468d709f17ac3a   \n",
              "1979  64afe2c1d3c077ff0232c1a2   \n",
              "\n",
              "                                                     id  \\\n",
              "1864                    Bingsu/clip-vit-base-patch32-ko   \n",
              "236               jalbrechts/vilt-finetuned-fashion-vqa   \n",
              "4965                              merve/xgboost-example   \n",
              "4481  espnet/Wangyou_Zhang_chime4_enh_train_enh_beam...   \n",
              "1979               ZoeVN/sam_full_finetune_breastcancer   \n",
              "\n",
              "                                                modelId      author  \\\n",
              "1864                    Bingsu/clip-vit-base-patch32-ko      Bingsu   \n",
              "236               jalbrechts/vilt-finetuned-fashion-vqa  jalbrechts   \n",
              "4965                              merve/xgboost-example       merve   \n",
              "4481  espnet/Wangyou_Zhang_chime4_enh_train_enh_beam...      espnet   \n",
              "1979               ZoeVN/sam_full_finetune_breastcancer       ZoeVN   \n",
              "\n",
              "                                           sha              lastModified  \\\n",
              "1864  844c6cd1d75e142331ffd451ad8a878191869322  2022-11-08T11:02:10.000Z   \n",
              "236   a8771d8fdd9d65853e1e653d9a61fdc506e319b1  2023-10-26T10:05:19.000Z   \n",
              "4965  70beca484018e2959c72dbfb9d3eb575590a94d6  2023-01-19T16:18:48.000Z   \n",
              "4481  573b1a03ff782e264a235f470b3adba2ac092ea8  2022-02-11T06:24:00.000Z   \n",
              "1979  cf3d94f072caba70f306da2aecadcb641cc196d8  2023-07-13T11:41:28.000Z   \n",
              "\n",
              "      private  disabled  gated                    pipeline_tag  ...  \\\n",
              "1864    False     False  False  zero-shot-image-classification  ...   \n",
              "236     False     False  False       visual-question-answering  ...   \n",
              "4965    False     False  False              tabular-regression  ...   \n",
              "4481    False     False  False                  audio-to-audio  ...   \n",
              "1979    False     False  False                 mask-generation  ...   \n",
              "\n",
              "                                            model-index  \\\n",
              "1864                                               None   \n",
              "236   [{'name': 'vilt-finetuned-fashion-vqa', 'resul...   \n",
              "4965                                               None   \n",
              "4481                                               None   \n",
              "1979                                                NaN   \n",
              "\n",
              "                                                 config  \\\n",
              "1864  {'architectures': ['CLIPModel'], 'model_type':...   \n",
              "236   {'architectures': ['ViltForQuestionAnswering']...   \n",
              "4965  {'sklearn': {'model': {'file': 'model.pkl'}, '...   \n",
              "4481                                                NaN   \n",
              "1979  {'architectures': ['SamModel'], 'model_type': ...   \n",
              "\n",
              "                                               cardData  \\\n",
              "1864  {'widget': [{'src': 'https://huggingface.co/da...   \n",
              "236   {'license': 'apache-2.0', 'base_model': 'dande...   \n",
              "4965  {'library_name': 'sklearn', 'tags': ['sklearn'...   \n",
              "4481  {'tags': ['espnet', 'audio', 'audio-to-audio']...   \n",
              "1979                                                NaN   \n",
              "\n",
              "                                       transformersInfo  \\\n",
              "1864  {'auto_model': 'AutoModelForZeroShotImageClass...   \n",
              "236   {'auto_model': 'AutoModelForVisualQuestionAnsw...   \n",
              "4965                                                NaN   \n",
              "4481                                                NaN   \n",
              "1979  {'auto_model': 'AutoModelForMaskGeneration', '...   \n",
              "\n",
              "                                               siblings  \\\n",
              "1864  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "236   [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "4965  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "4481  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "1979  [{'rfilename': '.gitattributes'}, {'rfilename'...   \n",
              "\n",
              "                                             spaces                 createdAt  \\\n",
              "1864                    [Bingsu/my-clip-model-test]  2022-09-16T05:18:05.000Z   \n",
              "236   [kpkom/jalbrechts-vilt-finetuned-fashion-vqa]  2023-10-26T07:25:48.000Z   \n",
              "4965                                             []  2023-01-19T16:18:43.000Z   \n",
              "4481                                             []  2022-03-02T23:29:05.000Z   \n",
              "1979                                             []  2023-07-13T11:40:49.000Z   \n",
              "\n",
              "                                            safetensors  \\\n",
              "1864  {'parameters': {'F32': 151277312, 'I64': 127},...   \n",
              "236                                                 NaN   \n",
              "4965                                                NaN   \n",
              "4481                                                NaN   \n",
              "1979                                                NaN   \n",
              "\n",
              "                                             widgetData mask_token  \n",
              "1864  [{'src': 'https://huggingface.co/datasets/mish...        NaN  \n",
              "236                                                 NaN        NaN  \n",
              "4965  [{'structuredData': {'Fedu': [3, 3, 3], 'Fjob'...        NaN  \n",
              "4481                                                NaN        NaN  \n",
              "1979                                                NaN        NaN  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s2b9Vr-eIm5i"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('models_data_df.pickle' ,'wb') as file:\n",
        "  pickle.dump(df ,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGWg8H4YI1WX"
      },
      "outputs": [],
      "source": [
        "with open('models_data_df.pickle' ,'rb') as file:\n",
        "  df = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtu1plbEI_b7"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vjwLXRnJAfG"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvMBhovUJC_q"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiAc4LR2JE46"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMiprcTfJJ3o"
      },
      "outputs": [],
      "source": [
        "df.sample(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc7GR8NQRa7o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
